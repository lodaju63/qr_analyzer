"""
l.pt ëª¨ë¸ íŒŒì¼ ë™ì‘ í™•ì¸ ìŠ¤í¬ë¦½íŠ¸
ì˜ìƒ ë° ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸ ì§€ì›
"""

import cv2
import numpy as np
import os
from pathlib import Path
import torch
import time
import datetime
import threading
from queue import Queue, Empty

# Ultralytics YOLO ëª¨ë¸ ë¡œë“œ ì‹œë„
try:
    from ultralytics import YOLO
    ULTRALYTICS_AVAILABLE = True
except ImportError:
    ULTRALYTICS_AVAILABLE = False
    print("âš ï¸ ultralyticsë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# QReader import (ì •í™•í•œ QR ìœ„ì¹˜ íƒì§€ìš©)
try:
    from qreader import QReader
    QREADER_AVAILABLE = True
except ImportError:
    QREADER_AVAILABLE = False
    print("âš ï¸ QReaderë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. pip install qreaderë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")

# í‘œì‹œìš© ì„¤ì •
import matplotlib.pyplot as plt
from matplotlib.patches import Rectangle


# -----------------------------------------------------------------
# â˜…â˜…â˜…â˜…â˜… IoU ê¸°ë°˜ ì¤‘ë³µ ì œê±° í•¨ìˆ˜ â˜…â˜…â˜…â˜…â˜…
# -----------------------------------------------------------------
def calculate_iou(bbox1, bbox2):
    """ë‘ ë°”ìš´ë”© ë°•ìŠ¤ì˜ IoU(Intersection over Union) ê³„ì‚°"""
    x1_1, y1_1, x2_1, y2_1 = bbox1
    x1_2, y1_2, x2_2, y2_2 = bbox2
    
    # êµì§‘í•© ì˜ì—­ ê³„ì‚°
    x1_i = max(x1_1, x1_2)
    y1_i = max(y1_1, y1_2)
    x2_i = min(x2_1, x2_2)
    y2_i = min(y2_1, y2_2)
    
    # êµì§‘í•©ì´ ì—†ëŠ” ê²½ìš°
    if x2_i <= x1_i or y2_i <= y1_i:
        return 0.0
    
    intersection = (x2_i - x1_i) * (y2_i - y1_i)
    
    # ê° ë°•ìŠ¤ì˜ ë©´ì 
    area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
    area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
    
    # í•©ì§‘í•© ì˜ì—­
    union = area1 + area2 - intersection
    
    # IoU ê³„ì‚°
    iou = intersection / union if union > 0 else 0.0
    return iou


def calculate_center_distance(bbox1, bbox2):
    """ë‘ ë°”ìš´ë”© ë°•ìŠ¤ì˜ ì¤‘ì‹¬ì  ê°„ ê±°ë¦¬ ê³„ì‚° (ì •ê·œí™”)"""
    x1_1, y1_1, x2_1, y2_1 = bbox1
    x1_2, y1_2, x2_2, y2_2 = bbox2
    
    # ì¤‘ì‹¬ì  ê³„ì‚°
    center1_x = (x1_1 + x2_1) / 2
    center1_y = (y1_1 + y2_1) / 2
    center2_x = (x1_2 + x2_2) / 2
    center2_y = (y1_2 + y2_2) / 2
    
    # ìœ í´ë¦¬ë“œ ê±°ë¦¬
    distance = np.sqrt((center1_x - center2_x)**2 + (center1_y - center2_y)**2)
    
    # ë°•ìŠ¤ì˜ ëŒ€ê°ì„  ê¸¸ì´ë¡œ ì •ê·œí™” (í° ë°•ìŠ¤ ê¸°ì¤€)
    diag1 = np.sqrt((x2_1 - x1_1)**2 + (y2_1 - y1_1)**2)
    diag2 = np.sqrt((x2_2 - x1_2)**2 + (y2_2 - y1_2)**2)
    max_diag = max(diag1, diag2)
    
    # ì •ê·œí™”ëœ ê±°ë¦¬ (0~1 ì‚¬ì´)
    normalized_distance = distance / max_diag if max_diag > 0 else float('inf')
    
    return normalized_distance


def get_qr_center_and_bbox(detection):
    """QRì˜ ì¤‘ì‹¬ì ê³¼ ì‚¬ê°í˜• ì¢Œí‘œë¥¼ ë°˜í™˜"""
    # bbox_xyxy ì‚¬ìš© (YOLO íƒì§€ ê²°ê³¼)
    if 'bbox' in detection:
        bbox = detection['bbox']
        if isinstance(bbox, (list, tuple, np.ndarray)) and len(bbox) == 4:
            x1, y1, x2, y2 = bbox
            center_x = (x1 + x2) / 2
            center_y = (y1 + y2) / 2
            return center_x, center_y, x1, y1, x2, y2
    
    # quad_xyê°€ ìˆìœ¼ë©´ ì‚¬ìš©
    if 'quad_xy' in detection:
        quad = detection['quad_xy']
        if len(quad) == 4:
            quad_array = np.array(quad)
            center = np.mean(quad_array, axis=0)
            x_coords = quad_array[:, 0]
            y_coords = quad_array[:, 1]
            x1, x2 = np.min(x_coords), np.max(x_coords)
            y1, y2 = np.min(y_coords), np.max(y_coords)
            return center[0], center[1], x1, y1, x2, y2
    
    # bbox_xyxy ì‚¬ìš© (fallback)
    if 'bbox_xyxy' in detection:
        bbox = detection['bbox_xyxy']
        x1, y1, x2, y2 = bbox
        center_x = (x1 + x2) / 2
        center_y = (y1 + y2) / 2
        return center_x, center_y, x1, y1, x2, y2
    
    return None, None, None, None, None, None


def filter_overlapping_detections(detections, iou_threshold=0.5):
    """
    ê²¹ì¹˜ëŠ” íƒì§€ ê²°ê³¼ ì œê±° (NMSì™€ ìœ ì‚¬)
    ìœ„ì¹˜ ê¸°ë°˜ ì¤‘ë³µ ì œê±° (í…ìŠ¤íŠ¸ ê¸°ë°˜ ì•„ë‹˜)
    """
    if not detections:
        return []
    
    # ì‹ ë¢°ë„(confidence) ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ë†’ì€ ê²ƒì´ ìš°ì„ )
    detections.sort(key=lambda x: x['confidence'], reverse=True)
    
    filtered_detections = []
    for detection in detections:
        is_overlapping = False
        bbox1 = detection['bbox']
        
        # bboxê°€ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° íŠœí”Œë¡œ ë³€í™˜
        if isinstance(bbox1, (list, np.ndarray)):
            if len(bbox1) == 4:
                bbox1 = (bbox1[0], bbox1[1], bbox1[2], bbox1[3])
            else:
                continue
        
        for filtered in filtered_detections:
            bbox2 = filtered['bbox']
            if isinstance(bbox2, (list, np.ndarray)):
                if len(bbox2) == 4:
                    bbox2 = (bbox2[0], bbox2[1], bbox2[2], bbox2[3])
                else:
                    continue
            
            iou = calculate_iou(bbox1, bbox2)
            
            if iou > iou_threshold:
                is_overlapping = True
                break
        
        if not is_overlapping:
            filtered_detections.append(detection)
    
    return filtered_detections


# -----------------------------------------------------------------
# â˜…â˜…â˜…â˜…â˜… í”„ë ˆì„ ê°„ ì¶”ì  ê¸°ëŠ¥ â˜…â˜…â˜…â˜…â˜…
# -----------------------------------------------------------------
class QRTrack:
    """ë‹¨ì¼ QR ì½”ë“œ ì¶”ì  ì •ë³´"""
    def __init__(self, track_id, qr_data, frame_number):
        self.track_id = track_id
        self.qr_data = qr_data  # {'text': str, 'detection': dict, 'bbox': list, ...}
        self.frame_number = frame_number
        self.last_seen_frame = frame_number
        self.missed_frames = 0
        self.history = []  # ìœ„ì¹˜ ì´ë ¥ [(x1, y1, x2, y2), ...]
        
        # ìœ„ì¹˜ ì •ë³´ ì¶”ì¶œ
        center_x, center_y, x1, y1, x2, y2 = get_qr_center_and_bbox(qr_data)
        if center_x is not None:
            self.bbox = (x1, y1, x2, y2)
            self.center = (center_x, center_y)
            self.history.append(self.bbox)
        else:
            self.bbox = None
            self.center = None
    
    def update(self, qr_data, frame_number):
        """ì¶”ì  ì •ë³´ ì—…ë°ì´íŠ¸"""
        self.qr_data = qr_data
        self.frame_number = frame_number
        self.last_seen_frame = frame_number
        self.missed_frames = 0
        
        # ìœ„ì¹˜ ì •ë³´ ì—…ë°ì´íŠ¸
        center_x, center_y, x1, y1, x2, y2 = get_qr_center_and_bbox(qr_data)
        if center_x is not None:
            self.bbox = (x1, y1, x2, y2)
            self.center = (center_x, center_y)
            self.history.append(self.bbox)
            # ìµœê·¼ 10ê°œë§Œ ìœ ì§€
            if len(self.history) > 10:
                self.history.pop(0)
    
    def predict_position(self):
        """ì´ì „ ìœ„ì¹˜ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒ ìœ„ì¹˜ ì˜ˆì¸¡"""
        if self.bbox is None:
            return None
        
        if len(self.history) < 2:
            return self.bbox
        
        # ìµœê·¼ 2ê°œ ìœ„ì¹˜ë¡œ ì†ë„ ê³„ì‚°
        prev_bbox = self.history[-2]
        curr_bbox = self.history[-1]
        
        # ì†ë„ ê³„ì‚° (ì¤‘ì‹¬ì  ê¸°ì¤€)
        prev_center_x = (prev_bbox[0] + prev_bbox[2]) / 2
        prev_center_y = (prev_bbox[1] + prev_bbox[3]) / 2
        curr_center_x = (curr_bbox[0] + curr_bbox[2]) / 2
        curr_center_y = (curr_bbox[1] + curr_bbox[3]) / 2
        
        vx = curr_center_x - prev_center_x
        vy = curr_center_y - prev_center_y
        
        # missed_framesë¥¼ ê³ ë ¤í•˜ì—¬ ì˜ˆì¸¡
        frames_to_predict = self.missed_frames + 1
        predicted_center_x = curr_center_x + vx * frames_to_predict
        predicted_center_y = curr_center_y + vy * frames_to_predict
        
        # ë°•ìŠ¤ í¬ê¸° ìœ ì§€
        box_width = curr_bbox[2] - curr_bbox[0]
        box_height = curr_bbox[3] - curr_bbox[1]
        
        predicted_bbox = (
            int(predicted_center_x - box_width / 2),
            int(predicted_center_y - box_height / 2),
            int(predicted_center_x + box_width / 2),
            int(predicted_center_y + box_height / 2)
        )
        
        return predicted_bbox


class QRTracker:
    """QR ì½”ë“œ í”„ë ˆì„ ê°„ ì¶”ì  ê´€ë¦¬ì"""
    def __init__(self, max_missed_frames=5, iou_threshold=0.2, center_dist_threshold=0.8):
        self.tracks = {}  # {track_id: QRTrack}
        self.next_track_id = 0
        self.max_missed_frames = max_missed_frames
        self.iou_threshold = iou_threshold
        self.center_dist_threshold = center_dist_threshold
    
    def update(self, detected_qrs, frame_number):
        """íƒì§€ëœ QR ì½”ë“œë“¤ê³¼ ì¶”ì  ì¤‘ì¸ QR ì½”ë“œë“¤ì„ ë§¤ì¹­í•˜ì—¬ ì—…ë°ì´íŠ¸"""
        # 1. íƒì§€ëœ QR ì½”ë“œë“¤ì˜ bbox ì¶”ì¶œ
        detected_bboxes = []
        for qr in detected_qrs:
            center_x, center_y, x1, y1, x2, y2 = get_qr_center_and_bbox(qr)
            if center_x is not None:
                detected_bboxes.append({
                    'qr': qr,
                    'bbox': (x1, y1, x2, y2),
                    'center': (center_x, center_y)
                })
        
        # 2. í™œì„± ì¶”ì  ëª©ë¡
        active_tracks = {
            tid: track for tid, track in self.tracks.items()
            if track.missed_frames <= self.max_missed_frames
        }
        
        # 3. ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
        matched_detections = set()
        matched_tracks = set()
        match_scores = []
        
        for track_id, track in active_tracks.items():
            if track.bbox is None:
                continue
            
            # ì˜ˆì¸¡ ìœ„ì¹˜ ê³„ì‚°
            if track.missed_frames > 0:
                predicted_bbox = track.predict_position()
                if predicted_bbox is not None:
                    track_bbox = predicted_bbox
                else:
                    track_bbox = track.bbox
            else:
                track_bbox = track.bbox
            
            track_center = track.center
            track_text = track.qr_data.get('text', '')
            
            for idx, det in enumerate(detected_bboxes):
                # IoU ê³„ì‚°
                iou = calculate_iou(track_bbox, det['bbox'])
                
                # ì¤‘ì‹¬ì  ê±°ë¦¬ ê³„ì‚°
                center_dist = calculate_center_distance(track_bbox, det['bbox'])
                
                # í…ìŠ¤íŠ¸ ë§¤ì¹­ í™•ì¸
                det_text = det['qr'].get('text', '')
                text_match = (track_text != '' and det_text != '' and track_text == det_text)
                
                # ë™ì  ì„ê³„ê°’
                dynamic_iou_threshold = self.iou_threshold * (1.0 - track.missed_frames * 0.1)
                dynamic_iou_threshold = max(0.1, dynamic_iou_threshold)
                
                # ë§¤ì¹­ ì¡°ê±´
                if (iou >= dynamic_iou_threshold or 
                    center_dist <= self.center_dist_threshold or 
                    text_match):
                    
                    # ë³µí•© ì ìˆ˜ ê³„ì‚°
                    if text_match:
                        score = 1000.0 + iou * 100
                    else:
                        score = iou * 100 + (1.0 - center_dist) * 50
                    
                    match_scores.append((track_id, idx, score, iou, center_dist, text_match))
        
        # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
        match_scores.sort(key=lambda x: x[2], reverse=True)
        
        # ìµœì  ë§¤ì¹­ ìˆ˜í–‰
        for track_id, detection_idx, score, iou, center_dist, text_match in match_scores:
            if track_id in matched_tracks or detection_idx in matched_detections:
                continue
            
            # ë§¤ì¹­ ì„±ê³µ: ì¶”ì  ì—…ë°ì´íŠ¸
            track = active_tracks[track_id]
            det = detected_bboxes[detection_idx]
            
            # íƒì§€ëœ QR ì •ë³´ê°€ ë” ì •í™•í•˜ë©´ ì—…ë°ì´íŠ¸
            if not track.qr_data.get('text') or det['qr'].get('text'):
                track.update(det['qr'], frame_number)
            
            matched_detections.add(detection_idx)
            matched_tracks.add(track_id)
        
        # 4. ë§¤ì¹­ë˜ì§€ ì•Šì€ íƒì§€ëŠ” ìƒˆë¡œìš´ ì¶”ì  ìƒì„±
        for idx, det in enumerate(detected_bboxes):
            if idx not in matched_detections:
                track_id = self.next_track_id
                self.next_track_id += 1
                new_track = QRTrack(track_id, det['qr'], frame_number)
                self.tracks[track_id] = new_track
        
        # 5. ë§¤ì¹­ë˜ì§€ ì•Šì€ ì¶”ì ì€ missed_frames ì¦ê°€
        for track_id, track in active_tracks.items():
            if track_id not in matched_tracks:
                track.missed_frames += 1
                track.frame_number = frame_number
        
        # 6. ì¶”ì  ê²°ê³¼ ë°˜í™˜
        tracked_qrs = []
        
        # ë§¤ì¹­ëœ íƒì§€ ë° ìƒˆë¡œ ìƒì„±ëœ ì¶”ì 
        for idx, det in enumerate(detected_bboxes):
            if idx in matched_detections:
                # ë§¤ì¹­ëœ track_id ì°¾ê¸°
                track_id = None
                for tid, didx, _, _, _, _ in match_scores:
                    if didx == idx and tid in matched_tracks:
                        track_id = tid
                        break
                
                if track_id is not None:
                    qr = det['qr'].copy()
                    qr['track_id'] = track_id
                    qr['tracked'] = True
                    qr['predicted'] = False
                    tracked_qrs.append(qr)
            elif idx not in matched_detections:
                # ìƒˆë¡œ ìƒì„±ëœ ì¶”ì  (ì—¬ê¸°ì„œëŠ” ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ. 4ë‹¨ê³„ì—ì„œ ì´ë¯¸ tracksì— ì¶”ê°€ë¨)
                pass
        
        # ë§¤ì¹­ë˜ì§€ ì•Šì€ ì¶”ì  (ì˜ˆì¸¡ ìœ„ì¹˜ ì‚¬ìš©)
        for track_id, track in active_tracks.items():
            if track_id not in matched_tracks and track.missed_frames <= self.max_missed_frames:
                predicted_bbox = track.predict_position()
                if predicted_bbox is not None:
                    tracked_qr = track.qr_data.copy()
                    tracked_qr['track_id'] = track_id
                    tracked_qr['tracked'] = True
                    tracked_qr['predicted'] = True
                    tracked_qr['missed_frames'] = track.missed_frames
                    
                    # detectionì— ì˜ˆì¸¡ ìœ„ì¹˜ ì¶”ê°€
                    if 'bbox' not in tracked_qr:
                        tracked_qr['bbox'] = list(predicted_bbox)
                    
                    tracked_qrs.append(tracked_qr)
        
        # ìƒˆë¡œ ìƒì„±ëœ íŠ¸ë˜í‚¹ë„ ìµœì¢… ëª©ë¡ì— í¬í•¨
        newly_created_track_ids = [
            tid for tid in self.tracks 
            if self.tracks[tid].frame_number == frame_number and tid not in matched_tracks
        ]
        for tid in newly_created_track_ids:
            track = self.tracks[tid]
            tracked_qr = track.qr_data.copy()
            tracked_qr['track_id'] = tid
            tracked_qr['tracked'] = True
            tracked_qr['predicted'] = False
            tracked_qrs.append(tracked_qr)
        
        return tracked_qrs
    
    def get_active_track_count(self):
        """í™œì„± ì¶”ì  ê°œìˆ˜ ë°˜í™˜"""
        return len([t for t in self.tracks.values() if t.missed_frames <= self.max_missed_frames])


def test_model_info(model_path='l.pt'):
    """ëª¨ë¸ ì •ë³´ í™•ì¸"""
    print("=" * 60)
    print(f"ğŸ“¦ ëª¨ë¸ íŒŒì¼: {model_path}")
    print("=" * 60)
    
    if not os.path.exists(model_path):
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        return None
    
    file_size = os.path.getsize(model_path) / (1024 * 1024)  # MB
    print(f"ğŸ“Š íŒŒì¼ í¬ê¸°: {file_size:.2f} MB")
    
    # Ultralytics YOLO ëª¨ë¸ë¡œ ë¡œë“œ ì‹œë„
    if ULTRALYTICS_AVAILABLE:
        try:
            print("\nğŸ” Ultralytics YOLO ëª¨ë¸ë¡œ ë¡œë“œ ì‹œë„...")
            model = YOLO(model_path)
            
            print(f"âœ… ëª¨ë¸ íƒ€ì…: YOLO (Ultralytics)")
            print(f"ğŸ“‹ ëª¨ë¸ ì •ë³´:")
            print(f" Â  - Task: {model.task if hasattr(model, 'task') else 'Unknown'}")
            print(f" Â  - Classes: {len(model.names) if hasattr(model, 'names') else 'Unknown'}")
            
            if hasattr(model, 'names'):
                print(f" Â  - í´ë˜ìŠ¤ ëª©ë¡:")
                for idx, name in model.names.items():
                    print(f" Â  Â  [{idx}] {name}")
            
            if hasattr(model, 'model'):
                model_info = model.model
                print(f" Â  - ëª¨ë¸ êµ¬ì¡°: {type(model_info).__name__}")
            
            return model, 'yolo'
        except Exception as e:
            print(f"âŒ YOLO ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    # ì¼ë°˜ PyTorch ëª¨ë¸ë¡œ ë¡œë“œ ì‹œë„
    try:
        print("\nğŸ” PyTorch ëª¨ë¸ë¡œ ë¡œë“œ ì‹œë„...")
        checkpoint = torch.load(model_path, map_location='cpu')
        
        print(f"âœ… ëª¨ë¸ íƒ€ì…: PyTorch")
        print(f"ğŸ“‹ ì²´í¬í¬ì¸íŠ¸ í‚¤:")
        for key in checkpoint.keys():
            if isinstance(checkpoint[key], dict):
                print(f" Â  - {key}: (dict with {len(checkpoint[key])} keys)")
                if len(checkpoint[key].keys()) < 10:
                    for subkey in checkpoint[key].keys():
                        print(f" Â  Â  - {subkey}: {type(checkpoint[subkey]).__name__}")
            elif isinstance(checkpoint[key], (list, tuple)):
                print(f" Â  - {key}: ({type(checkpoint[key]).__name__} with {len(checkpoint[key])} items)")
            else:
                print(f" Â  - {key}: {type(checkpoint[key]).__name__}")
        
        return checkpoint, 'pytorch'
    except Exception as e:
        print(f"âŒ PyTorch ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None, None

def test_yolo_detection(model, image_path, conf_threshold=0.25):
    """YOLO ëª¨ë¸ë¡œ ì´ë¯¸ì§€ íƒì§€ í…ŒìŠ¤íŠ¸"""
    print(f"\nğŸ–¼ï¸ Â ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸: {os.path.basename(image_path)}")
    
    # ì´ë¯¸ì§€ ë¡œë“œ
    image = cv2.imread(image_path)
    if image is None:
        print(f"âŒ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
        return None
    
    print(f" Â  ì´ë¯¸ì§€ í¬ê¸°: {image.shape[1]}x{image.shape[0]}")
    
    # íƒì§€ ì‹¤í–‰
    try:
        results = model(image, conf=conf_threshold, verbose=False)
        result = results[0]
        
        print(f" Â  íƒì§€ëœ ê°ì²´ ìˆ˜: {len(result.boxes) if result.boxes is not None else 0}")
        
        detections = []
        if result.boxes is not None and len(result.boxes) > 0:
            for i, box in enumerate(result.boxes):
                cls = int(box.cls[0])
                conf = float(box.conf[0])
                xyxy = box.xyxy[0].cpu().numpy()
                
                class_name = result.names[cls] if hasattr(result, 'names') else f"Class_{cls}"
                
                detections.append({
                    'class': class_name,
                    'confidence': conf,
                    'bbox': xyxy,
                    'class_id': cls
                })
                
                print(f" Â  [{i+1}] {class_name}: {conf:.2%} at [{int(xyxy[0])}, {int(xyxy[1])}, {int(xyxy[2])}, {int(xyxy[3])}]")
        
        return {
            'image': image,
            'detections': detections,
            'result': result
        }
    except Exception as e:
        print(f"âŒ íƒì§€ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None

def visualize_results(image, detections, save_path=None):
    """íƒì§€ ê²°ê³¼ ì‹œê°í™”"""
    if detections is None or len(detections) == 0:
        print(" Â  âš ï¸ íƒì§€ëœ ê°ì²´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì´ë¯¸ì§€ ë³µì‚¬
    vis_image = image.copy()
    
    # BGR to RGB ë³€í™˜
    vis_image_rgb = cv2.cvtColor(vis_image, cv2.COLOR_BGR2RGB)
    
    # Matplotlibìœ¼ë¡œ ì‹œê°í™”
    fig, ax = plt.subplots(1, 1, figsize=(12, 8))
    ax.imshow(vis_image_rgb)
    
    # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
    for det in detections:
        bbox = det['bbox']
        x1, y1, x2, y2 = map(int, bbox)
        
        # ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        rect = Rectangle((x1, y1), x2-x1, y2-y1, 
                        linewidth=2, edgecolor='red', facecolor='none')
        ax.add_patch(rect)
        
        # ë¼ë²¨ ì¶”ê°€
        label = f"{det['class']}: {det['confidence']:.2%}"
        ax.text(x1, y1-5, label, color='red', fontsize=10, 
                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
    
    ax.axis('off')
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        print(f" Â  ğŸ’¾ ê²°ê³¼ ì €ì¥: {save_path}")
    
    plt.show()

def test_video_detection(model, video_path, conf_threshold=0.25, 
                        frame_interval=1, show_video=True, save_output=True,
                         process_scale=1.0, enable_decode=True, qreader=None,
                         use_qreader_detect=False, qreader_detect_interval=5,
                         use_tracking=True):
    """YOLO ëª¨ë¸ë¡œ ì˜ìƒ íƒì§€ í…ŒìŠ¤íŠ¸ (ì¶”ì  + ë¹„ë™ê¸° í•´ë… ìµœì í™” ë²„ì „)
    
    Args:
        model: YOLO ëª¨ë¸
        video_path: ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        conf_threshold: ì‹ ë¢°ë„ ì„ê³„ê°’
        frame_interval: íƒì§€ ê°„ê²© (1=ëª¨ë“  í”„ë ˆì„, 2=2í”„ë ˆì„ë§ˆë‹¤, 5=5í”„ë ˆì„ë§ˆë‹¤)
        show_video: í™”ë©´ í‘œì‹œ ì—¬ë¶€
        save_output: ê²°ê³¼ ì˜ìƒ ì €ì¥ ì—¬ë¶€
        process_scale: ì²˜ë¦¬ í•´ìƒë„ ìŠ¤ì¼€ì¼ (1.0=ì›ë³¸, 0.5=50%, 0.25=25%)
        enable_decode: í•´ë… ê¸°ëŠ¥ ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸: True)
        qreader: QReader ì¸ìŠ¤í„´ìŠ¤ (í•´ë… ì‚¬ìš© ì‹œ í•„ìš”, Noneì´ë©´ ìë™ ìƒì„±)
        use_qreader_detect: QReaderì˜ detect()ë¡œ ì •í™•í•œ QR ìœ„ì¹˜ íƒì§€ ì—¬ë¶€ (ê¸°ë³¸: False, ëŠë¦¼)
        qreader_detect_interval: QReader detect() ì‹¤í–‰ ê°„ê²© (Ní”„ë ˆì„ë§ˆë‹¤, ê¸°ë³¸: 5)
        use_tracking: í”„ë ˆì„ ê°„ ì¶”ì  ê¸°ëŠ¥ ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸: True, ëŠê¹€ ì—†ëŠ” ì‹œê°í™”)
    
    Note:
        - íƒì§€: ë™ê¸° ì²˜ë¦¬ (ë¹ ë¦„, ì›ë³¸ ì†ë„ ìœ ì§€)
        - í•´ë…: ë¹„ë™ê¸° ì²˜ë¦¬ (ëŠë¦¼, ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì²˜ë¦¬)
        - ì¶”ì : í”„ë ˆì„ ê°„ ì¶”ì ìœ¼ë¡œ ëŠê¹€ ì—†ëŠ” ì‹œê°í™”
        - ì¤‘ë³µ ì œê±°: IoU ê¸°ë°˜ (ìœ„ì¹˜ ê¸°ë°˜)
        - ì‹œê°í™”: í•´ë… ì„±ê³µ=ì´ˆë¡ìƒ‰, í•´ë… ì‹¤íŒ¨=ë¹¨ê°„ìƒ‰
    """
    print(f"\nğŸ¬ ì˜ìƒ í…ŒìŠ¤íŠ¸: {os.path.basename(video_path)}")
    print("=" * 60)
    
    # ë¹„ë””ì˜¤ íŒŒì¼ í™•ì¸
    if not os.path.exists(video_path):
        print(f"âŒ ì˜ìƒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
        return None
    
    # ë¹„ë””ì˜¤ ìº¡ì²˜
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"âŒ ì˜ìƒì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
        return None
    
    # ë¹„ë””ì˜¤ ì •ë³´
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    duration = total_frames / fps if fps > 0 else 0
    
    # ì²˜ë¦¬ í•´ìƒë„ ì„¤ì •
    process_width = int(width * process_scale)
    process_height = int(height * process_scale)
    scale_x = width / process_width if process_width > 0 else 1.0
    scale_y = height / process_height if process_height > 0 else 1.0
    
    print(f"ğŸ“¹ ì˜ìƒ ì •ë³´:")
    print(f" Â  ì›ë³¸ í•´ìƒë„: {width}x{height}")
    print(f" Â  ì²˜ë¦¬ í•´ìƒë„: {process_width}x{process_height} (ìŠ¤ì¼€ì¼: {process_scale*100:.0f}%)")
    print(f" Â  FPS: {fps:.2f}")
    print(f" Â  ì´ í”„ë ˆì„: {total_frames}")
    print(f" Â  ê¸¸ì´: {duration:.2f}ì´ˆ")
    print(f" Â  íƒì§€ ê°„ê²©: {frame_interval}í”„ë ˆì„ë§ˆë‹¤")
    
    # ì¶œë ¥ ì„¤ì •
    output_dir = Path('l_pt_test_results')
    output_dir.mkdir(exist_ok=True)
    
    video_output_path = None
    out_video = None
    if save_output:
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        video_output_path = output_dir / f"video_result_{timestamp}.mp4"
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out_video = cv2.VideoWriter(str(video_output_path), fourcc, fps, (width, height))
        print(f" Â  ì¶œë ¥ íŒŒì¼: {video_output_path}")
    
    # í†µê³„
    frame_count = 0
    detection_count = 0
    total_detections = 0
    detection_times = []
    detections_per_frame = []
    frame_processing_times = []  # ê° í”„ë ˆì„ ì²˜ë¦¬ ì‹œê°„ (íƒì§€ + ì‹œê°í™” ë“±)
    
    # ë§ˆì§€ë§‰ íƒì§€ ê²°ê³¼ ì €ì¥ (ë‹¤ìŒ íƒì§€ ì „ê¹Œì§€ í‘œì‹œ)
    last_detections = []
    last_qreader_detect_frame = 0  # QReader detect() ë§ˆì§€ë§‰ ì‹¤í–‰ í”„ë ˆì„
    
    # ë¡œê·¸ íŒŒì¼
    log_file_path = output_dir / f"video_log_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
    log_file = open(log_file_path, 'w', encoding='utf-8')
    
    def log_print(message):
        print(message)
        log_file.write(message + '\n')
        log_file.flush()
    
    # QReader ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (í•´ë…ìš©)
    if enable_decode and qreader is None and QREADER_AVAILABLE:
        try:
            qreader = QReader()
            log_print("âœ… QReader ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (í•´ë…ìš©)")
        except Exception as e:
            log_print(f"âš ï¸ QReader ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            enable_decode = False
    
    # QReader ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ì •í™•í•œ QR ìœ„ì¹˜ íƒì§€ìš©)
    qreader_detector = None
    if use_qreader_detect and QREADER_AVAILABLE:
        try:
            qreader_detector = QReader()
            log_print(f"âœ… QReader detect() í™œì„±í™” (ì •í™•í•œ QR ìœ„ì¹˜ íƒì§€, {qreader_detect_interval}í”„ë ˆì„ë§ˆë‹¤)")
            log_print(f" Â  âš ï¸ ì£¼ì˜: detect()ëŠ” ëŠë¦¬ë¯€ë¡œ ê°„ê²©ì„ ì¡°ì •í•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”.")
        except Exception as e:
            log_print(f"âš ï¸ QReader ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            qreader_detector = None
    elif use_qreader_detect and not QREADER_AVAILABLE:
        log_print("âš ï¸ QReaderë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°”ìš´ë”© ë°•ìŠ¤ë§Œ í‘œì‹œë©ë‹ˆë‹¤.")
    
    # ì¶”ì  ê¸°ëŠ¥ ì´ˆê¸°í™”
    qr_tracker = None
    if use_tracking:
        qr_tracker = QRTracker(max_missed_frames=5, iou_threshold=0.2, center_dist_threshold=0.8)
        log_print("âœ… ì¶”ì  ê¸°ëŠ¥ í™œì„±í™” (ëŠê¹€ ì—†ëŠ” ì‹œê°í™”)")
    
    log_print(f"ì˜ìƒ í…ŒìŠ¤íŠ¸ ì‹œì‘: {video_path}")
    log_print(f"ì„¤ì •: conf_threshold={conf_threshold}, frame_interval={frame_interval}, process_scale={process_scale}")
    log_print(f"í•´ìƒë„: ì›ë³¸ {width}x{height} â†’ ì²˜ë¦¬ {process_width}x{process_height}")
    log_print(f"ëª¨ë“œ: ë™ê¸° íƒì§€ ì²˜ë¦¬ (ìµœì í™”)")
    if enable_decode:
        log_print(f"í•´ë…: ë¹„ë™ê¸° ì²˜ë¦¬ í™œì„±í™”")
    log_print("-" * 60)
    
    # â˜…â˜…â˜…â˜…â˜… í•´ë…ìš© ë¹„ë™ê¸° ì²˜ë¦¬ ì„¤ì • â˜…â˜…â˜…â˜…â˜…
    decode_queue = None
    decode_results = {}  # {track_id: {'text': str, 'frame': int, 'quad_xy': list, 'decode_bbox': list}} - í•´ë… ê²°ê³¼ ì €ì¥
    decode_worker_thread = None
    stop_decode_worker = None
    
    if enable_decode and qreader is not None:
        decode_queue = Queue(maxsize=10)
        stop_decode_worker = threading.Event()
        decode_lock = threading.Lock()
        
        def decode_worker():
            """ë°±ê·¸ë¼ìš´ë“œì—ì„œ í•´ë… ìˆ˜í–‰í•˜ëŠ” ì›Œì»¤ ìŠ¤ë ˆë“œ"""
            # ì™¸ë¶€ ë³€ìˆ˜ frame_countë¥¼ ì°¸ì¡°í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ, ì´ˆê¸° ë¡œê·¸ë¥¼ ìœ„í•œ ì„ì‹œ track_id ë³€ìˆ˜ ì‚¬ìš©
            log_count = 0 
            
            while not stop_decode_worker.is_set():
                try:
                    item = decode_queue.get(timeout=0.1)
                    if item is None:
                        # íì— Noneì´ ë“¤ì–´ì˜¤ë©´ ìŠ¤ë ˆë“œ ì¢…ë£Œ
                        return 
                
                    track_id, roi, bbox, roi_offset = item  # roi_offset ì¶”ê°€: (roi_x1, roi_y1)
                    try:
                        # QReaderë¡œ í•´ë… ì‹œë„ (detect() ë¨¼ì € í˜¸ì¶œí•˜ì—¬ ì„±ê³µë¥  í–¥ìƒ)
                        decoded_text = None
                        quad_xy = None
                        detections = qreader.detect(roi)
                        
                        if detections and len(detections) > 0:
                            # detect()ë¡œ ì°¾ì€ íŒíŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ decode()
                            detection = detections[0]
                            decoded_text = qreader.decode(roi, detection)
                            
                            # quad_xy ì¶”ì¶œ (ROI ë‚´ ìƒëŒ€ ì¢Œí‘œ)
                            if 'quad_xy' in detection:
                                quad_xy_roi = detection['quad_xy']
                                if len(quad_xy_roi) == 4:
                                    # ROI ë‚´ ìƒëŒ€ ì¢Œí‘œë¥¼ ì›ë³¸ ì´ë¯¸ì§€ ì ˆëŒ€ ì¢Œí‘œë¡œ ë³€í™˜
                                    roi_x1, roi_y1 = roi_offset
                                    quad_xy = []
                                    for qx, qy in quad_xy_roi:
                                        abs_x = roi_x1 + int(qx)
                                        abs_y = roi_y1 + int(qy)
                                        quad_xy.append([abs_x, abs_y])
                            else:
                                # detect() ì‹¤íŒ¨ ì‹œ ì§ì ‘ decode() ì‹œë„
                                decoded_text = qreader.decode(roi)
                            
                            if decoded_text:
                                with decode_lock:
                                    decode_results[track_id] = {
                                        'text': decoded_text,
                                        # 'frame': frame_count, # ì™¸ë¶€ ë³€ìˆ˜ ì°¸ì¡° ë¶ˆê°€
                                        'quad_xy': quad_xy,  # ì •í™•í•œ QR ìœ„ì¹˜ (4ê°œ ê¼­ì§“ì )
                                        'decode_bbox': list(bbox)  # í•´ë… ì‹œì ì˜ bbox (ìœ„ì¹˜ ë³€í™˜ìš©)
                                    }
                                # ë””ë²„ê¹…: í•´ë… ì„±ê³µ ë¡œê·¸ (ì²˜ìŒ ëª‡ ê°œë§Œ)
                                if log_count < 10:
                                    log_print(f"âœ… í•´ë… ì„±ê³µ [T{track_id}]: {decoded_text[:50]}")
                                    log_count += 1
                        
                    except Exception as e:
                        # í•´ë… ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ (ë„ˆë¬´ ë§ì€ ë¡œê·¸ ë°©ì§€)
                        # ì²˜ìŒ ëª‡ ê°œë§Œ ë¡œê·¸ ì¶œë ¥
                        if log_count < 3 and track_id <= 3:
                            log_print(f"âš ï¸ í•´ë… ì‹¤íŒ¨ [T{track_id}]: {str(e)[:50]}")
                            log_count += 1
                        pass
                    
                    decode_queue.task_done()
                except Empty:
                    continue
                except Exception as e:
                    log_print(f"í•´ë… ì›Œì»¤ ì˜¤ë¥˜: {e}")
                    # itemì´ ì •ì˜ë˜ì—ˆê³  Noneì´ ì•„ë‹ˆë©°, íì— ë“¤ì–´ìˆëŠ” ì‘ì—…ì´ë¼ë©´ task_done í˜¸ì¶œ
                    if 'item' in locals() and item:
                        decode_queue.task_done()
        
        decode_worker_thread = threading.Thread(target=decode_worker, daemon=True)
        decode_worker_thread.start()
        log_print("âœ… í•´ë… ì›Œì»¤ ìŠ¤ë ˆë“œ ì‹œì‘")
    
    print(f"\nâ–¶ï¸ Â ì˜ìƒ ì²˜ë¦¬ ì‹œì‘... (ë™ê¸° íƒì§€ + {'ë¹„ë™ê¸° í•´ë…' if enable_decode else 'í•´ë… ì—†ìŒ'})")
    start_time = time.time()
    last_detection_frame = 0
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_count += 1
            current_time = frame_count / fps if fps > 0 else 0
            
            # í”„ë ˆì„ ì²˜ë¦¬ ì‹œì‘ ì‹œê°„
            frame_start_time = time.time()
            
            # â˜…â˜…â˜…â˜…â˜… ë™ê¸° íƒì§€ ì²˜ë¦¬ (ë¹ ë¦„) â˜…â˜…â˜…â˜…â˜…
            should_detect = (frame_count - last_detection_frame) >= frame_interval or frame_count == 1
            
            if should_detect:
                # ì²˜ë¦¬ìš© í•´ìƒë„ë¡œ ì¶•ì†Œ
                if process_scale < 1.0:
                    process_frame = cv2.resize(frame, (process_width, process_height), interpolation=cv2.INTER_LINEAR)
                else:
                    process_frame = frame
                
                # YOLO íƒì§€ ìˆ˜í–‰ (ë™ê¸°)
                detect_start = time.time()
                results = model(process_frame, conf=conf_threshold, verbose=False)
                detect_time = time.time() - detect_start
                detection_times.append(detect_time)
                
                result = results[0]
                detections = []
                
                if result.boxes is not None and len(result.boxes) > 0:
                    for box in result.boxes:
                        cls = int(box.cls[0])
                        conf = float(box.conf[0])
                        xyxy = box.xyxy[0].cpu().numpy()
                        
                        # ì›ë³¸ í•´ìƒë„ ì¢Œí‘œë¡œ ë³€í™˜
                        if process_scale < 1.0:
                            xyxy = [
                                xyxy[0] * scale_x,
                                xyxy[1] * scale_y,
                                xyxy[2] * scale_x,
                                xyxy[3] * scale_y
                            ]
                        
                        # â˜…â˜…â˜…â˜…â˜… íŒ¨ë”© ì¶”ê°€ (video_synch.pyì™€ ë™ì¼í•˜ê²Œ) â˜…â˜…â˜…â˜…â˜…
                        # íŒ¨ë”©ì„ ì²˜ìŒë¶€í„° ì¶”ê°€í•˜ì—¬ ë” ì •í™•í•œ ROI í™•ë³´
                        pad = 20  # video_synch.pyì™€ ë™ì¼í•œ íŒ¨ë”© í¬ê¸°
                        x1, y1, x2, y2 = xyxy
                        h, w = frame.shape[:2]
                        x1 = max(0, int(x1 - pad))
                        y1 = max(0, int(y1 - pad))
                        x2 = min(w, int(x2 + pad))
                        y2 = min(h, int(y2 + pad))
                        xyxy = [x1, y1, x2, y2]
                        
                        class_name = result.names[cls] if hasattr(result, 'names') else f"Class_{cls}"
                        
                        detections.append({
                            'class': class_name,
                            'confidence': conf,
                            'bbox': xyxy,
                            'class_id': cls
                        })
                
                    # â˜…â˜…â˜…â˜…â˜… IoU ê¸°ë°˜ ì¤‘ë³µ ì œê±° â˜…â˜…â˜…â˜…â˜…
                    filtered_detections = filter_overlapping_detections(detections, iou_threshold=0.5)
                    
                    if len(detections) > len(filtered_detections):
                        log_print(f" Â  Â âš¡ ì¤‘ë³µ ì œê±°: {len(detections)}ê°œ â†’ {len(filtered_detections)}ê°œ")
                    
                    # â˜…â˜…â˜…â˜…â˜… QReader detect()ë¡œ ì •í™•í•œ QR ìœ„ì¹˜ íƒì§€ (quad_xy) â˜…â˜…â˜…â˜…â˜…
                    # ì„±ëŠ¥ ìµœì í™”: ì¼ì • ê°„ê²©ìœ¼ë¡œë§Œ ì‹¤í–‰ (ê¸°ë³¸: 5í”„ë ˆì„ë§ˆë‹¤)
                    should_run_qreader_detect = (
                        qreader_detector is not None and 
                        filtered_detections and
                        (frame_count - last_qreader_detect_frame) >= qreader_detect_interval
                    )
                    
                    if should_run_qreader_detect:
                        for det in filtered_detections:
                            x1, y1, x2, y2 = map(int, det['bbox'])
                            # ROI ì¶”ì¶œ (ì´ë¯¸ íŒ¨ë”©ì´ í¬í•¨ëœ bboxì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©)
                            roi = frame[y1:y2, x1:x2]
                            
                            if roi.size > 0:
                                try:
                                    # QReaderì˜ detect()ë¡œ ì •í™•í•œ ìœ„ì¹˜ ì°¾ê¸°
                                    qr_detections = qreader_detector.detect(roi)
                                    if qr_detections and len(qr_detections) > 0:
                                        detection = qr_detections[0]
                                        if 'quad_xy' in detection:
                                            # ROI ë‚´ ìƒëŒ€ ì¢Œí‘œë¥¼ ì›ë³¸ ì´ë¯¸ì§€ ì ˆëŒ€ ì¢Œí‘œë¡œ ë³€í™˜
                                            # video_synch.pyì™€ ë™ì¼: íŒ¨ë”©ì´ í¬í•¨ëœ bbox ì¢Œí‘œ ì‚¬ìš©
                                            quad_xy = []
                                            for qx, qy in detection['quad_xy']:
                                                abs_x = x1 + int(qx)
                                                abs_y = y1 + int(qy)
                                                quad_xy.append([abs_x, abs_y])
                                            det['quad_xy'] = quad_xy
                                except Exception as e:
                                    # detect ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ (ë°”ìš´ë”© ë°•ìŠ¤ë§Œ ì‚¬ìš©)
                                    pass
                        last_qreader_detect_frame = frame_count
                    
                    # í†µê³„ ì—…ë°ì´íŠ¸
                    if filtered_detections:
                        frame_detections_count = len(filtered_detections)
                        detections_per_frame.append(frame_detections_count)
                        detection_count += 1
                    total_detections += len(filtered_detections)
                    
                    # ë¡œê·¸ ì¶œë ¥
                    if filtered_detections:
                        log_print(f"í”„ë ˆì„ {frame_count} ({current_time:.2f}ì´ˆ): {frame_detections_count}ê°œ íƒì§€")
                        for i, det in enumerate(filtered_detections):
                            log_print(f" Â [{i+1}] {det['class']}: {det['confidence']:.2%} "
                                        f"at [{int(det['bbox'][0])}, {int(det['bbox'][1])}, "
                                        f"{int(det['bbox'][2])}, {int(det['bbox'][3])}]")
                    
                    # â˜…â˜…â˜…â˜…â˜… ì¶”ì  ê¸°ëŠ¥ ì ìš© â˜…â˜…â˜…â˜…â˜…
                    if use_tracking and qr_tracker is not None:
                        # íƒì§€ ê²°ê³¼ë¥¼ ì¶”ì  í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                        tracked_qr_list = []
                        for det in filtered_detections:
                            qr_data = {
                                'bbox': det['bbox'],
                                'quad_xy': det.get('quad_xy'), # QReader detect ê²°ê³¼ ì „ë‹¬
                                'text': '',  # ì•„ì§ í•´ë… ì•ˆë¨
                                'detection': {
                                    'bbox_xyxy': det['bbox'],
                                    'quad_xy': det.get('quad_xy')  # detectionì—ë„ quad_xy í¬í•¨ (ì¶”ì ì— ìœ ì§€)
                                }
                            }
                            tracked_qr_list.append(qr_data)
                        
                        # ì¶”ì  ì—…ë°ì´íŠ¸
                        tracked_qrs = qr_tracker.update(tracked_qr_list, frame_count)
                        
                        # í•´ë… íì— ì¶”ê°€ (ë¹„ë™ê¸° í•´ë…)
                        if enable_decode and decode_queue is not None:
                            for tracked_qr in tracked_qrs:
                                track_id = tracked_qr.get('track_id')
                                if track_id is not None:
                                    # ì´ë¯¸ í•´ë…ëœ ê²ƒì€ ìŠ¤í‚µ (í•˜ì§€ë§Œ quad_xyëŠ” ì—…ë°ì´íŠ¸)
                                    with decode_lock:
                                        if track_id in decode_results:
                                            decode_result = decode_results[track_id]
                                            tracked_qr['text'] = decode_result['text']
                                            
                                            # quad_xyê°€ ìˆìœ¼ë©´ ì¶”ì  ìœ„ì¹˜ì— ë§ì¶°ì„œ ë³€í™˜
                                            if 'quad_xy' in decode_result and decode_result['quad_xy'] is not None:
                                                current_bbox = tracked_qr.get('bbox', tracked_qr.get('detection', {}).get('bbox_xyxy'))
                                                decode_bbox = decode_result.get('decode_bbox')
                                                
                                                if current_bbox is not None and len(current_bbox) == 4 and \
                                                   decode_bbox is not None and len(decode_bbox) == 4:
                                                    # í•´ë… ì‹œì ì˜ bboxì™€ í˜„ì¬ ì¶”ì  bboxì˜ ì°¨ì´ ê³„ì‚°
                                                    decode_x1, decode_y1, decode_x2, decode_y2 = decode_bbox
                                                    curr_x1, curr_y1, curr_x2, curr_y2 = map(int, current_bbox)
                                                    
                                                    # ì¤‘ì‹¬ì  ì´ë™ëŸ‰ ê³„ì‚°
                                                    decode_cx = (decode_x1 + decode_x2) / 2
                                                    decode_cy = (decode_y1 + decode_y2) / 2
                                                    curr_cx = (curr_x1 + curr_x2) / 2
                                                    curr_cy = (curr_y1 + curr_y2) / 2
                                                    
                                                    dx = curr_cx - decode_cx
                                                    dy = curr_cy - decode_cy
                                                    
                                                    # quad_xyë¥¼ í˜„ì¬ ì¶”ì  ìœ„ì¹˜ì— ë§ì¶°ì„œ ì´ë™
                                                    quad_xy_original = decode_result['quad_xy']
                                                    quad_xy_transformed = []
                                                    for qx, qy in quad_xy_original:
                                                        quad_xy_transformed.append([int(qx + dx), int(qy + dy)])
                                                    tracked_qr['quad_xy'] = quad_xy_transformed
                                                else:
                                                    # bbox ì •ë³´ê°€ ì—†ìœ¼ë©´ ì›ë³¸ quad_xy ì‚¬ìš©
                                                    tracked_qr['quad_xy'] = decode_result['quad_xy']
                                            continue # ì´ë¯¸ í•´ë…ëœ ê²ƒì€ íì— ë‹¤ì‹œ ë„£ì§€ ì•ŠìŒ
                                    
                                    # ROI ì¶”ì¶œí•˜ì—¬ í•´ë… íì— ì¶”ê°€
                                    bbox = tracked_qr.get('bbox', tracked_qr.get('detection', {}).get('bbox_xyxy'))
                                    if bbox is not None and len(bbox) == 4:
                                        x1, y1, x2, y2 = map(int, bbox)
                                        # ì´ë¯¸ íŒ¨ë”©ì´ í¬í•¨ëœ bboxì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš© (video_synch.pyì™€ ë™ì¼)
                                        roi = frame[y1:y2, x1:x2]
                                        if roi.size > 0:
                                            try:
                                                # ROI ì˜¤í”„ì…‹ ì •ë³´ë„ í•¨ê»˜ ì „ë‹¬ (quad_xy ì¢Œí‘œ ë³€í™˜ìš©)
                                                # video_synch.pyì™€ ë™ì¼: íŒ¨ë”©ì´ í¬í•¨ëœ bbox ì¢Œí‘œ ì‚¬ìš©
                                                decode_queue.put_nowait((track_id, roi, bbox, (x1, y1)))
                                                # ë””ë²„ê¹…: í ì¶”ê°€ ë¡œê·¸ (ì²˜ìŒ ëª‡ ê°œë§Œ)
                                                if track_id <= 3 and len(decode_results) < 5:
                                                    log_print(f"ğŸ“¤ í•´ë… í ì¶”ê°€ [T{track_id}] (ROI í¬ê¸°: {roi.shape})")
                                            except:
                                                # íê°€ ê°€ë“ ì°¨ë©´ ìŠ¤í‚µ
                                                if track_id <= 3 and len(decode_results) < 5:
                                                    log_print(f"âš ï¸ í•´ë… í ê°€ë“ì°¸ [T{track_id}]")
                                                pass
                        
                        last_detections = tracked_qrs
                    else:
                        # ì¶”ì  ì—†ì´ íƒì§€ ê²°ê³¼ë§Œ ì‚¬ìš©
                        last_detections = filtered_detections.copy()
                
                last_detection_frame = frame_count
            else:
                # íƒì§€í•˜ì§€ ì•ŠëŠ” í”„ë ˆì„: ì¶”ì  ê²°ê³¼ ì‚¬ìš©
                if use_tracking and qr_tracker is not None:
                    # ì¶”ì ë§Œ ì‚¬ìš© (íƒì§€ ì—†ì´)
                    tracked_qrs = []
                    for track_id, track in qr_tracker.tracks.items():
                        if track.missed_frames <= qr_tracker.max_missed_frames:
                            predicted_bbox = track.predict_position()
                            if predicted_bbox is not None:
                                tracked_qr = track.qr_data.copy()
                                tracked_qr['track_id'] = track_id
                                tracked_qr['tracked'] = True
                                tracked_qr['predicted'] = True
                                tracked_qr['bbox'] = list(predicted_bbox)
                                
                                # í•´ë… ê²°ê³¼ í™•ì¸
                                if enable_decode:
                                    with decode_lock:
                                        if track_id in decode_results:
                                            decode_result = decode_results[track_id]
                                            tracked_qr['text'] = decode_result['text']
                                            
                                            # quad_xy ìš°ì„ ìˆœìœ„: íƒì§€ í”„ë ˆì„ì˜ quad_xy > í•´ë… ê²°ê³¼ì˜ quad_xy
                                            # íƒì§€ í”„ë ˆì„ì—ì„œ ì–»ì€ ì •í™•í•œ quad_xyê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
                                            if 'quad_xy' not in tracked_qr or tracked_qr.get('quad_xy') is None:
                                                # íƒì§€ í”„ë ˆì„ì˜ quad_xyê°€ ì—†ì„ ë•Œë§Œ í•´ë… ê²°ê³¼ì˜ quad_xy ì‚¬ìš©
                                                if 'quad_xy' in decode_result and decode_result['quad_xy'] is not None:
                                                    current_bbox = tracked_qr.get('bbox')
                                                    decode_bbox = decode_result.get('decode_bbox')
                                                    
                                                    if current_bbox is not None and len(current_bbox) == 4 and \
                                                       decode_bbox is not None and len(decode_bbox) == 4:
                                                        # í•´ë… ì‹œì ì˜ bboxì™€ í˜„ì¬ ì¶”ì  bboxì˜ ì°¨ì´ ê³„ì‚°
                                                        decode_x1, decode_y1, decode_x2, decode_y2 = decode_bbox
                                                        curr_x1, curr_y1, curr_x2, curr_y2 = map(int, current_bbox)
                                                        
                                                        # ì¤‘ì‹¬ì  ì´ë™ëŸ‰ ê³„ì‚°
                                                        decode_cx = (decode_x1 + decode_x2) / 2
                                                        decode_cy = (decode_y1 + decode_y2) / 2
                                                        curr_cx = (curr_x1 + curr_x2) / 2
                                                        curr_cy = (curr_y1 + curr_y2) / 2
                                                        
                                                        dx = curr_cx - decode_cx
                                                        dy = curr_cy - decode_cy
                                                        
                                                        # quad_xyë¥¼ í˜„ì¬ ì¶”ì  ìœ„ì¹˜ì— ë§ì¶°ì„œ ì´ë™
                                                        quad_xy_original = decode_result['quad_xy']
                                                        quad_xy_transformed = []
                                                        for qx, qy in quad_xy_original:
                                                            quad_xy_transformed.append([int(qx + dx), int(qy + dy)])
                                                        tracked_qr['quad_xy'] = quad_xy_transformed
                                                    else:
                                                        # bbox ì •ë³´ê°€ ì—†ìœ¼ë©´ ì›ë³¸ quad_xy ì‚¬ìš©
                                                        tracked_qr['quad_xy'] = decode_result['quad_xy']
                                            continue # ì´ë¯¸ í•´ë…ëœ ê²ƒì€ íì— ë‹¤ì‹œ ë„£ì§€ ì•ŠìŒ
                                    
                                    # ROI ì¶”ì¶œí•˜ì—¬ í•´ë… íì— ì¶”ê°€
                                    bbox = tracked_qr.get('bbox', tracked_qr.get('detection', {}).get('bbox_xyxy'))
                                    if bbox is not None and len(bbox) == 4:
                                        x1, y1, x2, y2 = map(int, bbox)
                                        # ì´ë¯¸ íŒ¨ë”©ì´ í¬í•¨ëœ bboxì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš© (video_synch.pyì™€ ë™ì¼)
                                        roi = frame[y1:y2, x1:x2]
                                        if roi.size > 0:
                                            try:
                                                # ROI ì˜¤í”„ì…‹ ì •ë³´ë„ í•¨ê»˜ ì „ë‹¬ (quad_xy ì¢Œí‘œ ë³€í™˜ìš©)
                                                # video_synch.pyì™€ ë™ì¼: íŒ¨ë”©ì´ í¬í•¨ëœ bbox ì¢Œí‘œ ì‚¬ìš©
                                                decode_queue.put_nowait((track_id, roi, bbox, (x1, y1)))
                                                # ë””ë²„ê¹…: í ì¶”ê°€ ë¡œê·¸ (ì²˜ìŒ ëª‡ ê°œë§Œ)
                                                if track_id <= 3 and len(decode_results) < 5:
                                                    log_print(f"ğŸ“¤ í•´ë… í ì¶”ê°€ [T{track_id}] (ROI í¬ê¸°: {roi.shape})")
                                            except:
                                                # íê°€ ê°€ë“ ì°¨ë©´ ìŠ¤í‚µ
                                                if track_id <= 3 and len(decode_results) < 5:
                                                    log_print(f"âš ï¸ í•´ë… í ê°€ë“ì°¸ [T{track_id}]")
                                                pass
                                
                                tracked_qrs.append(tracked_qr)
                    last_detections = tracked_qrs
            
            # ê²°ê³¼ ì‹œê°í™” (ìµœì‹  íƒì§€ ê²°ê³¼ ì‚¬ìš©)
            vis_frame = frame.copy()
            
            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° (í•´ë… ì„±ê³µ=ì´ˆë¡ìƒ‰, ì‹¤íŒ¨=ë¹¨ê°„ìƒ‰)
            display_detections = last_detections
            for det in display_detections:
                # í•´ë… ìƒíƒœ í™•ì¸ (ìµœì‹  í•´ë… ê²°ê³¼ í™•ì¸)
                track_id = det.get('track_id', None)
                has_text = det.get('text', '') != ''
                
                # í•´ë…ì´ í™œì„±í™”ë˜ì–´ ìˆê³  track_idê°€ ìˆìœ¼ë©´ ìµœì‹  í•´ë… ê²°ê³¼ í™•ì¸
                if enable_decode and track_id is not None and decode_results is not None:
                    with decode_lock:
                        if track_id in decode_results:
                            decode_result = decode_results[track_id]
                            det['text'] = decode_result['text']
                            has_text = True
                            
                            # quad_xy ìš°ì„ ìˆœìœ„: íƒì§€ í”„ë ˆì„ì˜ quad_xy > í•´ë… ê²°ê³¼ì˜ quad_xy
                            # íƒì§€ í”„ë ˆì„ì—ì„œ ì–»ì€ ì •í™•í•œ quad_xyê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
                            if 'quad_xy' not in det or det.get('quad_xy') is None:
                                # íƒì§€ í”„ë ˆì„ì˜ quad_xyê°€ ì—†ì„ ë•Œë§Œ í•´ë… ê²°ê³¼ì˜ quad_xy ì‚¬ìš©
                                if 'quad_xy' in decode_result and decode_result['quad_xy'] is not None:
                                    current_bbox = det.get('bbox', det.get('detection', {}).get('bbox_xyxy'))
                                    decode_bbox = decode_result.get('decode_bbox')
                                    
                                    if current_bbox is not None and len(current_bbox) == 4 and \
                                       decode_bbox is not None and len(decode_bbox) == 4:
                                        # í•´ë… ì‹œì ì˜ bboxì™€ í˜„ì¬ ì¶”ì  bboxì˜ ì°¨ì´ ê³„ì‚°
                                        decode_x1, decode_y1, decode_x2, decode_y2 = decode_bbox
                                        curr_x1, curr_y1, curr_x2, curr_y2 = map(int, current_bbox)
                                        
                                        # ì¤‘ì‹¬ì  ì´ë™ëŸ‰ ê³„ì‚°
                                        decode_cx = (decode_x1 + decode_x2) / 2
                                        decode_cy = (decode_y1 + decode_y2) / 2
                                        curr_cx = (curr_x1 + curr_x2) / 2
                                        curr_cy = (curr_y1 + curr_y2) / 2
                                        
                                        dx = curr_cx - decode_cx
                                        dy = curr_cy - decode_cy
                                        
                                        # quad_xyë¥¼ í˜„ì¬ ì¶”ì  ìœ„ì¹˜ì— ë§ì¶°ì„œ ì´ë™
                                        quad_xy_original = decode_result['quad_xy']
                                        quad_xy_transformed = []
                                        for qx, qy in quad_xy_original:
                                            quad_xy_transformed.append([int(qx + dx), int(qy + dy)])
                                        det['quad_xy'] = quad_xy_transformed
                                    else:
                                        # bbox ì •ë³´ê°€ ì—†ìœ¼ë©´ ì›ë³¸ quad_xy ì‚¬ìš©
                                        det['quad_xy'] = decode_result['quad_xy']
                
                is_predicted = det.get('predicted', False)
                
                # ìƒ‰ìƒ ê²°ì •: í•´ë… ì„±ê³µ=ì´ˆë¡ìƒ‰, ì‹¤íŒ¨=ë¹¨ê°„ìƒ‰
                if has_text:
                    box_color = (0, 255, 0)  # ì´ˆë¡ìƒ‰ (BGR)
                    text_color = (0, 0, 0)  # ê²€ì€ìƒ‰
                else:
                    box_color = (0, 0, 255)  # ë¹¨ê°„ìƒ‰ (BGR)
                    text_color = (255, 255, 255)  # í°ìƒ‰
                
                # ì˜ˆì¸¡ ìœ„ì¹˜ëŠ” ì ì„ ìœ¼ë¡œ í‘œì‹œ
                line_type = cv2.LINE_AA
                thickness = 2
                
                # quad_xyê°€ ìˆìœ¼ë©´ ì •í™•í•œ 4ê°œ ê¼­ì§“ì ìœ¼ë¡œ ê·¸ë¦¬ê¸°
                if 'quad_xy' in det and det['quad_xy'] is not None:
                    quad_xy = det['quad_xy']
                    if len(quad_xy) == 4:
                        points = np.array(quad_xy, dtype=np.int32)
                        if is_predicted:
                            # ì ì„  íš¨ê³¼ (ê°„ê²©ì„ ë‘ê³  ì„  ê·¸ë¦¬ê¸°)
                            for i in range(4):
                                p1 = tuple(points[i])
                                p2 = tuple(points[(i+1)%4])
                                # ê°„ë‹¨í•œ ì ì„ ì€ êµ¬í˜„ì´ ë³µì¡í•˜ë¯€ë¡œ, ì¼ë‹¨ì€ ì‹¤ì„ ìœ¼ë¡œ í‘œì‹œ (ë‘ê»˜ë¥¼ ì–‡ê²Œ)
                                cv2.line(vis_frame, p1, p2, box_color, 1, line_type) 
                        else:
                            cv2.polylines(vis_frame, [points], True, box_color, thickness, line_type)
                        
                        # ë¼ë²¨ ìœ„ì¹˜ëŠ” ì¢Œì¸¡ ìƒë‹¨ ê¼­ì§“ì 
                        label_x, label_y = int(quad_xy[0][0]), int(quad_xy[0][1])
                    else:
                        # quad_xyê°€ ì˜ëª»ë˜ì—ˆìœ¼ë©´ bbox ì‚¬ìš©
                        bbox = det.get('bbox', det.get('detection', {}).get('bbox_xyxy', []))
                        if bbox is not None and len(bbox) == 4:
                            x1, y1, x2, y2 = map(int, bbox)
                            cv2.rectangle(vis_frame, (x1, y1), (x2, y2), box_color, thickness, line_type)
                            label_x, label_y = x1, y1
                        else:
                            continue
                else:
                    # ë°”ìš´ë”© ë°•ìŠ¤ ì‚¬ìš©
                    bbox = det.get('bbox', det.get('detection', {}).get('bbox_xyxy', []))
                    if bbox is not None and len(bbox) == 4:
                        x1, y1, x2, y2 = map(int, bbox)
                        cv2.rectangle(vis_frame, (x1, y1), (x2, y2), box_color, thickness, line_type)
                        label_x, label_y = x1, y1
                    else:
                        continue
                
                # ë¼ë²¨ êµ¬ì„±
                label_parts = []
                if track_id is not None:
                    label_parts.append(f"T{track_id}")
                if is_predicted:
                    label_parts.append("P")
                if has_text:
                    text = det['text']
                    # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°
                    if len(text) > 30:
                        text = text[:27] + "..."
                    # OpenCV putTextì—ì„œ ë¬¸ì œê°€ ë˜ëŠ” íŠ¹ìˆ˜ ë¬¸ìë“¤ì„ í‘œì¤€ í•˜ì´í”ˆìœ¼ë¡œ ë³€ê²½
                    text = text.replace('â€“', '-').replace('â€”', '-').replace('âˆ’', '-')
                    text = text.replace('ï¼Ÿ', '?').replace('ï¼', '!').replace('ï¼Œ', ',')
                    label_parts.append(text)
                else:
                    conf = det.get('confidence', 0)
                    class_name = det.get('class', 'QR')
                    if conf > 0:
                        label_parts.append(f"{class_name} {conf:.1%}")
                    else:
                        label_parts.append(f"{class_name} (ë¯¸í•´ë…)")
                
                label = " | ".join(label_parts)
                font_scale = 0.6
                label_size, baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, font_scale, 2)
                
                # ë¼ë²¨ ë°°ê²½
                # ë¼ë²¨ì´ ìœ„ë¡œ íŠ€ì–´ë‚˜ê°€ì§€ ì•Šë„ë¡ y ì¢Œí‘œ ì¡°ì •
                label_rect_y1 = max(0, label_y - label_size[1] - 10)
                label_rect_y2 = label_y
                label_text_y = label_y - 5
                
                cv2.rectangle(vis_frame, (label_x, label_rect_y1), 
                              (label_x + label_size[0] + 5, label_rect_y2), box_color, -1)
                cv2.putText(vis_frame, label, (label_x, label_text_y), 
                            cv2.FONT_HERSHEY_SIMPLEX, font_scale, text_color, 2)
            
            # í”„ë ˆì„ ì •ë³´ í‘œì‹œ
            info_text = f"Frame: {frame_count}/{total_frames} | Time: {current_time:.1f}s"
            if display_detections:
                info_text += f" | Active Tracks: {qr_tracker.get_active_track_count() if qr_tracker else len(display_detections)}"
            cv2.putText(vis_frame, info_text, (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            
            # ì¶œë ¥ ë¹„ë””ì˜¤ì— ì €ì¥
            if out_video is not None:
                out_video.write(vis_frame)
            
            # í™”ë©´ì— í‘œì‹œ
            if show_video:
                # í™”ë©´ í¬ê¸°ì— ë§ê²Œ ë¦¬ì‚¬ì´ì¦ˆ
                display_width = 1280
                if width > display_width:
                    scale = display_width / width
                    display_height = int(height * scale)
                    display_frame = cv2.resize(vis_frame, (display_width, display_height))
                else:
                    display_frame = vis_frame
                
                cv2.imshow('QR Detection Test (Optimized)', display_frame)
                
                # 'q' í‚¤ë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œ
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    print("\nâš ï¸ ì‚¬ìš©ìê°€ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
                    break
            
            # í”„ë ˆì„ ì²˜ë¦¬ ì‹œê°„ ì¸¡ì •
            frame_processing_time = time.time() - frame_start_time
            frame_processing_times.append(frame_processing_time)
            
            # ì§„í–‰ ìƒí™© ì¶œë ¥ (ì‹¤ì‹œê°„ ì²˜ë¦¬ ì†ë„ í¬í•¨)
            if frame_count % 30 == 0:
                progress = (frame_count / total_frames) * 100
                # í˜„ì¬ê¹Œì§€ì˜ í‰ê·  ì²˜ë¦¬ FPS ê³„ì‚°
                elapsed_time = time.time() - start_time
                current_processing_fps = frame_count / elapsed_time if elapsed_time > 0 else 0
                speed_ratio = (current_processing_fps / fps * 100) if fps > 0 else 0
                print(f" Â  ì§„í–‰: {progress:.1f}% ({frame_count}/{total_frames} í”„ë ˆì„) | "
                      f"ì²˜ë¦¬ ì†ë„: {current_processing_fps:.2f} FPS (ì›ë³¸ {fps:.2f} FPSì˜ {speed_ratio:.1f}%)")
    
    except KeyboardInterrupt:
        print("\nâš ï¸ ì‚¬ìš©ìê°€ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
    finally:
        # â˜…â˜…â˜…â˜…â˜… í•´ë… ì›Œì»¤ ìŠ¤ë ˆë“œ ì¢…ë£Œ â˜…â˜…â˜…â˜…â˜…
        if enable_decode and stop_decode_worker is not None and decode_queue is not None:
            stop_decode_worker.set()
            # íì— Noneì„ ë„£ì–´ ì›Œì»¤ ìŠ¤ë ˆë“œê°€ ì¢…ë£Œë˜ë„ë¡ ì‹ í˜¸ ì „ì†¡
            try:
                decode_queue.put_nowait(None)
            except:
                pass # íê°€ ê°€ë“ì°¨ë„ ì¢…ë£Œ ì‹ í˜¸ëŠ” ë³´ë‚´ì•¼ í•¨
            if decode_worker_thread is not None:
                decode_worker_thread.join(timeout=2.0)
            log_print("âœ… í•´ë… ì›Œì»¤ ìŠ¤ë ˆë“œ ì¢…ë£Œ")
        
        # ì •ë¦¬
        total_time = time.time() - start_time
        cap.release()
        if out_video is not None:
            out_video.release()
        if show_video:
            cv2.destroyAllWindows()
        
        # í†µê³„ ì¶œë ¥
        print(f"\nğŸ“Š ì²˜ë¦¬ ì™„ë£Œ!")
        print(f" Â  ì´ í”„ë ˆì„: {frame_count}")
        print(f" Â  íƒì§€ëœ í”„ë ˆì„: {detection_count}")
        print(f" Â  ì´ íƒì§€ ìˆ˜: {total_detections}")
        print(f" Â  ì²˜ë¦¬ ì‹œê°„: {total_time:.2f}ì´ˆ")
        
        # ì²˜ë¦¬ ì†ë„ í†µê³„
        if frame_count > 0 and total_time > 0:
            actual_fps = frame_count / total_time
            print(f"\nâš¡ ì²˜ë¦¬ ì†ë„ ë¶„ì„:")
            print(f" Â  ì›ë³¸ ì˜ìƒ FPS: {fps:.2f}")
            print(f" Â  ì‹¤ì œ ì²˜ë¦¬ FPS: {actual_fps:.2f}")
            speed_ratio = (actual_fps / fps * 100) if fps > 0 else 0
            print(f" Â  ì†ë„ ë¹„ìœ¨: {speed_ratio:.1f}% (ì›ë³¸ ëŒ€ë¹„)")
            if actual_fps >= fps:
                print(f" Â  âœ… ì‹¤ì‹œê°„ ì²˜ë¦¬ ê°€ëŠ¥! (ì›ë³¸ë³´ë‹¤ {actual_fps/fps:.2f}x ë¹ ë¦„)")
            else:
                print(f" Â  âš ï¸ ì‹¤ì‹œê°„ ì²˜ë¦¬ ë¶ˆê°€ (ì›ë³¸ì˜ {actual_fps/fps:.2f}x ëŠë¦¼)")
        
        if frame_processing_times:
            avg_frame_time = np.mean(frame_processing_times)
            min_frame_time = np.min(frame_processing_times)
            max_frame_time = np.max(frame_processing_times)
            print(f"\nğŸ“ˆ í”„ë ˆì„ ì²˜ë¦¬ ì‹œê°„:")
            print(f" Â  í‰ê· : {avg_frame_time*1000:.2f}ms")
            print(f" Â  ìµœì†Œ: {min_frame_time*1000:.2f}ms")
            print(f" Â  ìµœëŒ€: {max_frame_time*1000:.2f}ms")
            if fps > 0:
                target_frame_time = 1.0 / fps
                print(f" Â  ëª©í‘œ (ì›ë³¸ FPS ê¸°ì¤€): {target_frame_time*1000:.2f}ms")
        
        if detection_times:
            avg_detect_time = np.mean(detection_times)
            print(f"\nğŸ” íƒì§€ ì‹œê°„:")
            print(f" Â  í‰ê·  íƒì§€ ì‹œê°„: {avg_detect_time*1000:.2f}ms")
        if detections_per_frame:
            avg_detections = np.mean(detections_per_frame)
            print(f" Â  í”„ë ˆì„ë‹¹ í‰ê·  íƒì§€: {avg_detections:.2f}ê°œ")
        
        log_print("-" * 60)
        log_print(f"ì²˜ë¦¬ ì™„ë£Œ")
        log_print(f"ì´ í”„ë ˆì„: {frame_count}, íƒì§€ í”„ë ˆì„: {detection_count}, ì´ íƒì§€: {total_detections}")
        log_print(f"ì²˜ë¦¬ ì‹œê°„: {total_time:.2f}ì´ˆ")
        
        # ì²˜ë¦¬ ì†ë„ ë¡œê·¸
        if frame_count > 0 and total_time > 0:
            actual_fps = frame_count / total_time
            log_print(f"\nâš¡ ì²˜ë¦¬ ì†ë„ ë¶„ì„:")
            log_print(f" Â  ì›ë³¸ ì˜ìƒ FPS: {fps:.2f}")
            log_print(f" Â  ì‹¤ì œ ì²˜ë¦¬ FPS: {actual_fps:.2f}")
            speed_ratio = (actual_fps / fps * 100) if fps > 0 else 0
            log_print(f" Â  ì†ë„ ë¹„ìœ¨: {speed_ratio:.1f}% (ì›ë³¸ ëŒ€ë¹„)")
            if actual_fps >= fps:
                log_print(f" Â  âœ… ì‹¤ì‹œê°„ ì²˜ë¦¬ ê°€ëŠ¥! (ì›ë³¸ë³´ë‹¤ {actual_fps/fps:.2f}x ë¹ ë¦„)")
            else:
                log_print(f" Â  âš ï¸ ì‹¤ì‹œê°„ ì²˜ë¦¬ ë¶ˆê°€ (ì›ë³¸ì˜ {actual_fps/fps:.2f}x ëŠë¦¼)")
        
        if frame_processing_times:
            avg_frame_time = np.mean(frame_processing_times)
            min_frame_time = np.min(frame_processing_times)
            max_frame_time = np.max(frame_processing_times)
            log_print(f"\nğŸ“ˆ í”„ë ˆì„ ì²˜ë¦¬ ì‹œê°„:")
            log_print(f" Â  í‰ê· : {avg_frame_time*1000:.2f}ms")
            log_print(f" Â  ìµœì†Œ: {min_frame_time*1000:.2f}ms")
            log_print(f" Â  ìµœëŒ€: {max_frame_time*1000:.2f}ms")
            if fps > 0:
                target_frame_time = 1.0 / fps
                log_print(f" Â  ëª©í‘œ (ì›ë³¸ FPS ê¸°ì¤€): {target_frame_time*1000:.2f}ms")
        
        log_file.close()
        
        if video_output_path:
            print(f" Â  ğŸ’¾ ê²°ê³¼ ì˜ìƒ ì €ì¥: {video_output_path}")
            print(f" Â  ğŸ“ ë¡œê·¸ íŒŒì¼: {log_file_path}")
    
    return {
        'total_frames': frame_count,
        'detection_frames': detection_count,
        'total_detections': total_detections,
        'output_video': video_output_path,
        'log_file': log_file_path
    }

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    model_path = 'l.pt'
    video_path = r'C:\Users\Administrator\qr_sh\data\video\sample_video3-1.mp4'
    
    # 1. ëª¨ë¸ ì •ë³´ í™•ì¸
    model, model_type = test_model_info(model_path)
    
    if model is None:
        print("\nâŒ ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # 2. YOLO ëª¨ë¸ì¸ ê²½ìš° í…ŒìŠ¤íŠ¸
    if model_type == 'yolo':
        print("\n" + "=" * 60)
        print("ğŸ¬ ì˜ìƒ í…ŒìŠ¤íŠ¸ ëª¨ë“œ")
        print("=" * 60)
        
        # ì˜ìƒ í…ŒìŠ¤íŠ¸
        if os.path.exists(video_path):
            print(f"\nğŸ“¹ ì˜ìƒ íŒŒì¼: {video_path}")
            
            # ì‚¬ìš©ì ì„¤ì •
            conf_threshold = 0.25  # ì‹ ë¢°ë„ ì„ê³„ê°’
            frame_interval = 2     # 2í”„ë ˆì„ë§ˆë‹¤ íƒì§€ (ì†ë„ í–¥ìƒ)
            process_scale = 1.0    # ì²˜ë¦¬ í•´ìƒë„ ìŠ¤ì¼€ì¼ (1.0=ì›ë³¸, 0.5=50%, 0.25=25%)
            show_video = True      # í™”ë©´ì— í‘œì‹œ ì—¬ë¶€
            save_output = True     # ê²°ê³¼ ì˜ìƒ ì €ì¥ ì—¬ë¶€
            
            result = test_video_detection(
                model, video_path,
                conf_threshold=conf_threshold,
                frame_interval=frame_interval,
                show_video=show_video,
                save_output=save_output,
                process_scale=process_scale,
                enable_decode=True,  # í•´ë… í™œì„±í™”
                qreader=None,  # ìë™ ìƒì„±
                use_qreader_detect=False,  # ê¸°ë³¸ê°’: False (ëŠë¦¼, í•„ìš”ì‹œ Trueë¡œ ë³€ê²½)
                qreader_detect_interval=5,  # QReader detect() ì‹¤í–‰ ê°„ê²© (5í”„ë ˆì„ë§ˆë‹¤)
                use_tracking=True  # ì¶”ì  ê¸°ëŠ¥ í™œì„±í™” (ëŠê¹€ ì—†ëŠ” ì‹œê°í™”)
            )
            
            if result:
                print(f"\nâœ… ì˜ìƒ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        else:
            print(f"\nâŒ ì˜ìƒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
            print(f"\nğŸ“ ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸ë¡œ ì „í™˜...")
            
            # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²½ë¡œ
            test_images_dir = Path('data/250723_test')
            
            if test_images_dir.exists():
                test_images = list(test_images_dir.glob('*.jpg'))[:5]
                
                if len(test_images) > 0:
                    print(f"\nğŸ“ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {len(test_images)}ê°œ")
                    
                    output_dir = Path('l_pt_test_results')
                    output_dir.mkdir(exist_ok=True)
                    
                    for i, img_path in enumerate(test_images):
                        print(f"\n{'='*60}")
                        result_data = test_yolo_detection(model, str(img_path))
                        
                        if result_data:
                            save_path = output_dir / f"result_{i+1}_{img_path.stem}.png"
                            visualize_results(result_data['image'], result_data['detections'], 
                                            str(save_path))
                    
                    print(f"\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ! ê²°ê³¼ëŠ” '{output_dir}' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                else:
                    print("âŒ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                print(f"âŒ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {test_images_dir}")
    
    elif model_type == 'pytorch':
        print("\nâš ï¸ ì¼ë°˜ PyTorch ëª¨ë¸ì…ë‹ˆë‹¤. YOLO ì „ìš© í…ŒìŠ¤íŠ¸ëŠ” ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ëª¨ë¸ êµ¬ì¡°ë¥¼ í™•ì¸í•˜ë ¤ë©´ ì¶”ê°€ ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤.")

if __name__ == '__main__':
    main()