"""
ì˜ìƒ í”Œë ˆì´ì–´ + ì‹¤ì‹œê°„ QR íƒì§€
ì˜ìƒì„ í™”ë©´ì— ë³´ì—¬ì£¼ë©´ì„œ QR ì½”ë“œ íƒì§€ ì‹œ ì‹œê°í™”
"""

import cv2
import time
import os
import numpy as np
import threading
import queue

# ê²½ê³  ë©”ì‹œì§€ ìˆ¨ê¸°ê¸°
import warnings
warnings.filterwarnings('ignore')

# PyZbar ê²½ê³  ë©”ì‹œì§€ ì™„ì „íˆ ìˆ¨ê¸°ê¸°
import os
os.environ['PYTHONWARNINGS'] = 'ignore'
os.environ['ZBAR_WARNINGS'] = '0'

# í‘œì¤€ ì¶œë ¥ ë¦¬ë‹¤ì´ë ‰ì…˜ìœ¼ë¡œ ê²½ê³  ìˆ¨ê¸°ê¸°
import sys
from contextlib import redirect_stderr
import io

# QReader import
try:
    from qreader import QReader
    QREADER_AVAILABLE = True
    # QReader ê²½ê³  ë©”ì‹œì§€ ìˆ¨ê¸°ê¸°
    warnings.filterwarnings('ignore', category=UserWarning, module='qreader')
except ImportError:
    QREADER_AVAILABLE = False
    print("âš ï¸ QReaderë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. pip install qreaderë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")

# PyZbar ê´€ë ¨ ì½”ë“œ ì œê±°ë¨
PYZBAR_AVAILABLE = False

# PIL import (í•œê¸€ í°íŠ¸ ì§€ì›ìš©)
try:
    from PIL import Image, ImageDraw, ImageFont
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    print("âš ï¸ PILì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. pip install Pillowë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")

# ë³‘ë ¬ ì²˜ë¦¬ìš© QR íƒì§€ í•¨ìˆ˜ë“¤
def qreader_detect_parallel(frame, qreader, results_queue):
    """QReader íƒì§€ (ë³‘ë ¬ ì²˜ë¦¬ìš©)"""
    try:
        detections = qreader.detect(frame)
        if detections and len(detections) > 0:
            results = []
            for i, detection in enumerate(detections):
                try:
                    decoded_text = qreader.decode(frame, detection)
                    if decoded_text:
                        # íŠ¹ìˆ˜ ë¬¸ì ì²˜ë¦¬
                        decoded_text = decoded_text.replace('â€“', '-')
                        decoded_text = decoded_text.replace('â€”', '-')
                        
                        # í•œê¸€ ì¸ì½”ë”© ì²˜ë¦¬
                        try:
                            if isinstance(decoded_text, bytes):
                                decoded_text = decoded_text.decode('utf-8')
                        except UnicodeDecodeError:
                            try:
                                decoded_text = decoded_text.decode('cp949')
                            except:
                                decoded_text = str(decoded_text)
                        
                        
                        results.append({
                            'text': decoded_text,
                            'detection': detection,
                            'method': f'QReader-{i+1}',
                            'success': True
                        })
                    else:
                        results.append({
                            'text': 'í•´ë… ì‹¤íŒ¨',
                            'detection': detection,
                            'method': f'QReader-{i+1}-ì‹¤íŒ¨',
                            'success': False
                        })
                except Exception as e:
                    continue
            
            if results:
                results_queue.put(('QReader', results))
    except Exception as e:
        pass

# PyZbar í•¨ìˆ˜ ì œê±°ë¨

def brightness_qreader_detect_parallel(frame, qreader, results_queue):
    """ë°ê¸°í–¥ìƒ+QReader íƒì§€ (ë³‘ë ¬ ì²˜ë¦¬ìš©, íŒŒë¼ë¯¸í„° ìŠ¤ìœ•)"""
    try:
        params = [(1.3, 20), (1.5, 30), (1.7, 40)]
        aggregate = []
        for alpha, beta in params:
            bright = cv2.convertScaleAbs(frame, alpha=alpha, beta=beta)
            bright = cv2.medianBlur(bright, 3)
            detections = qreader.detect(bright)
            if detections and len(detections) > 0:
                for i, detection in enumerate(detections):
                    try:
                        decoded_text = qreader.decode(bright, detection)
                        decoded_text = _process_decoded_text(decoded_text)
                        if decoded_text:
                            aggregate.append({'text': decoded_text,'detection': detection,'method': f'ë°ê¸°í–¥ìƒ+QReader-{i+1}','success': True})
                        else:
                            aggregate.append({'text': 'í•´ë… ì‹¤íŒ¨','detection': detection,'method': f'ë°ê¸°í–¥ìƒ+QReader-{i+1}-ì‹¤íŒ¨','success': False})
                    except Exception:
                        continue
        if aggregate:
            results_queue.put(('ë°ê¸°í–¥ìƒ+QReader', aggregate))
    except Exception:
        pass

def clahe_qreader_detect_parallel(frame, qreader, results_queue):
    """CLAHE+QReader íƒì§€ (ë³‘ë ¬ ì²˜ë¦¬ìš©, íŒŒë¼ë¯¸í„° ìŠ¤ìœ•)"""
    try:
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        clip_limits = [2.0, 3.0]
        tiles = [(8, 8), (12, 12)]
        aggregate = []
        for cl in clip_limits:
            for ts in tiles:
                clahe = cv2.createCLAHE(clipLimit=cl, tileGridSize=ts)
                enhanced = clahe.apply(gray)
                enhanced = cv2.medianBlur(enhanced, 3)
                enhanced_bgr = cv2.cvtColor(enhanced, cv2.COLOR_GRAY2BGR)
                detections = qreader.detect(enhanced_bgr)
                if detections and len(detections) > 0:
                    for i, detection in enumerate(detections):
                        try:
                            decoded_text = qreader.decode(enhanced_bgr, detection)
                            decoded_text = _process_decoded_text(decoded_text)
                            if decoded_text:
                                aggregate.append({'text': decoded_text,'detection': detection,'method': f'CLAHE+QReader-{i+1}','success': True})
                            else:
                                aggregate.append({'text': 'í•´ë… ì‹¤íŒ¨','detection': detection,'method': f'CLAHE+QReader-{i+1}-ì‹¤íŒ¨','success': False})
                        except Exception:
                            continue
        if aggregate:
            results_queue.put(('CLAHE+QReader', aggregate))
    except Exception as e:
        pass

# ë°˜ì „+QReader (í°ìƒ‰ QRìš©)
def inverted_qreader_detect_parallel(frame, qreader, results_queue):
    try:
        inverted = cv2.bitwise_not(frame)
        detections = qreader.detect(inverted)
        if detections and len(detections) > 0:
            results = []
            for i, detection in enumerate(detections):
                try:
                    decoded_text = qreader.decode(inverted, detection)
                    if decoded_text:
                        decoded_text = decoded_text.replace('â€“', '-').replace('â€”', '-')
                        try:
                            if isinstance(decoded_text, bytes):
                                decoded_text = decoded_text.decode('utf-8')
                        except UnicodeDecodeError:
                            try:
                                decoded_text = decoded_text.decode('cp949')
                            except:
                                decoded_text = str(decoded_text)
                        results.append({
                            'text': decoded_text,
                            'detection': detection,
                            'method': f'Inverted+QReader-{i+1}',
                            'success': True
                        })
                    else:
                        results.append({
                            'text': 'í•´ë… ì‹¤íŒ¨',
                            'detection': detection,
                            'method': f'Inverted+QReader-{i+1}-ì‹¤íŒ¨',
                            'success': False
                        })
                except Exception:
                    continue
            if results:
                results_queue.put(('Inverted+QReader', results))
    except Exception:
        pass

# ì›ë³¸ ì´ì§„í™”+QReader
def binary_qreader_detect_parallel(frame, qreader, results_queue):
    try:
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        aggregate = []
        blurs = [0, 3]
        blocks = [11, 15, 21]
        consts = [2, 5, 10]
        for k in blurs:
            src = cv2.medianBlur(gray, k) if k else gray
            for b in blocks:
                for c in consts:
                    try:
                        binary = cv2.adaptiveThreshold(src, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, b, c)
                        binary_bgr = cv2.cvtColor(binary, cv2.COLOR_GRAY2BGR)
                        detections = qreader.detect(binary_bgr)
                        if detections and len(detections) > 0:
                            for i, detection in enumerate(detections):
                                try:
                                    decoded_text = qreader.decode(binary_bgr, detection)
                                    if decoded_text:
                                        aggregate.append({'text': decoded_text,'detection': detection,'method': f'Binary+QReader-{i+1}','success': True})
                                    else:
                                        aggregate.append({'text': 'í•´ë… ì‹¤íŒ¨','detection': detection,'method': f'Binary+QReader-{i+1}-ì‹¤íŒ¨','success': False})
                                except Exception:
                                    continue
                    except Exception:
                        continue
        if aggregate:
            results_queue.put(('Binary+QReader', aggregate))
    except Exception:
        pass

# ë°˜ì „+CLAHE+QReader
def inverted_clahe_qreader_detect_parallel(frame, qreader, results_queue):
    try:
        inverted = cv2.bitwise_not(frame)
        gray = cv2.cvtColor(inverted, cv2.COLOR_BGR2GRAY)
        clip_limits = [2.0, 3.0]
        tiles = [(8, 8), (12, 12)]
        aggregate = []
        for cl in clip_limits:
            for ts in tiles:
                clahe = cv2.createCLAHE(clipLimit=cl, tileGridSize=ts)
                enhanced = clahe.apply(gray)
                enhanced = cv2.medianBlur(enhanced, 3)
                enhanced_bgr = cv2.cvtColor(enhanced, cv2.COLOR_GRAY2BGR)
                detections = qreader.detect(enhanced_bgr)
                if detections and len(detections) > 0:
                    for i, detection in enumerate(detections):
                        try:
                            decoded_text = qreader.decode(enhanced_bgr, detection)
                            if decoded_text:
                                aggregate.append({'text': decoded_text,'detection': detection,'method': f'Inverted+CLAHE+QReader-{i+1}','success': True})
                            else:
                                aggregate.append({'text': 'í•´ë… ì‹¤íŒ¨','detection': detection,'method': f'Inverted+CLAHE+QReader-{i+1}-ì‹¤íŒ¨','success': False})
                        except Exception:
                            continue
        if aggregate:
            results_queue.put(('Inverted+CLAHE+QReader', aggregate))
    except Exception:
        pass

# ë°˜ì „+ì´ì§„í™”+QReader
def inverted_binary_qreader_detect_parallel(frame, qreader, results_queue):
    try:
        inverted = cv2.bitwise_not(frame)
        gray = cv2.cvtColor(inverted, cv2.COLOR_BGR2GRAY)
        aggregate = []
        blurs = [0, 3]
        blocks = [11, 15, 21]
        consts = [2, 5, 10]
        for k in blurs:
            src = cv2.medianBlur(gray, k) if k else gray
            for b in blocks:
                for c in consts:
                    try:
                        binary = cv2.adaptiveThreshold(src, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, b, c)
                        binary_bgr = cv2.cvtColor(binary, cv2.COLOR_GRAY2BGR)
                        detections = qreader.detect(binary_bgr)
                        if detections and len(detections) > 0:
                            for i, detection in enumerate(detections):
                                try:
                                    decoded_text = qreader.decode(binary_bgr, detection)
                                    if decoded_text:
                                        aggregate.append({'text': decoded_text,'detection': detection,'method': f'Inverted+Binary+QReader-{i+1}','success': True})
                                    else:
                                        aggregate.append({'text': 'í•´ë… ì‹¤íŒ¨','detection': detection,'method': f'Inverted+Binary+QReader-{i+1}-ì‹¤íŒ¨','success': False})
                                except Exception:
                                    continue
                    except Exception:
                        continue
        if aggregate:
            results_queue.put(('Inverted+Binary+QReader', aggregate))
    except Exception:
        pass
# ë°ê¸°í–¥ìƒ+PyZbar í•¨ìˆ˜ ì œê±°ë¨

def process_frame_parallel(frame, qreader):
    """í”„ë ˆì„ì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬í•˜ì—¬ ëª¨ë“  QR íƒì§€ ë°©ë²• ì‹¤í–‰"""
    results_queue = queue.Queue()
    threads = []
    
    # ì—¬ëŸ¬ ë°©ë²•ì„ ë™ì‹œì— ì‹¤í–‰ (ë°˜ì „/ì´ì§„í™” ê³„ì—´ í¬í•¨)
    if qreader:
        threads.append(threading.Thread(target=qreader_detect_parallel, args=(frame, qreader, results_queue)))
        threads.append(threading.Thread(target=brightness_qreader_detect_parallel, args=(frame, qreader, results_queue)))
        threads.append(threading.Thread(target=clahe_qreader_detect_parallel, args=(frame, qreader, results_queue)))
        threads.append(threading.Thread(target=inverted_qreader_detect_parallel, args=(frame, qreader, results_queue)))
        threads.append(threading.Thread(target=binary_qreader_detect_parallel, args=(frame, qreader, results_queue)))
        threads.append(threading.Thread(target=inverted_clahe_qreader_detect_parallel, args=(frame, qreader, results_queue)))
        threads.append(threading.Thread(target=inverted_binary_qreader_detect_parallel, args=(frame, qreader, results_queue)))
    
    # ëª¨ë“  ìŠ¤ë ˆë“œ ì‹œì‘
    for thread in threads:
        thread.start()
    
    # ëª¨ë“  ìŠ¤ë ˆë“œ ì™„ë£Œ ëŒ€ê¸°
    for thread in threads:
        thread.join()
    
    # ê²°ê³¼ ìˆ˜ì§‘
    all_results = {}
    while not results_queue.empty():
        method, results = results_queue.get()
        all_results[method] = results
    
    return all_results

def create_single_frame(frame):
    """ì›ë³¸ í”„ë ˆì„ë§Œ ì‚¬ìš©"""
    return frame, [1.0]

def get_scale_color(scale):
    """ìŠ¤ì¼€ì¼ë³„ ìƒ‰ìƒ ë°˜í™˜ (BGR í˜•ì‹)"""
    if scale == 1.0:
        return (0, 255, 0)    # ì´ˆë¡ìƒ‰
    elif scale == 1.5:
        return (255, 0, 0)    # íŒŒë€ìƒ‰
    elif scale == 2.0:
        return (0, 255, 255)  # ë…¸ë€ìƒ‰
    else:
        return (255, 255, 255)  # ê¸°ë³¸ í°ìƒ‰

def put_korean_text(img, text, position, font_size=20, color=(0, 255, 0)):
    """OpenCV ì´ë¯¸ì§€ì— í•œê¸€ í…ìŠ¤íŠ¸ë¥¼ ê·¸ë¦¬ëŠ” í•¨ìˆ˜"""
    if not PIL_AVAILABLE:
        # PILì´ ì—†ìœ¼ë©´ OpenCV ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©
        cv2.putText(img, text, position, cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
        return img
    
    try:
        # OpenCV ì´ë¯¸ì§€ë¥¼ PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
        img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(img_pil)
        
        # í•œê¸€ í°íŠ¸ ë¡œë“œ (Windows ê¸°ë³¸ í°íŠ¸ë“¤ ì‹œë„)
        font_paths = [
            "C:/Windows/Fonts/malgun.ttf",  # ë§‘ì€ ê³ ë”•
            "C:/Windows/Fonts/gulim.ttc",   # êµ´ë¦¼
            "C:/Windows/Fonts/batang.ttc",  # ë°”íƒ•
            "C:/Windows/Fonts/arial.ttf"    # Arial (fallback)
        ]
        
        font = None
        for font_path in font_paths:
            try:
                font = ImageFont.truetype(font_path, font_size)
                break
            except:
                continue
        
        # í°íŠ¸ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš° ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©
        if font is None:
            font = ImageFont.load_default()
        
        # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
        draw.text(position, text, font=font, fill=color)
        
        # PIL ì´ë¯¸ì§€ë¥¼ OpenCV ì´ë¯¸ì§€ë¡œ ë³€í™˜
        img_cv = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)
        return img_cv
        
    except Exception as e:
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ OpenCV ê¸°ë³¸ í°íŠ¸ë¡œ fallback
        cv2.putText(img, text, position, cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
        return img

def get_english_method_name(method_name):
    """í•œê¸€ ë°©ë²•ëª…ì„ ì˜ë¬¸ìœ¼ë¡œ ë³€í™˜ (OpenCV putText í˜¸í™˜)"""
    method_map = {
        "QReader": "QReader",
        "ë°ê¸°í–¥ìƒ+QReader": "Bright+QReader",
        "CLAHE+QReader": "CLAHE+QReader",
        "Inverted+QReader": "Inverted+QReader",
        "Binary+QReader": "Binary+QReader",
        "Inverted+CLAHE+QReader": "Inverted+CLAHE+QReader",
        "Inverted+Binary+QReader": "Inverted+Binary+QReader"
    }
    return method_map.get(method_name, method_name)

def is_center_in_bbox(center_x, center_y, bbox_x1, bbox_y1, bbox_x2, bbox_y2):
    """ì¤‘ì‹¬ì ì´ ì‚¬ê°í˜• ì•ˆì— ìˆëŠ”ì§€ í™•ì¸"""
    return bbox_x1 <= center_x <= bbox_x2 and bbox_y1 <= center_y <= bbox_y2

def get_qr_center_and_bbox(detection):
    """QRì˜ ì¤‘ì‹¬ì ê³¼ ì‚¬ê°í˜• ì¢Œí‘œë¥¼ ë°˜í™˜ - quad_xy ìš°ì„  ì‚¬ìš©"""
    # quad_xyê°€ ìˆìœ¼ë©´ ê°€ì¥ ì •í™•í•œ ì¤‘ì‹¬ì ê³¼ ì‚¬ê°í˜• ì‚¬ìš©
    if 'quad_xy' in detection:
        quad = detection['quad_xy']
        if len(quad) == 4:
            quad_array = np.array(quad)
            center = np.mean(quad_array, axis=0)
            # quad_xyì˜ ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚°
            x_coords = quad_array[:, 0]
            y_coords = quad_array[:, 1]
            x1, x2 = np.min(x_coords), np.max(x_coords)
            y1, y2 = np.min(y_coords), np.max(y_coords)
            return center[0], center[1], x1, y1, x2, y2
    
    # polygon_xyê°€ ìˆìœ¼ë©´ ì‚¬ìš©
    elif 'polygon_xy' in detection:
        polygon = detection['polygon_xy']
        if len(polygon) >= 4:
            polygon_array = np.array(polygon)
            center = np.mean(polygon_array, axis=0)
            x_coords = polygon_array[:, 0]
            y_coords = polygon_array[:, 1]
            x1, x2 = np.min(x_coords), np.max(x_coords)
            y1, y2 = np.min(y_coords), np.max(y_coords)
            return center[0], center[1], x1, y1, x2, y2
    
    # bbox_xyxy ì‚¬ìš© (fallback)
    elif 'bbox_xyxy' in detection:
        bbox = detection['bbox_xyxy']
        x1, y1, x2, y2 = bbox
        center_x = (x1 + x2) / 2
        center_y = (y1 + y2) / 2
        return center_x, center_y, x1, y1, x2, y2
    
    # cxcy+wh ì‚¬ìš© (ìµœì¢… fallback)
    elif 'cxcy' in detection and 'wh' in detection:
        cx, cy = detection['cxcy']
        w, h = detection['wh']
        x1, y1 = cx - w/2, cy - h/2
        x2, y2 = cx + w/2, cy + h/2
        return cx, cy, x1, y1, x2, y2
    
    return None, None, None, None, None, None

def process_single_results(results):
    """ì›ë³¸ ìŠ¤ì¼€ì¼ ê²°ê³¼ ì²˜ë¦¬ - ì¤‘ì‹¬ì  ê¸°ë°˜ ì¤‘ë³µ ì œê±°"""
    unique_qrs = []
    
    # ë””ë²„ê¹…: íƒì§€ ê²°ê³¼ ì¶œë ¥
    total_detected = sum(len(qr_list) for qr_list in results.values())
    successful = sum(len([qr for qr in qr_list if qr['success']]) for qr_list in results.values())
    print(f"    ğŸ” íƒì§€ ê²°ê³¼: {successful}/{total_detected} ì„±ê³µ")
    
    for method, qr_list in results.items():
        for qr in qr_list:
            if qr['success']:
                detection = qr['detection']
                center_x, center_y, x1, y1, x2, y2 = get_qr_center_and_bbox(detection)
                
                if center_x is not None:
                    # ê¸°ì¡´ QRë“¤ê³¼ ì¤‘ë³µ ì²´í¬
                    is_duplicate = False
                    for existing_qr in unique_qrs:
                        existing_detection = existing_qr['detection']
                        existing_center_x, existing_center_y, existing_x1, existing_y1, existing_x2, existing_y2 = get_qr_center_and_bbox(existing_detection)
                        
                        if existing_center_x is not None:
                            # í˜„ì¬ QRì˜ ì¤‘ì‹¬ì´ ê¸°ì¡´ QRì˜ ì‚¬ê°í˜• ì•ˆì— ìˆê±°ë‚˜
                            # ê¸°ì¡´ QRì˜ ì¤‘ì‹¬ì´ í˜„ì¬ QRì˜ ì‚¬ê°í˜• ì•ˆì— ìˆìœ¼ë©´ ì¤‘ë³µ
                            if (is_center_in_bbox(center_x, center_y, existing_x1, existing_y1, existing_x2, existing_y2) or
                                is_center_in_bbox(existing_center_x, existing_center_y, x1, y1, x2, y2)):
                                is_duplicate = True
                                break
                    
                    if not is_duplicate:
                        qr['scale'] = 1.0
                        unique_qrs.append(qr)
    
    return unique_qrs

def extract_bounding_box(detection, image_width=None, image_height=None):
    """
    QReader detection ê²°ê³¼ì—ì„œ ìš°ì„ ìˆœìœ„ì— ë”°ë¼ Bounding Box ì¶”ì¶œ
    
    ìš°ì„ ìˆœìœ„:
    1. polygon_xy ë˜ëŠ” quad_xy (ê°€ì¥ ì •í™•)
    2. cxcy + wh (ì¢‹ì€ ëŒ€ì•ˆ)
    3. bbox_xyxyn (ì •ê·œí™”ëœ ì¢Œí‘œ)
    4. bbox_xyxy (ê¸°ë³¸)
    """
    # ğŸ¥‡ 1ìˆœìœ„: polygon_xy ë˜ëŠ” quad_xy (ê°€ì¥ ì •í™•)
    for key in ['polygon_xy', 'quad_xy']:
        if key in detection:
            points = detection[key]
            if len(points) >= 4:
                # ëª¨ë“  ì ì˜ x, y ì¢Œí‘œ ì¶”ì¶œ
                x_coords = [point[0] for point in points]
                y_coords = [point[1] for point in points]
                
                # Bounding Box ê³„ì‚°
                x1 = min(x_coords)
                y1 = min(y_coords)
                x2 = max(x_coords)
                y2 = max(y_coords)
                
                return [x1, y1, x2, y2], f"ğŸ“ {key} ê¸°ë°˜"
    
    # ğŸ¥ˆ 2ìˆœìœ„: cxcy + wh (ì¢‹ì€ ëŒ€ì•ˆ)
    if 'cxcy' in detection and 'wh' in detection:
        cx, cy = detection['cxcy']
        w, h = detection['wh']
        
        x1 = cx - w / 2
        y1 = cy - h / 2
        x2 = cx + w / 2
        y2 = cy + h / 2
        
        return [x1, y1, x2, y2], f"ğŸ“ cxcy+wh ê¸°ë°˜ (ì¤‘ì‹¬: {cx:.1f},{cy:.1f}, í¬ê¸°: {w:.1f}x{h:.1f})"
    
    # ğŸ¥‰ 3ìˆœìœ„: bbox_xyxyn (ì •ê·œí™”ëœ ì¢Œí‘œ)
    if 'bbox_xyxyn' in detection and image_width and image_height:
        bbox_norm = detection['bbox_xyxyn']
        x1 = bbox_norm[0] * image_width
        y1 = bbox_norm[1] * image_height
        x2 = bbox_norm[2] * image_width
        y2 = bbox_norm[3] * image_height
        
        return [x1, y1, x2, y2], f"ğŸ“ ì •ê·œí™” ì¢Œí‘œ ê¸°ë°˜"
    
    # 4ìˆœìœ„: bbox_xyxy (ê¸°ë³¸)
    if 'bbox_xyxy' in detection:
        return detection['bbox_xyxy'], f"ğŸ“ bbox_xyxy ê¸°ë°˜"
    
    return None, "âš ï¸ ìœ„ì¹˜ ì •ë³´ ì—†ìŒ"


def video_player_with_qr(video_path, output_dir="video_player_results"):
    """ì˜ìƒ í”Œë ˆì´ì–´ + ì‹¤ì‹œê°„ QR íƒì§€"""
    
    # ğŸ• ì „ì²´ ì‹¤í–‰ ì‹œê°„ ì¸¡ì • ì‹œì‘
    total_start_time = time.time()
    
    # ê¸°ì¡´ ê²°ê³¼ í´ë” ì‚­ì œ í›„ ì¬ìƒì„±
    import shutil
    if os.path.exists(output_dir):
        shutil.rmtree(output_dir)
        print(f"ğŸ—‘ï¸ ê¸°ì¡´ ê²°ê³¼ í´ë” ì‚­ì œ: {output_dir}")
    
    os.makedirs(output_dir, exist_ok=True)
    os.makedirs(os.path.join(output_dir, "enhanced"), exist_ok=True)
    os.makedirs(os.path.join(output_dir, "failed"), exist_ok=True)
    print(f"ğŸ“ ê²°ê³¼ í´ë” ìƒì„±: {output_dir}")
    
    # QR íƒì§€ê¸° ì´ˆê¸°í™”
    detector = cv2.QRCodeDetector()
    
    # QReader ì´ˆê¸°í™”
    qreader = None
    if QREADER_AVAILABLE:
        try:
            qreader = QReader()
            print("âœ… QReader ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ QReader ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            qreader = None
    
    print(f"ğŸ“Š ì‚¬ìš© ê°€ëŠ¥í•œ íƒì§€ê¸°:")
    print(f"  - OpenCV: âŒ")
    print(f"  - QReader: {'âœ…' if qreader else 'âŒ'}")
    print(f"  - PyZbar: âŒ (ì œê±°ë¨)")
    print(f"  - PIL (í•œê¸€í°íŠ¸): {'âœ…' if PIL_AVAILABLE else 'âŒ'}")
    
    # ë¹„ë””ì˜¤ ìº¡ì²˜
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"âŒ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
        return
    
    # ë¹„ë””ì˜¤ ì •ë³´
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    print(f"\nğŸ“¹ ë¹„ë””ì˜¤ ì •ë³´:")
    print(f"  íŒŒì¼: {video_path}")
    print(f"  í•´ìƒë„: {width}x{height}")
    print(f"  FPS: {fps:.2f}")
    print(f"  ì´ í”„ë ˆì„: {total_frames}")
    print(f"  ê¸¸ì´: {total_frames/fps:.2f}ì´ˆ")
    
    # í•´ìƒë„ ì¡°ì • (í™”ë©´ì— ë§ê²Œ)
    display_width = 1280
    display_height = 720
    
    if width > display_width:
        scale = display_width / width
        display_width = int(width * scale)
        display_height = int(height * scale)
    
    print(f"  í™”ë©´ í•´ìƒë„: {display_width}x{display_height}")
    print(f"\nğŸ¬ ì˜ìƒ ì¬ìƒ ì‹œì‘!")
    print(f"  - ESC í‚¤: ì¢…ë£Œ")
    print(f"  - SPACE í‚¤: ì¼ì‹œì •ì§€/ì¬ìƒ")
    print(f"  - S í‚¤: í˜„ì¬ í”„ë ˆì„ ì €ì¥")
    
    # ì¬ìƒ ì œì–´ ë³€ìˆ˜
    paused = False
    frame_count = 0
    detected_count = 0
    start_time = time.time()
    
    # FPS ê³„ì‚°ìš©
    fps_counter = 0
    fps_start_time = time.time()
    
    # íƒì§€ ê°„ê²© ì„¤ì • (ì„±ëŠ¥ í–¥ìƒ)
    detection_interval = 3  # 3í”„ë ˆì„ë§ˆë‹¤ íƒì§€ (0.3ì´ˆ ê°„ê²©)
    last_detection_frame = 0
    
    # í†µê³„ ë³€ìˆ˜
    success_count = 0
    failed_count = 0
    
    # ë°©ë²•ë³„ ì„±ê³µë¥  ì¶”ì  (í…ŒìŠ¤íŠ¸ìš© í™•ì¥)
    method_stats = {
        "QReader": 0,
        "ë°ê¸°í–¥ìƒ+QReader": 0,
        "CLAHE+QReader": 0,
        "Inverted+QReader": 0,
        "Binary+QReader": 0,
        "Inverted+CLAHE+QReader": 0,
        "Inverted+Binary+QReader": 0
    }
    
    # í…ŒìŠ¤íŠ¸ìš©: ë°©ë²•ë³„ íƒì§€ ê°œìˆ˜ ë° ê³ ìœ  íƒì§€ ì¶”ì 
    method_detection_count = {
        "QReader": 0,
        "ë°ê¸°í–¥ìƒ+QReader": 0,
        "CLAHE+QReader": 0,
        "Inverted+QReader": 0,
        "Binary+QReader": 0,
        "Inverted+CLAHE+QReader": 0,
        "Inverted+Binary+QReader": 0
    }
    
    method_unique_detection_count = {
        "QReader": 0,
        "ë°ê¸°í–¥ìƒ+QReader": 0,
        "CLAHE+QReader": 0,
        "Inverted+QReader": 0,
        "Binary+QReader": 0,
        "Inverted+CLAHE+QReader": 0,
        "Inverted+Binary+QReader": 0
    }
    
    # ëª¨ë“  ë°©ë²•ì—ì„œ ì°¾ì€ QR ì½”ë“œë“¤ì„ ì €ì¥ (ì¤‘ë³µ ì œê±°ìš©)
    all_detected_qrs = []
    
    # í˜„ì¬ í”„ë ˆì„ìš© ë³€ìˆ˜
    current_success = 0
    current_failed = 0
    
    while True:
        if not paused:
            ret, frame = cap.read()
            if not ret:
                print("\nğŸ“º ì˜ìƒ ì¬ìƒ ì™„ë£Œ!")
                break
            
            frame_count += 1
        
        # í•´ìƒë„ ì¡°ì • (í™”ë©´ í‘œì‹œìš©)
        display_frame = cv2.resize(frame, (display_width, display_height))
        
        # QR ì½”ë“œ íƒì§€ (ì„±ëŠ¥ ìµœì í™”)
        detected = False
        detected_text = ""
        detection_method = ""
        points = None
        
        # ë‹¤ì¤‘ QR ì‹œê°í™”ë¥¼ ìœ„í•œ ë¦¬ìŠ¤íŠ¸
        all_qr_visualizations = []  # [{"points": [...], "text": "...", "method": "...", "success": bool}, ...]
        
        # íƒì§€ ê°„ê²© ì²´í¬ (ì„±ëŠ¥ í–¥ìƒ)
        should_detect = (frame_count - last_detection_frame) >= detection_interval
        
        # í”„ë ˆì„ ìŠ¤í‚µ/ì²˜ë¦¬ ì½˜ì†” ì¶œë ¥ ì œê±°
        
        if should_detect:
            # í˜„ì¬ í”„ë ˆì„ìš© ë³€ìˆ˜ ì´ˆê¸°í™”
            current_success = 0
            current_failed = 0
            
            try:
                # ğŸš€ ë³‘ë ¬ ì²˜ë¦¬ë¡œ ëª¨ë“  QR íƒì§€ ë°©ë²• ë™ì‹œ ì‹¤í–‰
                start_time = time.time()
                
                # ì›ë³¸ í”„ë ˆì„ë§Œ ì‚¬ìš©
                single_frame, scales = create_single_frame(frame)
                
                # ë³‘ë ¬ ì²˜ë¦¬
                results = process_frame_parallel(single_frame, qreader)
                
                # ê²°ê³¼ í†µí•© ë° ì¤‘ë³µ ì œê±°
                unique_qrs = process_single_results(results)
                
                # ì „ì²´ íƒì§€ ê°œìˆ˜ ì—…ë°ì´íŠ¸ (í…ŒìŠ¤íŠ¸ìš© ìƒì„¸ í†µê³„)
                for method, qr_list in results.items():
                    if method in method_detection_count:
                        method_detection_count[method] += len(qr_list)
                
                parallel_time = time.time() - start_time
                
                # ê²°ê³¼ ì²˜ë¦¬ ë° í†µê³„ ì—…ë°ì´íŠ¸
                if unique_qrs:
                    print(f"\nğŸ” í”„ë ˆì„ {frame_count}: {len(unique_qrs)}ê°œì˜ ê³ ìœ  QR ì½”ë“œ ë°œê²¬")
                    
                    for qr in unique_qrs:
                        if qr['success']:
                            print(f"    âœ… QR ì½”ë“œ: {qr['text']} ({qr['method']})")
                            current_success += 1
                            # ì›ë³¸ ë°©ë²•ëª…ìœ¼ë¡œ í†µê³„ ì—…ë°ì´íŠ¸ (ìŠ¤ì¼€ì¼ ì •ë³´ ì œê±°)
                            # "PyZbar-1-0.5x" â†’ "PyZbar"
                            if '-0.5x' in qr['method'] or '-0.75x' in qr['method'] or '-1.0x' in qr['method'] or '-1.25x' in qr['method'] or '-1.5x' in qr['method']:
                                # ìŠ¤ì¼€ì¼ ì •ë³´ì™€ ì¸ë±ìŠ¤ ëª¨ë‘ ì œê±°
                                temp_method = qr['method'].rsplit('-', 1)[0]  # ìŠ¤ì¼€ì¼ ì œê±°
                                if temp_method.endswith('-1'):
                                    original_method = temp_method[:-2]  # "-1" ì œê±°
                                else:
                                    original_method = temp_method.split('-')[0]  # ì²« ë²ˆì§¸ ë¶€ë¶„ë§Œ
                            else:
                                original_method = qr['method'].split('-')[0]  # ì²« ë²ˆì§¸ ë¶€ë¶„ë§Œ
                            
                            # method_statsì— ì¡´ì¬í•˜ëŠ” í‚¤ì¸ì§€ í™•ì¸
                            if original_method in method_stats:
                                method_stats[original_method] += 1
                            else:
                                print(f"    âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ë°©ë²•: {original_method}")
                            
                            # í…ŒìŠ¤íŠ¸ìš© ìƒì„¸ í†µê³„ ì—…ë°ì´íŠ¸
                            if original_method in method_detection_count:
                                method_detection_count[original_method] += 1
                            if original_method in method_unique_detection_count:
                                method_unique_detection_count[original_method] += 1
                            
                            # ì‹œê°í™” ë°ì´í„° ì¶”ê°€ - ì‹¤ì œ QR í˜•íƒœ ë°˜ì˜
                            qr_points = None
                            detection = qr['detection']
                            
                            # QReader ê²°ê³¼ ì²˜ë¦¬ - quad_xyë¡œ ì •í™•í•œ ê¸°ìš¸ì–´ì§„ í˜•íƒœ ì‚¬ìš©
                            if 'quad_xy' in detection:
                                # quad_xy ì‚¬ìš© (ê¸°ìš¸ì–´ì§„ ì‚¬ê°í˜•ì˜ 4ê°œ ê¼­ì§“ì )
                                quad = detection['quad_xy']
                                if len(quad) == 4:
                                    # 4ê°œ ì ì„ ì‚¬ê°í˜• ìˆœì„œë¡œ ì •ë ¬ (ì™¼ìª½ìœ„â†’ì˜¤ë¥¸ìª½ìœ„â†’ì˜¤ë¥¸ìª½ì•„ë˜â†’ì™¼ìª½ì•„ë˜)
                                    quad_array = np.array(quad)
                                    # ì¤‘ì‹¬ì  ê³„ì‚°
                                    center = np.mean(quad_array, axis=0)
                                    # ê° ì ì˜ ê°ë„ ê³„ì‚° (ì¤‘ì‹¬ì  ê¸°ì¤€)
                                    angles = np.arctan2(quad_array[:, 1] - center[1], quad_array[:, 0] - center[0])
                                    # ê°ë„ ìˆœìœ¼ë¡œ ì •ë ¬
                                    sorted_indices = np.argsort(angles)
                                    sorted_quad = quad_array[sorted_indices]
                                    qr_points = np.array([sorted_quad], dtype=np.float32)
                            
                            elif 'bbox_xyxy' in detection:
                                # ì¶• ì •ë ¬ ë°”ìš´ë”© ë°•ìŠ¤ (fallback)
                                bbox = detection['bbox_xyxy']
                                x1, y1, x2, y2 = bbox
                                qr_points = np.array([[
                                    [x1, y1], [x2, y1], [x2, y2], [x1, y2]
                                ]], dtype=np.float32)
                            
                            elif 'cxcy' in detection and 'wh' in detection:
                                # ì¤‘ì‹¬ì +í¬ê¸° (fallback)
                                cx, cy = detection['cxcy']
                                w, h = detection['wh']
                                x1, y1 = cx - w/2, cy - h/2
                                x2, y2 = cx + w/2, cy + h/2
                                qr_points = np.array([[
                                    [x1, y1], [x2, y1], [x2, y2], [x1, y2]
                                ]], dtype=np.float32)
                            
                            else:
                                # extract_bounding_box í•¨ìˆ˜ ì‚¬ìš© (ìµœì¢… fallback)
                                bbox, method_info = extract_bounding_box(detection, frame.shape[1], frame.shape[0])
                                if bbox is not None:
                                    x1, y1, x2, y2 = bbox
                                    qr_points = np.array([[
                                        [x1, y1], [x2, y1], [x2, y2], [x1, y2]
                                    ]], dtype=np.float32)
                            
                            if qr_points is not None:
                                all_qr_visualizations.append({
                                    "points": qr_points,
                                    "text": qr['text'],
                                    "method": qr['method'],
                                    "success": True,
                                    "scale": qr.get('scale', 1.0)
                                })
                        else:
                            current_failed += 1
                            
                            # í•´ë… ì‹¤íŒ¨í•œ QRë„ unique_qrsì— ì¶”ê°€í•˜ì—¬ ì½˜ì†” ì¶œë ¥
                            qr['scale'] = 1.0
                            unique_qrs.append(qr)
                            
                            # í•´ë… ì‹¤íŒ¨í•œ QRë„ ì‹œê°í™” (ë¹¨ê°„ ë°•ìŠ¤)
                            qr_points = None
                            detection = qr['detection']
                            
                            # QReader ê²°ê³¼ ì²˜ë¦¬ - quad_xyë¡œ ì •í™•í•œ ê¸°ìš¸ì–´ì§„ í˜•íƒœ ì‚¬ìš©
                            if 'quad_xy' in detection:
                                quad = detection['quad_xy']
                                if len(quad) == 4:
                                    quad_array = np.array(quad)
                                    center = np.mean(quad_array, axis=0)
                                    angles = np.arctan2(quad_array[:, 1] - center[1], quad_array[:, 0] - center[0])
                                    sorted_indices = np.argsort(angles)
                                    sorted_quad = quad_array[sorted_indices]
                                    qr_points = np.array([sorted_quad], dtype=np.float32)
                            
                            elif 'bbox_xyxy' in detection:
                                bbox = detection['bbox_xyxy']
                                x1, y1, x2, y2 = bbox
                                qr_points = np.array([[
                                    [x1, y1], [x2, y1], [x2, y2], [x1, y2]
                                ]], dtype=np.float32)
                            
                            elif 'cxcy' in detection and 'wh' in detection:
                                cx, cy = detection['cxcy']
                                w, h = detection['wh']
                                x1, y1 = cx - w/2, cy - h/2
                                x2, y2 = cx + w/2, cy + h/2
                                qr_points = np.array([[
                                    [x1, y1], [x2, y1], [x2, y2], [x1, y2]
                                ]], dtype=np.float32)
                            
                            else:
                                bbox, method_info = extract_bounding_box(detection, frame.shape[1], frame.shape[0])
                                if bbox is not None:
                                    x1, y1, x2, y2 = bbox
                                    qr_points = np.array([[
                                        [x1, y1], [x2, y1], [x2, y2], [x1, y2]
                                    ]], dtype=np.float32)
                            
                            if qr_points is not None:
                                all_qr_visualizations.append({
                                    "points": qr_points,
                                    "text": qr['text'],
                                    "method": qr['method'],
                                    "success": False,  # ì‹¤íŒ¨ í‘œì‹œ
                                    "scale": qr.get('scale', 1.0)
                                })
                
                # ì²« ë²ˆì§¸ ì„±ê³µí•œ ê²°ê³¼ë¥¼ ë©”ì¸ ì‹œê°í™”ìš©ìœ¼ë¡œ ì„¤ì •
                if unique_qrs:
                    detected = True
                    detected_text = unique_qrs[0]['text']
                    detection_method = unique_qrs[0]['method']
                
                print(f"    âš¡ ë³‘ë ¬ ì²˜ë¦¬ ì‹œê°„: {parallel_time:.3f}ì´ˆ")
                
               
                
                # ì²˜ë¦¬í•œ í”„ë ˆì„ì€ í•­ìƒ ì—…ë°ì´íŠ¸ (QR ë°œê²¬ ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´)
                last_detection_frame = frame_count
                
                if detected:
                    detected_count += 1
                    
                    # í˜„ì¬ í”„ë ˆì„ì˜ ì„±ê³µ/ì‹¤íŒ¨ í†µê³„ ì¶œë ¥ (ì¤‘ë³µ ì œê±°)
                    total_found = current_success + current_failed
                    if total_found > 0:
                        print(f"    ğŸ“Š ê²°ê³¼: {total_found}ê°œ ì¤‘ {current_success}ê°œ ì„±ê³µ, {current_failed}ê°œ ì‹¤íŒ¨")
                    
                    # ë‹¤ì¤‘ QR ì½”ë“œ ì˜ì—­ì„ í™”ë©´ì— í‘œì‹œ
                    if all_qr_visualizations:
                        # ì›ë³¸ ì¢Œí‘œë¥¼ í™”ë©´ ì¢Œí‘œë¡œ ë³€í™˜í•˜ëŠ” ìŠ¤ì¼€ì¼
                        scale_x = display_width / width
                        scale_y = display_height / height
                        
                        try:
                            for j, qr_viz in enumerate(all_qr_visualizations):
                                try:
                                    points = qr_viz["points"]
                                    qr_text = qr_viz["text"]
                                    qr_method = qr_viz["method"]
                                    qr_success = qr_viz["success"]
                                    
                                    # points í˜•íƒœ í™•ì¸ ë° ë³€í™˜
                                    if len(points.shape) == 3 and points.shape[1] == 4:
                                        # (1, 4, 2) í˜•íƒœì¸ ê²½ìš°
                                        points_2d = points[0]  # (4, 2)ë¡œ ë³€í™˜
                                    elif len(points.shape) == 2 and points.shape[0] == 4:
                                        # (4, 2) í˜•íƒœì¸ ê²½ìš°
                                        points_2d = points
                                    else:
                                        points_2d = points.reshape(-1, 2) if points.size > 0 else None
                                    
                                    if points_2d is not None and len(points_2d) >= 4:
                                        # ì›ë³¸ ì¢Œí‘œë¥¼ í™”ë©´ ì¢Œí‘œë¡œ ë³€í™˜
                                        display_points = points_2d.copy()
                                        display_points[:, 0] *= scale_x
                                        display_points[:, 1] *= scale_y
                                        display_points = display_points.astype(np.int32)
                                        
                                        # í•´ë… ì‹¤íŒ¨ ì‹œ ë¹¨ê°„ ë°•ìŠ¤, ì„±ê³µ ì‹œ ìŠ¤ì¼€ì¼ë³„ ìƒ‰ìƒ
                                        if not qr_success or "ì‹¤íŒ¨" in qr_text or "ì‹¤íŒ¨" in qr_method:
                                            box_color = (0, 0, 255)  # ë¹¨ê°„ìƒ‰ (BGR)
                                            text_color = (0, 0, 255)  # ë¹¨ê°„ìƒ‰
                                        else:
                                            # ìŠ¤ì¼€ì¼ë³„ ìƒ‰ìƒ ì ìš©
                                            scale = qr_viz.get('scale', 1.0)
                                            box_color = get_scale_color(scale)
                                            text_color = box_color
                                        
                                        # QR ì½”ë“œ ì˜ì—­ ê·¸ë¦¬ê¸° (ì„  ë‘ê»˜ ì¤„ì„)
                                        cv2.polylines(display_frame, [display_points], True, box_color, 2)
                                        
                                        # í…ìŠ¤íŠ¸ í‘œì‹œ (í•˜ì´í”ˆ ë¬¸ì ì •ë¦¬)
                                        display_text = qr_text[:30] + "..." if len(qr_text) > 30 else qr_text
                                        # OpenCV putTextì—ì„œ ë¬¸ì œê°€ ë˜ëŠ” íŠ¹ìˆ˜ ë¬¸ìë“¤ì„ í‘œì¤€ í•˜ì´í”ˆìœ¼ë¡œ ë³€ê²½
                                        display_text = display_text.replace('â€“', '-').replace('â€”', '-').replace('âˆ’', '-')
                                        display_text = display_text.replace('ï¼Ÿ', '?').replace('ï¼', '!').replace('ï¼Œ', ',')
                                        text_pos = (int(display_points[0][0]), int(display_points[0][1]) - 15 - (j * 20))
                                        cv2.putText(display_frame, display_text, text_pos, cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1)
                                        
                                        # íƒì§€ ë°©ë²• í‘œì‹œ (ì²« ë²ˆì§¸ QRë§Œ, í•œê¸€ í°íŠ¸ ì‚¬ìš©)
                                        if j == 0:
                                            method_text = f"Method: {qr_method}"
                                            display_frame = put_korean_text(display_frame, method_text, (10, 25), font_size=16, color=text_color)
                                    else:
                                        pass  # points_2d ë³€í™˜ ì‹¤íŒ¨ (ì½˜ì†” ì¶œë ¥ ì œê±°)
                                except Exception as e:
                                    pass  # ê°œë³„ QR ì‹œê°í™” ì˜¤ë¥˜ (ì½˜ì†” ì¶œë ¥ ì œê±°)
                        except Exception as e:
                            print(f"    âŒ ì‹œê°í™” ì˜¤ë¥˜: {e}")
                            # ê¸°ë³¸ ì‹œê°í™” (í°íŠ¸ í¬ê¸° ì¤„ì„, í•˜ì´í”ˆ ë¬¸ì ì •ë¦¬)
                            text = detected_text[:30] + "..." if len(detected_text) > 30 else detected_text
                            text = text.replace('â€“', '-').replace('â€”', '-').replace('âˆ’', '-')
                            text = text.replace('ï¼Ÿ', '?').replace('ï¼', '!').replace('ï¼Œ', ',')
                            cv2.putText(display_frame, text, (50, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
                            method_text = f"Method: {detection_method}"
                            display_frame = put_korean_text(display_frame, method_text, (10, 25), font_size=16, color=(0, 255, 0))
                    else:
                        # ì‹œê°í™” ë°ì´í„°ê°€ ì—†ì„ ë•Œ ê¸°ë³¸ ì‹œê°í™” (í°íŠ¸ í¬ê¸° ì¤„ì„, í•˜ì´í”ˆ ë¬¸ì ì •ë¦¬)
                        print(f"    âš ï¸ ì‹œê°í™” ë°ì´í„° ì—†ìŒ")
                        text = detected_text[:30] + "..." if len(detected_text) > 30 else detected_text
                        text = text.replace('â€“', '-').replace('â€”', '-').replace('âˆ’', '-')
                        text = text.replace('ï¼Ÿ', '?').replace('ï¼', '!').replace('ï¼Œ', ',')
                        cv2.putText(display_frame, text, (50, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
                        method_text = f"Method: {detection_method}"
                        display_frame = put_korean_text(display_frame, method_text, (10, 25), font_size=16, color=(0, 255, 0))
                    
                    # ê²°ê³¼ ì €ì¥ (í•´ë… ì‹¤íŒ¨ ì‹œ failed í´ë”ì— ì €ì¥)
                    if "ì‹¤íŒ¨" in detected_text or "ì‹¤íŒ¨" in detection_method:
                        result_path = os.path.join(output_dir, "failed", f"frame_{frame_count:06d}.jpg")
                        failed_count += 1
                    else:
                        result_path = os.path.join(output_dir, "enhanced", f"frame_{frame_count:06d}.jpg")
                        success_count += 1
                    
                    # ì‹œê°í™”ëœ í”„ë ˆì„ ì €ì¥
                    cv2.imwrite(result_path, display_frame)
                
            except Exception as e:
                print(f"  âŒ í”„ë ˆì„ {frame_count} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        
        # ì„±ëŠ¥ ì •ë³´ í‘œì‹œ
        fps_counter += 1
        if fps_counter % 30 == 0:  # 30í”„ë ˆì„ë§ˆë‹¤ FPS ê³„ì‚°
            elapsed = time.time() - fps_start_time
            current_fps = 30 / elapsed if elapsed > 0 else 0
            fps_start_time = time.time()
            
            # ì„±ëŠ¥ ì •ë³´ í…ìŠ¤íŠ¸
            info_text = f"FPS: {current_fps:.1f} | Frame: {frame_count}/{total_frames} | QR: {detected_count}"
            cv2.putText(display_frame, info_text, (10, display_height - 20), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        # ì¼ì‹œì •ì§€ ìƒíƒœ í‘œì‹œ
        if paused:
            cv2.putText(display_frame, "PAUSED - Press SPACE to resume", (10, 60), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
        
        # í™”ë©´ì— í‘œì‹œ
        cv2.imshow("Video Player + QR Detection", display_frame)
        
        # í‚¤ ì…ë ¥ ì²˜ë¦¬
        key = cv2.waitKey(1) & 0xFF
        
        if key == 27:  # ESC í‚¤
            print("\nğŸ›‘ ì‚¬ìš©ìê°€ ì¢…ë£Œí–ˆìŠµë‹ˆë‹¤.")
            break
        elif key == ord(' '):  # SPACE í‚¤
            paused = not paused
            if paused:
                print("â¸ï¸  ì¼ì‹œì •ì§€")
            else:
                print("â–¶ï¸  ì¬ìƒ")
        elif key == ord('s'):  # S í‚¤
            # í˜„ì¬ í”„ë ˆì„ ì €ì¥ (ì‹œê°í™”ëœ ìƒíƒœë¡œ)
            save_path = os.path.join(output_dir, f"screenshot_{frame_count:06d}.jpg")
            cv2.imwrite(save_path, display_frame)
            print(f"ğŸ“· ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {save_path}")
    
    # ì •ë¦¬
    cap.release()
    cv2.destroyAllWindows()
    
    # ê²°ê³¼ ìš”ì•½
    elapsed = time.time() - start_time
    # ğŸ• ì „ì²´ ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
    total_end_time = time.time()
    total_execution_time = total_end_time - total_start_time
    
    print(f"\nğŸ“Š ê²°ê³¼ í†µê³„!")
    print(f"  ì´ í”„ë ˆì„: {total_frames}")
    print(f"  ì¬ìƒ ì‹œê°„: {elapsed:.1f}ì´ˆ")
    print(f"  ğŸš€ ì´ ì‹¤í–‰ ì‹œê°„: {total_execution_time:.1f}ì´ˆ (ë³‘ë ¬ ì²˜ë¦¬)")
    print(f"  íƒì§€ëœ QR ì½”ë“œ: {detected_count}ê°œ")
    print(f"  íƒì§€ìœ¨: {detected_count/frame_count*100:.1f}%" if frame_count > 0 else "  íƒì§€ìœ¨: 0.0%")
    print(f"  âœ… ì„±ê³µ: {success_count}ê°œ")
    print(f"  âŒ ì‹¤íŒ¨: {failed_count}ê°œ")
    print(f"  ê²°ê³¼ ì €ì¥: {output_dir}/")
    
    print(f"\nğŸ¯ ë°©ë²•ë³„ ì„±ê³µë¥ :")
    total_method_success = sum(method_stats.values())
    for method, count in method_stats.items():
        if total_method_success > 0:
            percentage = (count / total_method_success) * 100
            print(f"  {method}: {count}ê°œ ({percentage:.1f}%)")
    
    print(f"\nğŸ“Š í…ŒìŠ¤íŠ¸ìš© ìƒì„¸ í†µê³„:")
    print(f"  ë°©ë²•ë³„ íƒì§€ ê°œìˆ˜:")
    for method, count in method_detection_count.items():
        print(f"    {method}: {count}ê°œ")
    
    print(f"  ë°©ë²•ë³„ ì„±ê³µë¥  (íƒì§€ ëŒ€ë¹„):")
    for method in method_stats.keys():
        detected = method_detection_count[method]
        success = method_stats[method]
        if detected > 0:
            success_rate = (success / detected) * 100
            print(f"    {method}: {success}/{detected} ({success_rate:.1f}%)")
        else:
            print(f"    {method}: 0/0 (0.0%)")

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python video_player_qr.py <ë¹„ë””ì˜¤_íŒŒì¼_ê²½ë¡œ>")
        sys.exit(1)
    
    video_path = sys.argv[1]
    video_player_with_qr(video_path)
