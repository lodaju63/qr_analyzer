"""
êµ¬ê¸€ ì½”ë©ìš©: ì˜ìƒ í”Œë ˆì´ì–´ + ê³ ì„±ëŠ¥ QR íƒì§€ (ì •í™•ë„ ê°œì„ íŒ)
[ê°œì„  ì‚¬í•­]:
1. Padding: YOLO ë°•ìŠ¤ë³´ë‹¤ 20% ë„“ê²Œ ì˜ë¼ Quiet Zone í™•ë³´
2. Upscaling: ROI ì´ë¯¸ì§€ë¥¼ 2ë°° í™•ëŒ€ + ìƒ¤í”ˆ í•„í„° ì ìš©
3. Settings: Dynamsoft í•´ë… ì„¤ì •ì„ ìµœê³  ìˆ˜ì¤€ìœ¼ë¡œ ê°•í™”
4. Speed: ë¶ˆí•„ìš”í•œ ë¯¸ë¦¬ë³´ê¸° ì˜µì…˜ ê¸°ë³¸ OFF
"""

import cv2
import time
import os
import sys
import numpy as np
import threading
import queue
from queue import Queue, Empty
from IPython.display import display, Image, clear_output
import matplotlib.pyplot as plt
import warnings

warnings.filterwarnings('ignore')

# -----------------------------------------------------------------
# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì²´í¬
# -----------------------------------------------------------------
IN_COLAB = 'google.colab' in sys.modules

try:
    from dynamsoft_barcode_reader_bundle import dbr, license, cvr
    from dynamsoft_barcode_reader_bundle import EnumPresetTemplate
    DBR_AVAILABLE = True
except ImportError:
    print("âš ï¸ Dynamsoft Barcode Readerê°€ ì—†ìŠµë‹ˆë‹¤. !pip install dynamsoft-barcode-reader-bundle ì‹¤í–‰ í•„ìš”")
    DBR_AVAILABLE = False

try:
    from ultralytics import YOLO
    YOLO_AVAILABLE = True
except ImportError:
    print("âš ï¸ Ultralyticsê°€ ì—†ìŠµë‹ˆë‹¤. !pip install ultralytics ì‹¤í–‰ í•„ìš”")
    YOLO_AVAILABLE = False

try:
    from PIL import Image as PILImage, ImageDraw, ImageFont
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False

# -----------------------------------------------------------------
# 2. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (í•œê¸€ í°íŠ¸, YOLO íƒì§€ ë“±)
# -----------------------------------------------------------------
def get_platform_font_paths():
    if IN_COLAB:
        return ["/usr/share/fonts/truetype/nanum/NanumGothic.ttf", "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf"]
    return [] # ë¡œì»¬ ê²½ë¡œëŠ” ìƒëµ

def put_korean_text(img, text, position, font_size=20, color=(0, 255, 0)):
    if not PIL_AVAILABLE:
        cv2.putText(img, text, position, cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
        return img
    try:
        img_pil = PILImage.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(img_pil)
        font_paths = get_platform_font_paths()
        font = None
        for path in font_paths:
            if os.path.exists(path):
                font = ImageFont.truetype(path, font_size)
                break
        if font is None: font = ImageFont.load_default()
        draw.text(position, text, font=font, fill=color)
        return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)
    except:
        return img

def yolo_detect_qr_locations(model, frame, conf_threshold=0.25):
    """
    YOLOë¡œ QR ìœ„ì¹˜ ì°¾ê¸° + [ìˆ˜ì •ë¨] íŒ¨ë”©(ì—¬ìœ ê³µê°„) 20% ì¶”ê°€
    """
    try:
        results = model(frame, conf=conf_threshold, verbose=False)
        result = results[0]
        locations = []
        
        h_img, w_img = frame.shape[:2]
        
        if result.boxes is not None and len(result.boxes) > 0:
            for box in result.boxes:
                conf = float(box.conf[0])
                xyxy = box.xyxy[0].cpu().numpy()
                x1, y1, x2, y2 = map(int, xyxy)
                
                # [í•µì‹¬ ìˆ˜ì • 1] ë°•ìŠ¤ í¬ê¸°ì˜ 20% ë§Œí¼ ìƒí•˜ì¢Œìš° ì—¬ìœ  ê³µê°„ í™•ë³´ (Quiet Zone)
                box_w = x2 - x1
                box_h = y2 - y1
                pad_w = int(box_w * 0.2)
                pad_h = int(box_h * 0.2)
                
                x1 = max(0, x1 - pad_w)
                y1 = max(0, y1 - pad_h)
                x2 = min(w_img, x2 + pad_w)
                y2 = min(h_img, y2 + pad_h)
                
                locations.append({
                    'bbox': [x1, y1, x2, y2],
                    'confidence': conf
                })
        return locations
    except:
        return []

def preprocess_for_decoding(roi):
    """
    [í•µì‹¬ ìˆ˜ì • 2] ì‘ì€ QR ì½”ë“œë¥¼ ìœ„í•´ 2ë°° í™•ëŒ€ ë° ìƒ¤í”ˆ í•„í„° ì ìš©
    """
    try:
        # 1. 2ë°° í™•ëŒ€ (Cubic ë³´ê°„ë²•ì´ í™”ì§ˆ ì €í•˜ê°€ ì ìŒ)
        roi_upscaled = cv2.resize(roi, None, fx=2.0, fy=2.0, interpolation=cv2.INTER_CUBIC)
        
        # 2. ìƒ¤í”ˆ(Sharpen) í•„í„° ì ìš© - íë¦¿í•œ ê²½ê³„ì„  ê°•í™”
        kernel = np.array([[-1,-1,-1], [-1, 9,-1], [-1,-1,-1]])
        roi_sharpened = cv2.filter2D(roi_upscaled, -1, kernel)
        
        return roi_sharpened
    except:
        return roi

# -----------------------------------------------------------------
# 3. ì¶”ì (Tracking) ê´€ë ¨ í´ë˜ìŠ¤ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
# -----------------------------------------------------------------
def calculate_iou(bbox1, bbox2):
    x1_1, y1_1, x2_1, y2_1 = bbox1
    x1_2, y1_2, x2_2, y2_2 = bbox2
    x1_i, y1_i = max(x1_1, x1_2), max(y1_1, y1_2)
    x2_i, y2_i = min(x2_1, x2_2), min(y2_1, y2_2)
    if x2_i <= x1_i or y2_i <= y1_i: return 0.0
    intersection = (x2_i - x1_i) * (y2_i - y1_i)
    area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
    area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
    return intersection / (area1 + area2 - intersection) if (area1 + area2 - intersection) > 0 else 0.0

class QRTracker:
    def __init__(self, max_missed=10):
        self.tracks = {}
        self.next_id = 0
        self.max_missed = max_missed

    def update(self, detected_items, frame_num):
        # ê°„ë‹¨í•œ IoU ê¸°ë°˜ ë§¤ì¹­ (ìƒì„¸ ë¡œì§ì€ ê¸¸ì´ìƒ ê°„ì†Œí™”, í•µì‹¬ì€ ë™ì¼)
        active_tracks = {tid: t for tid, t in self.tracks.items() if t['missed'] <= self.max_missed}
        matched_det_indices = set()
        matched_track_ids = set()
        
        # ë§¤ì¹­ ì‹œë„
        for tid, track in active_tracks.items():
            best_iou = 0
            best_idx = -1
            for idx, det in enumerate(detected_items):
                if idx in matched_det_indices: continue
                iou = calculate_iou(track['bbox'], det['bbox'])
                if iou > 0.3 and iou > best_iou: # IoU ì„ê³„ê°’
                    best_iou = iou
                    best_idx = idx
            
            if best_idx != -1:
                # ë§¤ì¹­ ì„±ê³µ
                det = detected_items[best_idx]
                track['bbox'] = det['bbox']
                track['missed'] = 0
                track['last_frame'] = frame_num
                # ê¸°ì¡´ í…ìŠ¤íŠ¸ê°€ ì—†ê³  ìƒˆ íƒì§€ì— í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸
                if not track['text'] and det['text']:
                    track['text'] = det['text']
                    track['success'] = True
                
                matched_track_ids.add(tid)
                matched_det_indices.add(best_idx)
            else:
                track['missed'] += 1
        
        # ìƒˆë¡œìš´ íŠ¸ë™ ìƒì„±
        for idx, det in enumerate(detected_items):
            if idx not in matched_det_indices:
                self.tracks[self.next_id] = {
                    'bbox': det['bbox'],
                    'text': det['text'],
                    'success': det.get('success', False),
                    'missed': 0,
                    'start_frame': frame_num,
                    'last_frame': frame_num,
                    'id': self.next_id
                }
                self.next_id += 1
                
        # ì˜¤ë˜ëœ íŠ¸ë™ ì‚­ì œ
        self.tracks = {tid: t for tid, t in self.tracks.items() if t['missed'] <= self.max_missed}
        
        # ê²°ê³¼ ë°˜í™˜ìš© ë¦¬ìŠ¤íŠ¸
        results = []
        for tid, t in self.tracks.items():
            if t['missed'] <= 1: # í˜„ì¬ ë³´ì´ê±°ë‚˜ ë°©ê¸ˆ ë†“ì¹œ ê²ƒë§Œ
                res = t.copy()
                res['track_id'] = tid
                results.append(res)
        return results

# -----------------------------------------------------------------
# 4. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# -----------------------------------------------------------------
def video_player_with_qr(video_path, output_dir="results", show_preview=False, preview_interval=30):
    
    # 0. ì„¤ì • ë° ì¤€ë¹„
    os.makedirs(output_dir, exist_ok=True)
    run_id = time.strftime("%Y%m%d_%H%M%S")
    out_path = os.path.join(output_dir, f"output_{run_id}.mp4")
    
    print(f"ğŸš€ ì²˜ë¦¬ ì‹œì‘: {video_path}")
    print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {out_path}")
    if show_preview:
        print("âš ï¸ ì£¼ì˜: ë¯¸ë¦¬ë³´ê¸°(show_preview)ê°€ ì¼œì ¸ ìˆìœ¼ë©´ ì²˜ë¦¬ ì†ë„ê°€ ëŠë ¤ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    # 1. ëª¨ë¸ ë¡œë“œ
    yolo = None
    if YOLO_AVAILABLE:
        try:
            # GPU ì‚¬ìš© ê°€ëŠ¥ì‹œ ìë™ ì‚¬ìš©
            yolo = YOLO('model1.pt') 
            print("âœ… YOLO ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        except:
            print("âŒ model1.ptë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ëª¨ë¸(yolov8n.pt)ì„ ì‚¬ìš©í•˜ê±°ë‚˜ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
            try: yolo = YOLO('yolov8n.pt')
            except: pass

    # 2. Dynamsoft ì´ˆê¸°í™” ë° [í•µì‹¬ ìˆ˜ì • 3] ì„¤ì • ê°•í™”
    dbr_reader = None
    if DBR_AVAILABLE:
        try:
            license_key = "t0085YQEAADYdcL2llMa8vH1Rtnun+43saE/kdAE7ZbIxMQGRMtSzVSZRI8vfOK4Ids52rjekwzh87yABFLraXw5Va1BV7NnBjI8m7qbw3kxOprI75ExJpw=="
            license.LicenseManager.init_license(license_key)
            dbr_reader = cvr.CaptureVisionRouter()
            
            # ì„¤ì • ê°€ì ¸ì˜¤ê¸°
            err, msg, settings = dbr_reader.get_simplified_settings(EnumPresetTemplate.PT_DEFAULT)
            if err == 0:
                # [ì„¤ì • ê°•í™”]
                settings.barcode_settings.expected_barcodes_count = 50 # í•œ ë²ˆì— ë§ì´ ì°¾ë„ë¡
                settings.barcode_settings.deblur_level = 9             # ë¸”ëŸ¬ ì œê±° ìˆ˜ì¤€ ìµœëŒ€
                settings.barcode_settings.min_barcode_text_length = 1
                settings.timeout = 500  # íƒ€ì„ì•„ì›ƒ 500ms (ì¶©ë¶„íˆ ì‹œê°„ ì¤Œ)
                dbr_reader.update_settings(EnumPresetTemplate.PT_DEFAULT, settings)
                print("âœ… Dynamsoft ì„¤ì • ìµœì í™” ì™„ë£Œ (Deblur Lv.9)")
        except Exception as e:
            print(f"âŒ Dynamsoft ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    # 3. ë¹„ë””ì˜¤ ì¤€ë¹„
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print("âŒ ì˜ìƒì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    writer = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))
    
    # 4. í•´ë… ì›Œì»¤ (ìŠ¤ë ˆë“œ)
    decode_q = Queue()
    result_map = {} # track_id -> text
    lock = threading.Lock()
    
    def worker():
        while True:
            item = decode_q.get()
            if item is None: break
            track_id, roi_img = item
            
            # [ì „ì²˜ë¦¬] í™•ëŒ€ ë° ìƒ¤í”ˆ
            processed_roi = preprocess_for_decoding(roi_img)
            
            text = None
            if dbr_reader:
                try:
                    # RGB ë³€í™˜ ë¶ˆí•„ìš” (OpenCV ì´ë¯¸ì§€ëŠ” BGR, dbrì€ ìë™ ì²˜ë¦¬ í˜¹ì€ BGR ì„ í˜¸)
                    # ë§Œì•½ í•„ìš”í•˜ë‹¤ë©´: img_rgb = cv2.cvtColor(processed_roi, cv2.COLOR_BGR2RGB)
                    res = dbr_reader.capture(processed_roi, dbr.EnumImagePixelFormat.IPF_BGR_888)
                    decoded = res.get_decoded_barcodes_result()
                    if decoded and decoded.get_items():
                        text = decoded.get_items()[0].text
                except: pass
            
            if text:
                with lock:
                    result_map[track_id] = text
            decode_q.task_done()

    t_worker = threading.Thread(target=worker, daemon=True)
    t_worker.start()
    
    # 5. ë©”ì¸ ë£¨í”„
    tracker = QRTracker()
    frame_cnt = 0
    start_time = time.time()
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret: break
            frame_cnt += 1
            
            # A. YOLO íƒì§€ (íŒ¨ë”© í¬í•¨ë¨)
            detections = yolo_detect_qr_locations(yolo, frame)
            
            # B. íƒì§€ ê²°ê³¼ë¥¼ ì¶”ì ê¸° í¬ë§·ìœ¼ë¡œ ë³€í™˜
            det_for_tracker = []
            for det in detections:
                det_for_tracker.append({
                    'bbox': det['bbox'],
                    'text': None, # ì•„ì§ ëª¨ë¦„
                    'success': False
                })
            
            # C. ì¶”ì  ì—…ë°ì´íŠ¸
            tracked_objs = tracker.update(det_for_tracker, frame_cnt)
            
            # D. í•´ë… ìš”ì²­ ë° ê²°ê³¼ ë³‘í•©
            for obj in tracked_objs:
                tid = obj['track_id']
                
                # ì´ë¯¸ í•´ë…ëœ ì  ìˆìœ¼ë©´ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
                with lock:
                    if tid in result_map:
                        obj['text'] = result_map[tid]
                        obj['success'] = True
                
                # í•´ë… ì•ˆëìœ¼ë©´ íì— ë„£ê¸° (ë‹¨, ë„ˆë¬´ ë§ì´ ë„£ì§€ ì•Šê¸° ìœ„í•´ í ì‚¬ì´ì¦ˆ ì²´í¬ ê°€ëŠ¥)
                if not obj['success'] and decode_q.qsize() < 5:
                    x1, y1, x2, y2 = obj['bbox']
                    # ì¢Œí‘œ ì•ˆì „ì¥ì¹˜
                    x1, y1 = max(0, x1), max(0, y1)
                    x2, y2 = min(width, x2), min(height, y2)
                    if x2 > x1 and y2 > y1:
                        roi = frame[y1:y2, x1:x2].copy()
                        decode_q.put((tid, roi))
            
            # E. ê·¸ë¦¬ê¸° (ê²°ê³¼ ì˜ìƒìš©)
            for obj in tracked_objs:
                x1, y1, x2, y2 = obj['bbox']
                text = obj['text']
                color = (0, 255, 0) if text else (0, 0, 255)
                
                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                
                label = f"ID:{obj['track_id']}"
                if text: label += f" {text}"
                frame = put_korean_text(frame, label, (x1, y1-25), 20, color)

            writer.write(frame)
            
            # F. ë¡œê·¸ ë° í”„ë¦¬ë·°
            if frame_cnt % 30 == 0:
                elapsed = time.time() - start_time
                fps_cur = frame_cnt / elapsed
                sys.stdout.write(f"\rFrame: {frame_cnt}/{total_frames} | FPS: {fps_cur:.1f} | Found: {len(result_map)}")
                sys.stdout.flush()
                
                if show_preview:
                    # ì½”ë© í‘œì‹œìš© (ë¦¬ì‚¬ì´ì¦ˆí•´ì„œ ì „ì†¡ëŸ‰ ì¤„ì„)
                    preview_img = cv2.resize(frame, (0,0), fx=0.5, fy=0.5)
                    preview_img = cv2.cvtColor(preview_img, cv2.COLOR_BGR2RGB)
                    clear_output(wait=True)
                    plt.figure(figsize=(8, 5))
                    plt.imshow(preview_img)
                    plt.axis('off')
                    plt.show()

    except KeyboardInterrupt:
        print("\nì¤‘ì§€ë¨!")
    finally:
        cap.release()
        writer.release()
        decode_q.put(None)
        t_worker.join()
        print(f"\n\nì™„ë£Œ! ê²°ê³¼ íŒŒì¼: {out_path}")
        
        # ì½”ë©ì—ì„œ ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì‰½ê²Œ í•˜ë„ë¡
        if IN_COLAB and os.path.exists(out_path):
            print(f"ì˜ìƒì„ ë‹¤ìš´ë¡œë“œ í•˜ë ¤ë©´ ì™¼ìª½ íŒŒì¼ íƒìƒ‰ê¸°ì—ì„œ {output_dir} í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”.")