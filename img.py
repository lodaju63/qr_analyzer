"""
ì´ë¯¸ì§€ ì „ìš© QR ì½”ë“œ íƒì§€ ì‹œìŠ¤í…œ (Streamlit)
YOLO + U-Net/SegFormer + Transformer ë°©ì‹
ë‹¤ì–‘í•œ ì „ì²˜ë¦¬ ì˜µì…˜ ì œê³µ
"""

import streamlit as st
import cv2
import numpy as np
import os
import sys
import warnings
from PIL import Image
import torch
import torch.nn.functional as F
from typing import Tuple, List, Optional, Dict
import logging
import io
import zipfile

warnings.filterwarnings('ignore')

# Streamlit ë¡œê±° ë ˆë²¨ ì¡°ì •
logging.getLogger('streamlit').setLevel(logging.CRITICAL)

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì´ë¯¸ì§€ QR íƒì§€ ì‹œìŠ¤í…œ",
    page_icon="ğŸ–¼ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ============================================================================
# 1. ì „ì²˜ë¦¬ í•¨ìˆ˜ë“¤
# ============================================================================

def denoise_gaussian(image: np.ndarray, kernel_size: int = 5) -> np.ndarray:
    """Gaussian Blurë¡œ ì¼ë°˜ ì¡ìŒ ì œê±°"""
    if len(image.shape) == 3:
        return cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)
    else:
        return cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)

def denoise_median(image: np.ndarray, kernel_size: int = 5) -> np.ndarray:
    """Median Filterë¡œ salt-pepper ë…¸ì´ì¦ˆ ì œê±°"""
    if len(image.shape) == 3:
        return cv2.medianBlur(image, kernel_size)
    else:
        return cv2.medianBlur(image, kernel_size)

def denoise_bilateral(image: np.ndarray, d: int = 9, sigma_color: float = 75, sigma_space: float = 75) -> np.ndarray:
    """Bilateral Filter - ì—£ì§€ë¥¼ ë³´ì¡´í•˜ë©´ì„œ ë…¸ì´ì¦ˆ ì œê±°"""
    if len(image.shape) == 3:
        return cv2.bilateralFilter(image, d, sigma_color, sigma_space)
    else:
        return cv2.bilateralFilter(image, d, sigma_color, sigma_space)

def enhance_clahe(image: np.ndarray, clip_limit: float = 2.0, tile_grid_size: Tuple[int, int] = (8, 8)) -> np.ndarray:
    """CLAHE (Contrast Limited Adaptive Histogram Equalization)"""
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image.copy()
    
    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)
    enhanced = clahe.apply(gray)
    
    if len(image.shape) == 3:
        return cv2.cvtColor(enhanced, cv2.COLOR_GRAY2BGR)
    return enhanced

def enhance_gamma(image: np.ndarray, gamma: float = 1.0) -> np.ndarray:
    """Gamma Correction"""
    inv_gamma = 1.0 / gamma
    table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype("uint8")
    return cv2.LUT(image, table)

def enhance_retinex(image: np.ndarray, sigma_list: List[float] = [15, 80, 250]) -> np.ndarray:
    """Multi-Scale Retinex (MSR)"""
    # ê°„ë‹¨í•œ êµ¬í˜„ (SSR)
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY).astype(np.float32)
    else:
        gray = image.astype(np.float32)
    
    retinex = np.zeros_like(gray)
    for sigma in sigma_list:
        gaussian = cv2.GaussianBlur(gray, (0, 0), sigma)
        retinex += np.log10(gray + 1) - np.log10(gaussian + 1)
    
    retinex = retinex / len(sigma_list)
    retinex = (retinex - retinex.min()) / (retinex.max() - retinex.min()) * 255
    retinex = retinex.astype(np.uint8)
    
    if len(image.shape) == 3:
        return cv2.cvtColor(retinex, cv2.COLOR_GRAY2BGR)
    return retinex

def invert_image(image: np.ndarray) -> np.ndarray:
    """ì´ë¯¸ì§€ ë°˜ì „"""
    return cv2.bitwise_not(image)

def adaptive_threshold_gaussian(image: np.ndarray, max_value: int = 255, 
                                block_size: int = 11, c: int = 2) -> np.ndarray:
    """Gaussian Adaptive Thresholding"""
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image.copy()
    
    return cv2.adaptiveThreshold(gray, max_value, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                 cv2.THRESH_BINARY, block_size, c)

def adaptive_threshold_mean(image: np.ndarray, max_value: int = 255, 
                            block_size: int = 11, c: int = 2) -> np.ndarray:
    """Mean Adaptive Thresholding"""
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image.copy()
    
    return cv2.adaptiveThreshold(gray, max_value, cv2.ADAPTIVE_THRESH_MEAN_C, 
                                 cv2.THRESH_BINARY, block_size, c)

def threshold_otsu(image: np.ndarray) -> np.ndarray:
    """Otsu Thresholding"""
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image.copy()
    
    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    return binary

def morphology_closing(image: np.ndarray, kernel_size: int = 5) -> np.ndarray:
    """Closing (íŒ½ì°½ â†’ ì¹¨ì‹) - ëŠì–´ì§„ íŒ¨í„´ ì—°ê²°"""
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size, kernel_size))
    return cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)

def morphology_opening(image: np.ndarray, kernel_size: int = 5) -> np.ndarray:
    """Opening (ì¹¨ì‹ â†’ íŒ½ì°½) - ë…¸ì´ì¦ˆ ì œê±°"""
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size, kernel_size))
    return cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)

def morphology_dilation(image: np.ndarray, kernel_size: int = 5, iterations: int = 1) -> np.ndarray:
    """Dilation - íŒ¨í„´ ë³´ê°•"""
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size, kernel_size))
    return cv2.dilate(image, kernel, iterations=iterations)

def correct_perspective(image: np.ndarray, src_points: Optional[np.ndarray] = None) -> np.ndarray:
    """Perspective Transform - QR ì½”ë“œë¥¼ ì •ë©´ìœ¼ë¡œ ë³´ì •"""
    h, w = image.shape[:2]
    
    if src_points is None:
        # ìë™ìœ¼ë¡œ QR finder patternì„ ì°¾ì•„ì„œ ë³´ì •í•˜ëŠ” ë¡œì§
        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ì›ë³¸ ë°˜í™˜ (ì‹¤ì œë¡œëŠ” QR íƒì§€ í›„ finder pattern ê¸°ë°˜ ë³€í™˜)
        return image
    
    # ëª©ì ì§€ í¬ì¸íŠ¸ (ì •ì‚¬ê°í˜•)
    dst_points = np.array([[0, 0], [w, 0], [w, h], [0, h]], dtype=np.float32)
    
    # Homography ê³„ì‚°
    M = cv2.getPerspectiveTransform(src_points.astype(np.float32), dst_points)
    
    # Perspective ë³€í™˜
    return cv2.warpPerspective(image, M, (w, h))

def correct_rotation(image: np.ndarray, angle: float = 0) -> np.ndarray:
    """Rotation Correction"""
    if angle == 0:
        return image
    
    h, w = image.shape[:2]
    center = (w // 2, h // 2)
    M = cv2.getRotationMatrix2D(center, angle, 1.0)
    return cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)

def super_resolution(image: np.ndarray, scale: float = 2.0) -> np.ndarray:
    """Super Resolution - ê°„ë‹¨í•œ ì—…ìŠ¤ì¼€ì¼ë§ (ì‹¤ì œë¡œëŠ” SRGAN ë“±ì„ ì‚¬ìš©)"""
    h, w = image.shape[:2]
    new_h, new_w = int(h * scale), int(w * scale)
    return cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)

def deblur_lucy_richardson(image: np.ndarray, iterations: int = 30, sigma: float = 1.5) -> np.ndarray:
    """Lucy-Richardson Deblurring (ê°„ë‹¨í•œ êµ¬í˜„)"""
    # ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ êµ¬í˜„ì´ í•„ìš”
    # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ unsharp masking
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image.copy()
    
    gaussian = cv2.GaussianBlur(gray, (0, 0), sigma)
    unsharp = cv2.addWeighted(gray, 1.5, gaussian, -0.5, 0)
    
    if len(image.shape) == 3:
        return cv2.cvtColor(unsharp, cv2.COLOR_GRAY2BGR)
    return unsharp

def inpainting_telea(image: np.ndarray, mask: Optional[np.ndarray] = None) -> np.ndarray:
    """Telea Inpainting"""
    if mask is None:
        return image
    
    return cv2.inpaint(image, mask, 3, cv2.INPAINT_TELEA)

def inpainting_ns(image: np.ndarray, mask: Optional[np.ndarray] = None) -> np.ndarray:
    """Navier-Stokes Inpainting"""
    if mask is None:
        return image
    
    return cv2.inpaint(image, mask, 3, cv2.INPAINT_NS)

# ============================================================================
# 2. í†µí•© ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
# ============================================================================

def apply_preprocessing(image: np.ndarray, options: Dict) -> np.ndarray:
    """ì „ì²˜ë¦¬ ì˜µì…˜ì— ë”°ë¼ ì´ë¯¸ì§€ ì²˜ë¦¬"""
    result = image.copy()
    
    # 1. ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜ (í•„ìš”ì‹œ)
    if options.get('convert_grayscale', False):
        if len(result.shape) == 3:
            result = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY)
            result = cv2.cvtColor(result, cv2.COLOR_GRAY2BGR)
    
    # 2. ë…¸ì´ì¦ˆ ì œê±°
    if options.get('denoise_enabled', False):
        denoise_method = options.get('denoise_method', 'bilateral')
        if denoise_method == 'gaussian':
            result = denoise_gaussian(result, options.get('gaussian_kernel', 5))
        elif denoise_method == 'median':
            result = denoise_median(result, options.get('median_kernel', 5))
        elif denoise_method == 'bilateral':
            result = denoise_bilateral(result, 
                                      options.get('bilateral_d', 9),
                                      options.get('bilateral_sigma_color', 75),
                                      options.get('bilateral_sigma_space', 75))
    
    # 3. ëª…ì•”/ì¡°ëª… ë³´ì •
    if options.get('enhancement_enabled', False):
        enhancement_methods = options.get('enhancement_methods', [])
        if 'clahe' in enhancement_methods:
            result = enhance_clahe(result, 
                                  options.get('clahe_clip_limit', 2.0),
                                  tuple(options.get('clahe_tile_size', [8, 8])))
        if 'gamma' in enhancement_methods:
            result = enhance_gamma(result, options.get('gamma_value', 1.0))
        if 'retinex' in enhancement_methods:
            result = enhance_retinex(result, options.get('retinex_sigma', [15, 80, 250]))
    
    # 4. ë°˜ì „ ì²˜ë¦¬
    if options.get('invert', False):
        result = invert_image(result)
    
    # 5. Super Resolution
    if options.get('super_resolution_enabled', False):
        result = super_resolution(result, options.get('sr_scale', 2.0))
    
    # 6. Deblurring
    if options.get('deblur_enabled', False):
        result = deblur_lucy_richardson(result, 
                                       options.get('deblur_iterations', 30),
                                       options.get('deblur_sigma', 1.5))
    
    # 7. ì´ì§„í™”
    if options.get('binarization_enabled', False):
        binarization_method = options.get('binarization_method', 'adaptive_gaussian')
        if binarization_method == 'adaptive_gaussian':
            result = adaptive_threshold_gaussian(result,
                                               options.get('adaptive_max_value', 255),
                                               options.get('adaptive_block_size', 11),
                                               options.get('adaptive_c', 2))
        elif binarization_method == 'adaptive_mean':
            result = adaptive_threshold_mean(result,
                                           options.get('adaptive_max_value', 255),
                                           options.get('adaptive_block_size', 11),
                                           options.get('adaptive_c', 2))
        elif binarization_method == 'otsu':
            result = threshold_otsu(result)
        
        # ì´ì§„í™” í›„ BGRë¡œ ë³€í™˜
        if len(result.shape) == 2:
            result = cv2.cvtColor(result, cv2.COLOR_GRAY2BGR)
    
    # 8. í˜•íƒœí•™ì  ì—°ì‚°
    if options.get('morphology_enabled', False):
        morphology_ops = options.get('morphology_operations', [])
        kernel_size = options.get('morphology_kernel_size', 5)
        
        # ì´ì§„í™”ëœ ì´ë¯¸ì§€ì—ì„œë§Œ í˜•íƒœí•™ì  ì—°ì‚°
        if len(result.shape) == 3:
            gray = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY)
        else:
            gray = result.copy()
        
        for op in morphology_ops:
            if op == 'closing':
                gray = morphology_closing(gray, kernel_size)
            elif op == 'opening':
                gray = morphology_opening(gray, kernel_size)
            elif op == 'dilation':
                gray = morphology_dilation(gray, kernel_size, 
                                         options.get('dilation_iterations', 1))
        
        if len(image.shape) == 3:
            result = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)
        else:
            result = gray
    
    # 9. ê¸°í•˜í•™ì  ë³´ì •
    if options.get('geometric_enabled', False):
        if options.get('rotation_angle', 0) != 0:
            result = correct_rotation(result, options.get('rotation_angle', 0))
        if options.get('perspective_correction', False):
            result = correct_perspective(result)
    
    return result

# ============================================================================
# 3. ë”¥ëŸ¬ë‹ ëª¨ë¸ í†µí•© (í”Œë ˆì´ìŠ¤í™€ë”)
# ============================================================================

def load_unet_model(model_path: Optional[str] = None):
    """U-Net ëª¨ë¸ ë¡œë“œ (í”Œë ˆì´ìŠ¤í™€ë”)"""
    # TODO: ì‹¤ì œ U-Net ëª¨ë¸ ë¡œë“œ
    return None

def load_segformer_model(model_path: Optional[str] = None):
    """SegFormer ëª¨ë¸ ë¡œë“œ (í”Œë ˆì´ìŠ¤í™€ë”)"""
    # TODO: ì‹¤ì œ SegFormer ëª¨ë¸ ë¡œë“œ
    return None

def enhance_with_unet(image: np.ndarray, model) -> np.ndarray:
    """U-Netìœ¼ë¡œ ì´ë¯¸ì§€ ë³µì›/í–¥ìƒ"""
    if model is None:
        return image
    # TODO: U-Net ì¶”ë¡  ë¡œì§
    return image

def enhance_with_segformer(image: np.ndarray, model) -> np.ndarray:
    """SegFormerë¡œ ì´ë¯¸ì§€ ë³µì›/í–¥ìƒ"""
    if model is None:
        return image
    # TODO: SegFormer ì¶”ë¡  ë¡œì§
    return image

def load_transformer_decoder(model_path: Optional[str] = None):
    """Transformer Decoder ëª¨ë¸ ë¡œë“œ (í”Œë ˆì´ìŠ¤í™€ë”)"""
    # TODO: ì‹¤ì œ Transformer Decoder ëª¨ë¸ ë¡œë“œ
    return None

def decode_with_transformer(image: np.ndarray, model) -> str:
    """Transformer Decoderë¡œ QR ì½”ë“œ í•´ë…"""
    if model is None:
        return ""
    # TODO: Transformer ì¶”ë¡  ë¡œì§
    return ""

# ============================================================================
# 4. YOLO íƒì§€ ë° í•´ë…
# ============================================================================

def detect_qr_with_yolo(image: np.ndarray, yolo_model, conf_threshold: float = 0.25) -> List[Dict]:
    """YOLOë¡œ QR ì½”ë“œ ìœ„ì¹˜ íƒì§€ (ì¼ë°˜ ë””í…ì…˜ ëª¨ë¸)"""
    try:
        from ultralytics import YOLO
        results = yolo_model(image, conf=conf_threshold, verbose=False)
        result = results[0]
        
        detections = []
        h, w = image.shape[:2]
        
        # ì¼ë°˜ detection ëª¨ë¸ ì²˜ë¦¬
        if result.boxes is not None and len(result.boxes) > 0:
            for box in result.boxes:
                conf = float(box.conf[0])
                xyxy = box.xyxy[0].cpu().numpy()
                x1, y1, x2, y2 = map(int, xyxy)
                
                # íŒ¨ë”© ì¶”ê°€ (QR ì½”ë“œ ê²½ê³„ í™•ë³´)
                pad = 20
                x1 = max(0, x1 - pad)
                y1 = max(0, y1 - pad)
                x2 = min(w, x2 + pad)
                y2 = min(h, y2 + pad)
                
                detections.append({
                    'bbox': [x1, y1, x2, y2],
                    'confidence': conf
                })
        
        return detections
    except Exception as e:
        st.error(f"YOLO íƒì§€ ì˜¤ë¥˜: {e}")
        return []

def decode_qr_with_dynamsoft(image: np.ndarray, dbr_reader) -> Tuple[str, Optional[np.ndarray]]:
    """Dynamsoftë¡œ QR ì½”ë“œ í•´ë…"""
    try:
        from dynamsoft_barcode_reader_bundle import dbr as dbr_module
        
        if dbr_reader is None:
            return "", None
        
        # RGB ë³€í™˜
        if len(image.shape) == 3 and image.shape[2] == 3:
            rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        else:
            rgb_image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)
        
        captured_result = dbr_reader.capture(rgb_image, dbr_module.EnumImagePixelFormat.IPF_RGB_888)
        barcode_result = captured_result.get_decoded_barcodes_result()
        
        if barcode_result:
            items = barcode_result.get_items() if hasattr(barcode_result, 'get_items') else None
            if items and len(items) > 0:
                barcode_item = items[0]
                text = None
                if hasattr(barcode_item, 'get_text'):
                    text = barcode_item.get_text()
                elif hasattr(barcode_item, 'text'):
                    text = barcode_item.text
                
                # Quad í¬ì¸íŠ¸ ì¶”ì¶œ
                quad_xy = None
                try:
                    location = barcode_item.get_location() if hasattr(barcode_item, 'get_location') else None
                    if location:
                        result_points = location.result_points if hasattr(location, 'result_points') else None
                        if result_points:
                            quad_xy = [[int(p.x), int(p.y)] for p in result_points]
                except:
                    pass
                
                return text or "", quad_xy
        
        return "", None
    except Exception as e:
        st.warning(f"Dynamsoft í•´ë… ì˜¤ë¥˜: {e}")
        return "", None

# ============================================================================
# 5. ì‹œê°í™” í•¨ìˆ˜
# ============================================================================

def visualize_qr_results(image: np.ndarray, decodings: List[Dict]) -> np.ndarray:
    """QR ì½”ë“œ íƒì§€ ê²°ê³¼ë¥¼ ì´ë¯¸ì§€ì— ì‹œê°í™” (ì¼ë°˜ ë””í…ì…˜ ëª¨ë¸)"""
    display_image = image.copy()
    
    # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ì¸ ê²½ìš° BGRë¡œ ë³€í™˜
    if len(display_image.shape) == 2:
        display_image = cv2.cvtColor(display_image, cv2.COLOR_GRAY2BGR)
    
    for i, dec in enumerate(decodings):
        bbox = dec.get('bbox')
        if not bbox or len(bbox) != 4:
            continue
        
        x1, y1, x2, y2 = map(int, bbox)
        color = (0, 255, 0) if dec.get('success') else (0, 0, 255)
        points = None
        
        # Quad ì‚¬ìš© (ìš°ì„ )
        if dec.get('quad') and len(dec['quad']) == 4:
            quad = np.array(dec['quad'])
            if len(quad) == 4:
                quad_array = np.array(quad)
                center = np.mean(quad_array, axis=0)
                angles = np.arctan2(quad_array[:, 1] - center[1], 
                                  quad_array[:, 0] - center[0])
                sorted_indices = np.argsort(angles)
                sorted_quad = quad_array[sorted_indices]
                cv2.polylines(display_image, [sorted_quad], True, color, 2)
                points = sorted_quad
        
        # bbox ì‚¬ìš© (ìµœì¢… fallback)
        else:
            cv2.rectangle(display_image, (x1, y1), (x2, y2), color, 2)
            points = np.array([[x1, y1], [x2, y1], [x2, y2], [x1, y2]], dtype=np.int32)
        
        # QR ë²ˆí˜¸ í‘œì‹œ (pointsê°€ ìˆëŠ” ê²½ìš°)
        if points is not None and len(points) > 0:
            track_id_text = f"#{i}"
            text_pos = (int(points[0][0]), int(points[0][1]) - 10)
            cv2.putText(display_image, track_id_text, text_pos,
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
    
    return display_image

# ============================================================================
# 6. ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜
# ============================================================================

def process_image(image: np.ndarray, preprocessing_options: Dict, 
                 yolo_model, dbr_reader, transformer_model,
                 use_deep_learning: bool = False) -> Dict:
    """ì´ë¯¸ì§€ ì²˜ë¦¬ ë° í•´ë…"""
    
    results = {
        'original_image': image.copy(),
        'original_image_visualized': None,  # ì‹œê°í™”ëœ ì›ë³¸
        'preprocessed_image': None,  # ì „ì²˜ë¦¬ë§Œ (ì‹œê°í™” ì•ˆë¨)
        'preprocessed_image_visualized': None,  # ì „ì²˜ë¦¬ + ì‹œê°í™”
        'original_detections': [],
        'preprocessed_detections': [],
        'original_decodings': [],
        'preprocessed_decodings': []
    }
    
    # YOLO ì‹ ë¢°ë„ ì„ê³„ê°’
    conf_threshold = preprocessing_options.get('conf_threshold', 0.25)
    
    # 1. ì›ë³¸ ì´ë¯¸ì§€ ì²˜ë¦¬
    original_detections = detect_qr_with_yolo(image, yolo_model, conf_threshold)
    results['original_detections'] = original_detections
    
    original_decodings = []
    for det in original_detections:
        x1, y1, x2, y2 = det['bbox']
        roi = image[y1:y2, x1:x2]
        if roi.size > 0:
            text, quad = decode_qr_with_dynamsoft(roi, dbr_reader)
            original_decodings.append({
                'bbox': det['bbox'],
                'confidence': det['confidence'],
                'text': text,
                'quad': quad,
                'success': len(text) > 0
            })
    results['original_decodings'] = original_decodings
    
    # ì›ë³¸ ì´ë¯¸ì§€ ì‹œê°í™”
    results['original_image_visualized'] = visualize_qr_results(
        results['original_image'], original_decodings
    )
    
    # 2. ë”¥ëŸ¬ë‹ í–¥ìƒ (ì„ íƒì )
    enhanced_image = image.copy()
    if use_deep_learning:
        # U-Net ë˜ëŠ” SegFormerë¡œ í–¥ìƒ
        # TODO: ì‹¤ì œ ëª¨ë¸ í†µí•©
        pass
    
    # 3. ì „ì²˜ë¦¬ ì ìš©
    preprocessed_image = apply_preprocessing(enhanced_image, preprocessing_options)
    results['preprocessed_image'] = preprocessed_image
    
    # 4. ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ì²˜ë¦¬
    preprocessed_detections = detect_qr_with_yolo(preprocessed_image, yolo_model, conf_threshold)
    results['preprocessed_detections'] = preprocessed_detections
    
    preprocessed_decodings = []
    for det in preprocessed_detections:
        x1, y1, x2, y2 = det['bbox']
        roi = preprocessed_image[y1:y2, x1:x2]
        if roi.size > 0:
            # Dynamsoft í•´ë…
            text, quad = decode_qr_with_dynamsoft(roi, dbr_reader)
            
            # Transformer í•´ë… (ì‹¤íŒ¨ ì‹œ)
            if not text and transformer_model:
                text = decode_with_transformer(roi, transformer_model)
            
            preprocessed_decodings.append({
                'bbox': det['bbox'],
                'confidence': det['confidence'],
                'text': text,
                'quad': quad,
                'success': len(text) > 0,
            })
    results['preprocessed_decodings'] = preprocessed_decodings
    
    # ì „ì²˜ë¦¬ ì´ë¯¸ì§€ ì‹œê°í™”
    if preprocessed_image is not None:
        results['preprocessed_image_visualized'] = visualize_qr_results(
            preprocessed_image, preprocessed_decodings
        )
    
    return results

# ============================================================================
# 7. Streamlit UI
# ============================================================================

def main():
    st.title("ğŸ–¼ï¸ ì´ë¯¸ì§€ QR ì½”ë“œ íƒì§€ ì‹œìŠ¤í…œ")
    st.markdown("YOLO + U-Net/SegFormer + Transformer ë°©ì‹")
    st.markdown("---")
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'yolo_model' not in st.session_state:
        st.session_state.yolo_model = None
    if 'dbr_reader' not in st.session_state:
        st.session_state.dbr_reader = None
    if 'transformer_model' not in st.session_state:
        st.session_state.transformer_model = None
    if 'results' not in st.session_state:
        st.session_state.results = None
    
    # ì‚¬ì´ë“œë°” - ëª¨ë¸ ì´ˆê¸°í™”
    with st.sidebar:
        st.header("ğŸ”§ ëª¨ë¸ ì´ˆê¸°í™”")
        
        # YOLO ëª¨ë¸
        if st.button("YOLO ëª¨ë¸ ë¡œë“œ", width='stretch'):
            try:
                from ultralytics import YOLO
                model_path = os.environ.get('YOLO_MODEL_PATH', 'model2.pt')  # ê¸°ë³¸ê°’: model2.pt (ì¼ë°˜ ë””í…ì…˜ ëª¨ë¸)
                if os.path.exists(model_path):
                    with st.spinner("YOLO ëª¨ë¸ ë¡œë”© ì¤‘..."):
                        st.session_state.yolo_model = YOLO(model_path)
                    st.success("âœ… YOLO ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                else:
                    st.error(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
            except Exception as e:
                st.error(f"YOLO ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # Dynamsoft ì´ˆê¸°í™”
        if st.button("Dynamsoft ì´ˆê¸°í™”", width='stretch'):
            try:
                from dynamsoft_barcode_reader_bundle import dbr, license, cvr
                license_key = os.environ.get('DYNAMSOFT_LICENSE_KEY', 
                                            't0085YQEAADYdcL2llMa8vH1Rtnun+43saE/kdAE7ZbIxMQGRMtSzVSZRI8vfOK4Ids52rjekwzh87yABFLraXw5Va1BV7NnBjI8m7qbw3kxOprI75ExJpw==')
                error = license.LicenseManager.init_license(license_key)
                if error[0] == 0:
                    st.session_state.dbr_reader = cvr.CaptureVisionRouter()
                    st.success("âœ… Dynamsoft ì´ˆê¸°í™” ì™„ë£Œ")
                else:
                    st.warning(f"ë¼ì´ì„ ìŠ¤ ì˜¤ë¥˜: {error[1]}")
            except Exception as e:
                st.error(f"Dynamsoft ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # Transformer ëª¨ë¸ (ì„ íƒì )
        st.info("ğŸ’¡ **Transformer ëª¨ë¸**: Dynamsoft í•´ë… ì‹¤íŒ¨ ì‹œ í´ë°±ìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.")
        if st.button("Transformer ëª¨ë¸ ë¡œë“œ (ì„ íƒì )", width='stretch'):
            st.info("âš ï¸ Transformer ëª¨ë¸ì€ ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            st.caption("ğŸ’¡ ì–¸ì œ ë¡œë“œí•˜ë‚˜ìš”?")
            st.caption("  â€¢ Dynamsoft í•´ë… ì‹¤íŒ¨ìœ¨ì´ ë†’ì€ ê²½ìš°")
            st.caption("  â€¢ ì‹¬ê°í•˜ê²Œ ì†ìƒëœ ì´ë¯¸ì§€ê°€ ë§ì„ ë•Œ")
            st.caption("  â€¢ ë¼ì´ì„ ìŠ¤ ë¹„ìš© ì ˆê°ì´ í•„ìš”í•œ ê²½ìš°")
            st.caption("  â€¢ ìì„¸í•œ ë‚´ìš©: TRANSFORMER_USAGE_GUIDE.md ì°¸ê³ ")
        
        st.markdown("---")
        
        # YOLO íƒì§€ ì„¤ì •
        st.header("ğŸ¯ YOLO íƒì§€ ì„¤ì •")
        conf_threshold = st.slider(
            "ì‹ ë¢°ë„ ì„ê³„ê°’ (Confidence Threshold)", 
            0.0, 1.0, 0.25, 0.01,
            help="YOLOê°€ QR ì½”ë“œë¥¼ íƒì§€í•˜ëŠ” ìµœì†Œ ì‹ ë¢°ë„ì…ë‹ˆë‹¤.\n"
                 "â€¢ ê°’ì´ ë†’ìœ¼ë©´: ë” í™•ì‹¤í•œ QRë§Œ íƒì§€, ì˜¤íƒì§€ ê°ì†Œ, í•˜ì§€ë§Œ ì¼ë¶€ QR ë†“ì¹  ìˆ˜ ìˆìŒ\n"
                 "â€¢ ê°’ì´ ë‚®ìœ¼ë©´: ë” ë§ì€ QR íƒì§€ ê°€ëŠ¥, í•˜ì§€ë§Œ ì˜¤íƒì§€ ì¦ê°€\n"
                 "â€¢ ê¶Œì¥ê°’: 0.25 (ì¼ë°˜), 0.1 (ì•½í•œ QR), 0.5 (ì •í™•ë„ ìš°ì„ )"
        )
        
        st.markdown("---")
        
        # ì „ì²˜ë¦¬ ì˜µì…˜ ì„¤ì •
        st.header("âš™ï¸ ì „ì²˜ë¦¬ ì˜µì…˜")
        
        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        convert_grayscale = st.checkbox(
            "ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜", 
            value=False,
            help="ì´ë¯¸ì§€ë¥¼ í‘ë°±(ê·¸ë ˆì´ìŠ¤ì¼€ì¼)ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n"
                 "â€¢ ì¥ì : ì²˜ë¦¬ ì†ë„ í–¥ìƒ, ì¼ë¶€ ì „ì²˜ë¦¬ ë°©ë²•ì— ìœ ë¦¬\n"
                 "â€¢ ë‹¨ì : ìƒ‰ìƒ ì •ë³´ ì†ì‹¤\n"
                 "â€¢ ì‚¬ìš© ì‹œê¸°: ìƒ‰ìƒì´ ì¤‘ìš”í•˜ì§€ ì•Šì€ ê²½ìš°"
        )
        
        # 1. ë…¸ì´ì¦ˆ ì œê±°
        st.subheader("1ï¸âƒ£ ë…¸ì´ì¦ˆ ì œê±°")
        st.caption("ì² íŒì˜ ë…¹, ìŠ¤í¬ë˜ì¹˜, ë¨¼ì§€, ìŠ¤íŒŒí¬ ë“± ì¡ìŒì„ ì œê±°í•©ë‹ˆë‹¤. QR íŒ¨í„´ì€ ë³´ì¡´í•©ë‹ˆë‹¤.")
        
        denoise_enabled = st.checkbox(
            "ë…¸ì´ì¦ˆ ì œê±° í™œì„±í™”", 
            value=False,
            help="QR ì½”ë“œ íƒì§€ì— ë°©í•´ë˜ëŠ” ë…¸ì´ì¦ˆë¥¼ ì œê±°í•©ë‹ˆë‹¤."
        )
        denoise_method = "bilateral"
        gaussian_kernel = 5
        median_kernel = 5
        bilateral_d = 9
        bilateral_sigma_color = 75
        bilateral_sigma_space = 75
        if denoise_enabled:
            denoise_method = st.selectbox(
                "ë…¸ì´ì¦ˆ ì œê±° ë°©ë²•", 
                ["bilateral", "gaussian", "median"],
                index=0,
                help="â€¢ Bilateral (ì¶”ì²œ): ì—£ì§€ ë³´ì¡´í•˜ë©° ë…¸ì´ì¦ˆ ì œê±° - QR íŒ¨í„´ ìœ ì§€ ìµœì \n"
                     "â€¢ Gaussian: ë¶€ë“œëŸ¬ìš´ ë¸”ëŸ¬ - ì¼ë°˜ì ì¸ ì¡ìŒ ì œê±°\n"
                     "â€¢ Median: Salt-pepper ë…¸ì´ì¦ˆ(ì‘ì€ ì ë“¤) ì œê±°ì— íš¨ê³¼ì "
            )
            if denoise_method == "gaussian":
                gaussian_kernel = st.slider(
                    "Gaussian Kernel Size", 
                    3, 15, 5, 2,
                    help="ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ ì»¤ë„ í¬ê¸° (í™€ìˆ˜ë§Œ ê°€ëŠ¥: 3, 5, 7, 9, 11, 13, 15)\n"
                         "â€¢ ê°’ì´ ì‘ìœ¼ë©´: ì•½í•œ ë¸”ëŸ¬, ì„¸ë¶€ ì •ë³´ ë³´ì¡´, ë…¸ì´ì¦ˆ ì¼ë¶€ ë‚¨ìŒ\n"
                         "â€¢ ê°’ì´ í¬ë©´: ê°•í•œ ë¸”ëŸ¬, ë…¸ì´ì¦ˆ ì œê±° ê°•í•¨, í•˜ì§€ë§Œ QR íŒ¨í„´ì´ íë ¤ì§ˆ ìˆ˜ ìˆìŒ\n"
                         "â€¢ ê¶Œì¥ê°’: 5 (ì¼ë°˜), 3 (ì„ ëª…í•œ QR), 7-9 (ë…¸ì´ì¦ˆ ë§ìŒ)"
                )
            elif denoise_method == "median":
                median_kernel = st.slider(
                    "Median Kernel Size", 
                    3, 15, 5, 2,
                    help="ë¯¸ë””ì•ˆ í•„í„° ì»¤ë„ í¬ê¸° (í™€ìˆ˜ë§Œ ê°€ëŠ¥)\n"
                         "â€¢ ê°’ì´ ì‘ìœ¼ë©´: ì‘ì€ ë…¸ì´ì¦ˆë§Œ ì œê±°\n"
                         "â€¢ ê°’ì´ í¬ë©´: í° ë…¸ì´ì¦ˆë„ ì œê±°í•˜ì§€ë§Œ QR íŒ¨í„´ ì†ìƒ ê°€ëŠ¥\n"
                         "â€¢ ê¶Œì¥ê°’: 5 (ì¼ë°˜), 3 (ì‘ì€ ë…¸ì´ì¦ˆ), 7 (í° ë…¸ì´ì¦ˆ)"
                )
            elif denoise_method == "bilateral":
                bilateral_d = st.slider(
                    "Bilateral d (í•„í„°ë§ ê±°ë¦¬)", 
                    5, 15, 9, 2,
                    help="ê° í”½ì…€ ì£¼ë³€ì—ì„œ ê³ ë ¤í•  ì´ì›ƒ í”½ì…€ì˜ ê±°ë¦¬ (í™€ìˆ˜ë§Œ ê°€ëŠ¥)\n"
                         "â€¢ ê°’ì´ ì‘ìœ¼ë©´: ì‘ì€ ì˜ì—­ë§Œ ì²˜ë¦¬, ì„¸ë°€í•œ ë…¸ì´ì¦ˆ ì œê±°\n"
                         "â€¢ ê°’ì´ í¬ë©´: ë„“ì€ ì˜ì—­ ì²˜ë¦¬, í° íŒ¨í„´ ë…¸ì´ì¦ˆ ì œê±°\n"
                         "â€¢ ê¶Œì¥ê°’: 9 (ì¼ë°˜), 5 (ì„¸ë°€í•˜ê²Œ), 13 (í° ë…¸ì´ì¦ˆ)"
                )
                bilateral_sigma_color = st.slider(
                    "Sigma Color (ìƒ‰ìƒ ì°¨ì´ í—ˆìš©)", 
                    50, 150, 75, 5,
                    help="ìƒ‰ìƒ ê°’ì˜ ì°¨ì´ í—ˆìš© ë²”ìœ„\n"
                         "â€¢ ê°’ì´ ì‘ìœ¼ë©´: ë¹„ìŠ·í•œ ìƒ‰ìƒë§Œ í•„í„°ë§, ì—£ì§€ ë³´ì¡´ ê°•í•¨\n"
                         "â€¢ ê°’ì´ í¬ë©´: ë‹¤ë¥¸ ìƒ‰ìƒë„ í‰í™œí™”, ë…¸ì´ì¦ˆ ì œê±° ê°•í•¨\n"
                         "â€¢ ê¶Œì¥ê°’: 75 (ì¼ë°˜), 50 (ì—£ì§€ ê°•ì¡°), 100-150 (ê°•í•œ ë…¸ì´ì¦ˆ ì œê±°)"
                )
                bilateral_sigma_space = st.slider(
                    "Sigma Space (ê³µê°„ ê±°ë¦¬)", 
                    50, 150, 75, 5,
                    help="ê³µê°„ì  ê±°ë¦¬ì˜ ì˜í–¥ ë²”ìœ„\n"
                         "â€¢ ê°’ì´ ì‘ìœ¼ë©´: ê°€ê¹Œìš´ í”½ì…€ë§Œ ì˜í–¥, ì„¸ë°€í•œ ì²˜ë¦¬\n"
                         "â€¢ ê°’ì´ í¬ë©´: ë©€ë¦¬ ìˆëŠ” í”½ì…€ë„ ì˜í–¥, ë¶€ë“œëŸ¬ìš´ ì²˜ë¦¬\n"
                         "â€¢ ê¶Œì¥ê°’: 75 (ì¼ë°˜), 50 (ì„¸ë°€í•˜ê²Œ), 100-150 (ë¶€ë“œëŸ½ê²Œ)"
                )
        
        # 2. ëª…ì•”/ì¡°ëª… ë³´ì •
        st.subheader("2ï¸âƒ£ ëª…ì•”/ì¡°ëª… ë³´ì •")
        st.caption("ê¸ˆì† ë°˜ì‚¬, ê·¸ë¦¼ì, ë¶ˆê· ì¼í•œ ì¡°ëª… ë“±ìœ¼ë¡œ ì¸í•œ ëŒ€ë¹„ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤.")
        
        enhancement_enabled = st.checkbox(
            "ëª…ì•” ë³´ì • í™œì„±í™”", 
            value=False,
            help="ì–´ë‘ìš´ ë¶€ë¶„ì„ ë°ê²Œ, ë°ì€ ë¶€ë¶„ì„ ì¡°ì ˆí•˜ì—¬ QR ì½”ë“œ ëŒ€ë¹„ë¥¼ ê°œì„ í•©ë‹ˆë‹¤."
        )
        enhancement_methods = []
        clahe_clip_limit = 2.0
        clahe_tile_size = [8, 8]
        gamma_value = 1.0
        retinex_sigma = "15,80,250"
        if enhancement_enabled:
            enhancement_methods = st.multiselect(
                "ë³´ì • ë°©ë²• ì„ íƒ",
                ["clahe", "gamma", "retinex"],
                default=["clahe"],
                help="â€¢ CLAHE (ì¶”ì²œ): ì§€ì—­ë³„ ëª…ì•” ì¡°ì ˆ - ê¸ˆì† ë°˜ì‚¬/ê·¸ë¦¼ì í™˜ê²½ì— ìµœì \n"
                     "â€¢ Gamma: ì „ì²´ì ì¸ ë°ê¸° ì¡°ì ˆ - ì–´ë‘ìš´ ì´ë¯¸ì§€ì— ìœ ë¦¬\n"
                     "â€¢ Retinex: ë³µì¡í•œ ì¡°ëª… ì¡°ê±´ ë³´ì • - ìì—°ìŠ¤ëŸ¬ìš´ ë°ê¸° ì¡°ì ˆ"
            )
            if "clahe" in enhancement_methods:
                clahe_clip_limit = st.slider(
                    "CLAHE Clip Limit", 
                    1.0, 5.0, 2.0, 0.1,
                    help="ëŒ€ë¹„ ì œí•œ ê°’ - íˆìŠ¤í† ê·¸ë¨ í‰í™œí™” ê°•ë„ ì¡°ì ˆ\n"
                         "â€¢ ê°’ì´ ë‚®ìœ¼ë©´ (1.0-2.0): ì•½í•œ ëŒ€ë¹„ ê°œì„ , ì˜¤íƒì§€ ê°ì†Œ, ìì—°ìŠ¤ëŸ¬ì›€\n"
                         "â€¢ ê°’ì´ ë†’ìœ¼ë©´ (3.0-5.0): ê°•í•œ ëŒ€ë¹„ ê°œì„ , QR íŒ¨í„´ ëª…í™•í•´ì§, í•˜ì§€ë§Œ ì˜¤íƒì§€ ì¦ê°€ ê°€ëŠ¥\n"
                         "â€¢ ê¶Œì¥ê°’: 2.0 (ì¼ë°˜), 1.0-1.5 (ì˜¤íƒì§€ ë§ì„ ë•Œ), 3.0-4.0 (ëŒ€ë¹„ ë‚®ì€ ì´ë¯¸ì§€)"
                )
                tile_size_val = st.slider(
                    "CLAHE Tile Size", 
                    4, 16, 8, 2,
                    help="ì§€ì—­ ì²˜ë¦¬ íƒ€ì¼ í¬ê¸° (í”½ì…€)\n"
                         "â€¢ ê°’ì´ ì‘ìœ¼ë©´: ì‘ì€ ì˜ì—­ë³„ ì²˜ë¦¬, ì„¸ë°€í•œ ì¡°ì ˆ, ëŠë¦¼\n"
                         "â€¢ ê°’ì´ í¬ë©´: í° ì˜ì—­ë³„ ì²˜ë¦¬, ë¹ ë¦„, í•˜ì§€ë§Œ ì„¸ë°€í•¨ ë–¨ì–´ì§\n"
                         "â€¢ ê¶Œì¥ê°’: 8 (ì¼ë°˜), 4-6 (ì„¸ë°€í•˜ê²Œ), 12-16 (ë¹ ë¥´ê²Œ)"
                )
                clahe_tile_size = [tile_size_val, tile_size_val]
            if "gamma" in enhancement_methods:
                gamma_value = st.slider(
                    "Gamma ê°’", 
                    0.1, 3.0, 1.0, 0.1,
                    help="ê°ë§ˆ ë³´ì • ê°’ - ë°ê¸° ê³¡ì„  ì¡°ì ˆ\n"
                         "â€¢ ê°’ < 1.0 (ì˜ˆ: 0.5): ì–´ë‘ìš´ ë¶€ë¶„ ë°ê²Œ, ë°ì€ ë¶€ë¶„ì€ ëœ ë³€í™”\n"
                         "â€¢ ê°’ = 1.0: ë³€í™” ì—†ìŒ\n"
                         "â€¢ ê°’ > 1.0 (ì˜ˆ: 1.5-2.0): ì–´ë‘ìš´ ë¶€ë¶„ ë” ì–´ë‘¡ê²Œ, ë°ì€ ë¶€ë¶„ ê°•ì¡°\n"
                         "â€¢ ê¶Œì¥ê°’: 1.0 (ê¸°ë³¸), 0.5-0.8 (ì–´ë‘ìš´ ì´ë¯¸ì§€), 1.2-1.5 (ê³¼ë‹¤ ë…¸ì¶œ ì´ë¯¸ì§€)"
                )
            if "retinex" in enhancement_methods:
                retinex_sigma = st.text_input(
                    "Retinex Sigma (ì‰¼í‘œë¡œ êµ¬ë¶„)", 
                    "15,80,250",
                    help="ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ Retinexì˜ ì‹œê·¸ë§ˆ ê°’ë“¤ (ì‘ì€ê°’, ì¤‘ê°„ê°’, í°ê°’)\n"
                         "â€¢ ì‘ì€ ê°’ (15): ì‘ì€ ì„¸ë¶€ì‚¬í•­ ë³´ì •\n"
                         "â€¢ ì¤‘ê°„ ê°’ (80): ì¤‘ê°„ í¬ê¸° ì¡°ëª… ë³€í™” ë³´ì •\n"
                         "â€¢ í° ê°’ (250): í° ì˜ì—­ ì¡°ëª… ë³€í™” ë³´ì •\n"
                         "â€¢ ê¸°ë³¸ê°’: 15,80,250 (ëŒ€ë¶€ë¶„ì˜ ê²½ìš° ì í•©)"
                )
        
        # 3. ë°˜ì „
        st.subheader("3ï¸âƒ£ ë°˜ì „ ì²˜ë¦¬")
        st.caption("QR ì½”ë“œê°€ ì–´ë‘ìš´ ë°°ê²½ì— ë°ì€ ì½”ë“œ í˜•íƒœì¼ ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        
        invert = st.checkbox(
            "ì´ë¯¸ì§€ ë°˜ì „", 
            value=False,
            help="ì´ë¯¸ì§€ ìƒ‰ìƒì„ ë°˜ì „ì‹œí‚µë‹ˆë‹¤ (ê²€ì€ìƒ‰ â†” í°ìƒ‰)\n"
                 "â€¢ ì‚¬ìš© ì‹œê¸°: QR ì½”ë“œê°€ ìŒí™”(ë„¤ê±°í‹°ë¸Œ) í˜•íƒœì¼ ë•Œ\n"
                 "â€¢ íš¨ê³¼: ë°ì€ ë°°ê²½ + ì–´ë‘ìš´ QR â†’ ì–´ë‘ìš´ ë°°ê²½ + ë°ì€ QRë¡œ ë³€í™˜"
        )
        
        # 4. ì´ì§„í™”
        st.subheader("4ï¸âƒ£ ì´ì§„í™”")
        st.caption("ì´ë¯¸ì§€ë¥¼ ê²€ì€ìƒ‰/í°ìƒ‰ ë‘ ê°€ì§€ë¡œë§Œ ë‚˜ëˆ„ì–´ QR íŒ¨í„´ì„ ëª…í™•í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤.")
        
        binarization_enabled = st.checkbox(
            "ì´ì§„í™” í™œì„±í™”", 
            value=False,
            help="ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ì´ë¯¸ì§€ë¥¼ í‘ë°±(0 ë˜ëŠ” 255)ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n"
                 "â€¢ ì¥ì : QR íŒ¨í„´ì´ ëª…í™•í•´ì§, í•´ë…ë¥  í–¥ìƒ\n"
                 "â€¢ ë‹¨ì : ìƒ‰ìƒ ì •ë³´ ì™„ì „ ì†ì‹¤\n"
                 "â€¢ ì‚¬ìš© ì‹œê¸°: ì¡°ë„ ë¶ˆê· ì¼, ëŒ€ë¹„ ë‚®ì€ ì´ë¯¸ì§€"
        )
        binarization_method = "adaptive_gaussian"
        adaptive_block_size = 11
        adaptive_c = 2
        if binarization_enabled:
            binarization_method = st.selectbox(
                "ì´ì§„í™” ë°©ë²•",
                ["adaptive_gaussian", "adaptive_mean", "otsu"],
                index=0,
                help="â€¢ Adaptive Gaussian (ì¶”ì²œ): ì¡°ë„ ë¶ˆê· ì¼ í™˜ê²½ì— ìµœì  - ì§€ì—­ë³„ ì„ê³„ê°’ ê³„ì‚°\n"
                     "â€¢ Adaptive Mean: í‰ê·  ê¸°ë°˜ ì ì‘í˜• - Gaussianë³´ë‹¤ ë¹ ë¥´ì§€ë§Œ ëœ ì •í™•\n"
                     "â€¢ Otsu: ì „ì²´ ì´ë¯¸ì§€ ìµœì  ì„ê³„ê°’ - ì¡°ë„ ê· ì¼í•  ë•Œ ë¹ ë¥´ê³  íš¨ê³¼ì "
            )
            if "adaptive" in binarization_method:
                adaptive_block_size = st.slider(
                    "Block Size (ì§€ì—­ í¬ê¸°)", 
                    3, 21, 11, 2,
                    help="ì„ê³„ê°’ì„ ê³„ì‚°í•  ì§€ì—­ì˜ í¬ê¸° (í™€ìˆ˜ë§Œ ê°€ëŠ¥: 3, 5, 7, 9, 11, 13, 15, 17, 19, 21)\n"
                         "â€¢ ê°’ì´ ì‘ìœ¼ë©´: ì‘ì€ ì˜ì—­ë³„ ì²˜ë¦¬, ì„¸ë°€í•¨, ë…¸ì´ì¦ˆì— ë¯¼ê°\n"
                         "â€¢ ê°’ì´ í¬ë©´: í° ì˜ì—­ë³„ ì²˜ë¦¬, ì•ˆì •ì , í•˜ì§€ë§Œ ì„¸ë°€í•¨ ë–¨ì–´ì§\n"
                         "â€¢ ê¶Œì¥ê°’: 11 (ì¼ë°˜), 5-7 (ì„¸ë°€í•˜ê²Œ), 15-21 (í° QR, ì•ˆì •ì )"
                )
                adaptive_c = st.slider(
                    "C ê°’ (ìƒìˆ˜)", 
                    -10, 10, 2, 1,
                    help="ì„ê³„ê°’ì—ì„œ ë¹¼ëŠ” ìƒìˆ˜ ê°’ - ë°ê¸° ì¡°ì ˆ\n"
                         "â€¢ ê°’ì´ ë†’ìœ¼ë©´ (ì–‘ìˆ˜): ë” ë°ì€ í”½ì…€ë„ í°ìƒ‰ìœ¼ë¡œ, QR íŒ¨í„´ ë‘ê»ê²Œ\n"
                         "â€¢ ê°’ì´ ë‚®ìœ¼ë©´ (ìŒìˆ˜): ë” ì–´ë‘ìš´ í”½ì…€ë„ ê²€ì€ìƒ‰ìœ¼ë¡œ, QR íŒ¨í„´ ì–‡ê²Œ\n"
                         "â€¢ ê¶Œì¥ê°’: 2 (ì¼ë°˜), 0-5 (ë°ì€ QR), -5-0 (ì–´ë‘ìš´ QR)"
                )
        
        # 5. í˜•íƒœí•™ì  ì—°ì‚°
        st.subheader("5ï¸âƒ£ í˜•íƒœí•™ì  ì—°ì‚°")
        st.caption("QR ì½”ë“œì˜ íŒ¨í„´ì„ ì—°ê²°í•˜ê±°ë‚˜ ë…¸ì´ì¦ˆë¥¼ ì œê±°í•˜ì—¬ êµ¬ì¡°ë¥¼ ê°•í™”í•©ë‹ˆë‹¤.")
        
        morphology_enabled = st.checkbox(
            "í˜•íƒœí•™ì  ì—°ì‚° í™œì„±í™”", 
            value=False,
            help="ì´ì§„í™”ëœ ì´ë¯¸ì§€ì—ì„œ QR íŒ¨í„´ì˜ êµ¬ì¡°ë¥¼ ê°œì„ í•©ë‹ˆë‹¤.\n"
                 "â€¢ Closing: ëŠì–´ì§„ ì„  ì—°ê²°\n"
                 "â€¢ Opening: ì‘ì€ ë…¸ì´ì¦ˆ ì œê±°\n"
                 "â€¢ Dilation: íŒ¨í„´ ë‘ê»ê²Œ"
        )
        morphology_operations = []
        morphology_kernel_size = 5
        dilation_iterations = 1
        if morphology_enabled:
            morphology_operations = st.multiselect(
                "ì—°ì‚° ì„ íƒ",
                ["closing", "opening", "dilation"],
                default=["closing", "opening"],
                help="â€¢ Closing (íŒ½ì°½â†’ì¹¨ì‹): ëŠì–´ì§„ QR íŒ¨í„´ì˜ ì„ ì„ ì—°ê²°í•©ë‹ˆë‹¤\n"
                     "â€¢ Opening (ì¹¨ì‹â†’íŒ½ì°½): QR ì£¼ë³€ì˜ ì‘ì€ ë…¸ì´ì¦ˆë¥¼ ì œê±°í•©ë‹ˆë‹¤\n"
                     "â€¢ Dilation (íŒ½ì°½): í¬ë¯¸í•œ QR íŒ¨í„´ì„ ë‘ê»ê²Œ ë§Œë“­ë‹ˆë‹¤\n"
                     "â€¢ ê¶Œì¥ ìˆœì„œ: Closing â†’ Opening (ì¼ë°˜), ë˜ëŠ” Dilationë§Œ (í¬ë¯¸í•œ QR)"
            )
            morphology_kernel_size = st.slider(
                "Kernel Size (ì»¤ë„ í¬ê¸°)", 
                3, 15, 5, 2,
                help="í˜•íƒœí•™ì  ì—°ì‚°ì— ì‚¬ìš©í•  ì»¤ë„(í•„í„°) í¬ê¸° (í™€ìˆ˜ë§Œ ê°€ëŠ¥)\n"
                     "â€¢ ê°’ì´ ì‘ìœ¼ë©´: ì‘ì€ ë³€í™”ë§Œ ì²˜ë¦¬, ì„¸ë°€í•¨ ìœ ì§€\n"
                     "â€¢ ê°’ì´ í¬ë©´: í° ë³€í™” ì²˜ë¦¬, íŒ¨í„´ í¬ê²Œ ë³€í™”\n"
                     "â€¢ ê¶Œì¥ê°’: 5 (ì¼ë°˜), 3 (ì„¸ë°€í•˜ê²Œ), 7-9 (í° ë³€í™”)"
            )
            if "dilation" in morphology_operations:
                dilation_iterations = st.slider(
                    "Dilation Iterations (ë°˜ë³µ íšŸìˆ˜)", 
                    1, 5, 1,
                    help="Dilationì„ ë°˜ë³µí•  íšŸìˆ˜\n"
                         "â€¢ ê°’ì´ ë†’ìœ¼ë©´: ë” ë‘ê»ê²Œ, í¬ë¯¸í•œ QRë„ ê°•í™”\n"
                         "â€¢ ê°’ì´ ë‚®ìœ¼ë©´: ì•½í•˜ê²Œ, ì›ë³¸ ìœ ì§€\n"
                         "â€¢ ê¶Œì¥ê°’: 1 (ì¼ë°˜), 2-3 (í¬ë¯¸í•œ QR)"
                )
        
        # 6. Super Resolution
        st.subheader("6ï¸âƒ£ Super Resolution")
        st.caption("ì‘ê±°ë‚˜ íë¦¿í•œ QR ì½”ë“œë¥¼ í™•ëŒ€í•˜ì—¬ í•´ë…ë¥ ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.")
        
        super_resolution_enabled = st.checkbox(
            "Super Resolution í™œì„±í™”", 
            value=False,
            help="ì´ë¯¸ì§€ì˜ í•´ìƒë„ë¥¼ ë†’ì…ë‹ˆë‹¤.\n"
                 "â€¢ ì‚¬ìš© ì‹œê¸°: QR ì½”ë“œê°€ ì‘ê±°ë‚˜ ë©€ë¦¬ ìˆì„ ë•Œ\n"
                 "â€¢ íš¨ê³¼: QR ëª¨ë“ˆ(ì‘ì€ ì •ì‚¬ê°í˜•)ì˜ ê²½ê³„ê°€ ëª…í™•í•´ì§"
        )
        sr_scale = 2.0
        if super_resolution_enabled:
            sr_scale = st.slider(
                "ì—…ìŠ¤ì¼€ì¼ ë¹„ìœ¨", 
                1.5, 4.0, 2.0, 0.5,
                help="ì´ë¯¸ì§€ë¥¼ ëª‡ ë°°ë¡œ í™•ëŒ€í• ì§€ ì„¤ì •\n"
                     "â€¢ ê°’ì´ ì‘ìœ¼ë©´ (1.5-2.0): ì•½ê°„ í™•ëŒ€, ì²˜ë¦¬ ì†ë„ ë¹ ë¦„\n"
                     "â€¢ ê°’ì´ í¬ë©´ (3.0-4.0): ë§ì´ í™•ëŒ€, QR í¬ê²Œ ë³´ì´ì§€ë§Œ ì²˜ë¦¬ ëŠë¦¼\n"
                     "â€¢ ê¶Œì¥ê°’: 2.0 (ì¼ë°˜), 1.5 (ì•½ê°„ ì‘ì€ QR), 3.0-4.0 (ë§¤ìš° ì‘ì€ QR)"
            )
        
        # 7. Deblurring
        st.subheader("7ï¸âƒ£ Deblurring")
        st.caption("í”ë“¤ë¦¼ì´ë‚˜ ì´ë™ìœ¼ë¡œ ì¸í•´ íë¦¿í•´ì§„ QR ì½”ë“œë¥¼ ì„ ëª…í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤.")
        
        deblur_enabled = st.checkbox(
            "Deblurring í™œì„±í™”", 
            value=False,
            help="ë¸”ëŸ¬(íë¦¼) í˜„ìƒì„ ì œê±°í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ì„ ëª…í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤.\n"
                 "â€¢ ì‚¬ìš© ì‹œê¸°: ì¹´ë©”ë¼ í”ë“¤ë¦¼, ë¹ ë¥¸ ì´ë™ ì¤‘ ì´¬ì˜, ì´ˆì ì´ ë§ì§€ ì•Šì„ ë•Œ"
        )
        deblur_iterations = 30
        deblur_sigma = 1.5
        if deblur_enabled:
            deblur_iterations = st.slider(
                "Iterations (ë°˜ë³µ íšŸìˆ˜)", 
                10, 100, 30, 10,
                help="ë””ë¸”ëŸ¬ë§ ì•Œê³ ë¦¬ì¦˜ ë°˜ë³µ íšŸìˆ˜\n"
                     "â€¢ ê°’ì´ ë‚®ìœ¼ë©´: ë¹ ë¥¸ ì²˜ë¦¬, ì•½í•œ ë””ë¸”ëŸ¬\n"
                     "â€¢ ê°’ì´ ë†’ìœ¼ë©´: ëŠë¦° ì²˜ë¦¬, ê°•í•œ ë””ë¸”ëŸ¬, í•˜ì§€ë§Œ ê³¼ë„í•˜ë©´ ì¸ê³µë¬¼ ìƒì„±\n"
                     "â€¢ ê¶Œì¥ê°’: 30 (ì¼ë°˜), 10-20 (ì•½ê°„ íë¦¼), 50-100 (ì‹¬í•˜ê²Œ íë¦¼)"
            )
            deblur_sigma = st.slider(
                "Sigma (ë¸”ëŸ¬ ê°•ë„ ì¶”ì •)", 
                0.5, 3.0, 1.5, 0.1,
                help="ë¸”ëŸ¬ì˜ ê°•ë„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê°’\n"
                     "â€¢ ê°’ì´ ì‘ìœ¼ë©´: ì‘ì€ ë¸”ëŸ¬ë§Œ ì œê±°, ì„¸ë¶€ì‚¬í•­ ë³´ì¡´\n"
                     "â€¢ ê°’ì´ í¬ë©´: í° ë¸”ëŸ¬ë„ ì œê±°, í•˜ì§€ë§Œ ê³¼ë„í•˜ë©´ ì¸ê³µë¬¼ ìƒì„±\n"
                     "â€¢ ê¶Œì¥ê°’: 1.5 (ì¼ë°˜), 0.5-1.0 (ì•½ê°„ íë¦¼), 2.0-3.0 (ì‹¬í•˜ê²Œ íë¦¼)"
            )
        
        # 8. ê¸°í•˜í•™ì  ë³´ì •
        st.subheader("8ï¸âƒ£ ê¸°í•˜í•™ì  ë³´ì •")
        st.caption("ê¸°ìš¸ì–´ì§€ê±°ë‚˜ íšŒì „ëœ QR ì½”ë“œë¥¼ ì •ë©´ìœ¼ë¡œ í´ì„œ í•´ë…ë¥ ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.")
        
        geometric_enabled = st.checkbox(
            "ê¸°í•˜í•™ì  ë³´ì • í™œì„±í™”", 
            value=False,
            help="QR ì½”ë“œì˜ ê¸°í•˜í•™ì  ì™œê³¡ì„ ë³´ì •í•©ë‹ˆë‹¤.\n"
                 "â€¢ íšŒì „ ë³´ì •: ê¸°ìš¸ì–´ì§„ QRì„ ë°”ë¡œ ì„¸ì›€\n"
                 "â€¢ Perspective ë³´ì •: ë¹„ìŠ¤ë“¬í•˜ê²Œ ì°íŒ QRì„ ì •ë©´ìœ¼ë¡œ í´ì¤Œ"
        )
        rotation_angle = 0
        perspective_correction = False
        if geometric_enabled:
            rotation_angle = st.slider(
                "íšŒì „ ê°ë„", 
                -180, 180, 0, 5,
                help="QR ì½”ë“œë¥¼ íšŒì „ì‹œí‚¬ ê°ë„ (ë„ ë‹¨ìœ„)\n"
                     "â€¢ ì–‘ìˆ˜: ì‹œê³„ ë°©í–¥ íšŒì „\n"
                     "â€¢ ìŒìˆ˜: ë°˜ì‹œê³„ ë°©í–¥ íšŒì „\n"
                     "â€¢ 0: íšŒì „ ì—†ìŒ\n"
                     "â€¢ ì‚¬ìš© ì‹œê¸°: QR ì½”ë“œê°€ ê¸°ìš¸ì–´ì ¸ ìˆì„ ë•Œ"
            )
            perspective_correction = st.checkbox(
                "Perspective ë³´ì •", 
                value=False,
                help="ë¹„ìŠ¤ë“¬í•˜ê²Œ ì°íŒ QR ì½”ë“œë¥¼ ì •ë©´ìœ¼ë¡œ ë³´ì •í•©ë‹ˆë‹¤.\n"
                     "â€¢ íš¨ê³¼: ì›ê·¼ ì™œê³¡ ì œê±°, QR ì½”ë“œë¥¼ ì •ì‚¬ê°í˜•ìœ¼ë¡œ ë§Œë“¦\n"
                     "â€¢ ì‚¬ìš© ì‹œê¸°: QR ì½”ë“œê°€ ë¹„ìŠ¤ë“¬í•œ ê°ë„ë¡œ ì°í˜”ì„ ë•Œ\n"
                     "â€¢ ì°¸ê³ : ìë™ íƒì§€ ê¸°ëŠ¥ì€ ì•„ì§ ë¯¸êµ¬í˜„, ìˆ˜ë™ ì„¤ì • í•„ìš”"
            )
        
        # ë”¥ëŸ¬ë‹ í–¥ìƒ
        st.markdown("---")
        st.subheader("ğŸ¤– ë”¥ëŸ¬ë‹ í–¥ìƒ")
        st.caption("ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ë³µì›í•˜ê³  í–¥ìƒì‹œí‚µë‹ˆë‹¤. (í˜„ì¬ í”Œë ˆì´ìŠ¤í™€ë”)")
        
        use_deep_learning = st.checkbox(
            "U-Net/SegFormer í–¥ìƒ ì‚¬ìš©", 
            value=False,
            help="ë”¥ëŸ¬ë‹ ê¸°ë°˜ ì´ë¯¸ì§€ ë³µì›/í–¥ìƒ ê¸°ëŠ¥ì…ë‹ˆë‹¤.\n"
                 "â€¢ U-Net: ì´ë¯¸ì§€ ë³µì›, ë…¸ì´ì¦ˆ ì œê±°, ë””ë¸”ëŸ¬ë§\n"
                 "â€¢ SegFormer: ì´ë¯¸ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜ ê¸°ë°˜ í–¥ìƒ\n"
                 "â€¢ í˜„ì¬ ìƒíƒœ: í”Œë ˆì´ìŠ¤í™€ë”ë§Œ êµ¬í˜„ë¨ (í–¥í›„ êµ¬í˜„ ì˜ˆì •)\n"
                 "â€¢ íš¨ê³¼: ì‹¬ê°í•˜ê²Œ ì†ìƒëœ ì´ë¯¸ì§€ ë³µì› ê°€ëŠ¥"
        )
        
        # ì „ì²˜ë¦¬ ìˆœì„œ ì•ˆë‚´
        st.markdown("---")
        with st.expander("â„¹ï¸ ì „ì²˜ë¦¬ ì ìš© ìˆœì„œ", expanded=False):
            st.markdown("""
            ì „ì²˜ë¦¬ ì˜µì…˜ë“¤ì€ ë‹¤ìŒ ìˆœì„œë¡œ ì ìš©ë©ë‹ˆë‹¤:
            
            1. **ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜** (ì„ íƒ)
            2. **ë…¸ì´ì¦ˆ ì œê±°**
            3. **ëª…ì•”/ì¡°ëª… ë³´ì •**
            4. **ë°˜ì „ ì²˜ë¦¬**
            5. **Super Resolution**
            6. **Deblurring**
            7. **ì´ì§„í™”**
            8. **í˜•íƒœí•™ì  ì—°ì‚°**
            9. **ê¸°í•˜í•™ì  ë³´ì •**
            
            ğŸ’¡ **íŒ**: ìˆœì„œë¥¼ ê³ ë ¤í•˜ì—¬ ì˜µì…˜ì„ í™œì„±í™”í•˜ì„¸ìš”!
            """)
        
        # ì¶”ì²œ ì„¤ì •
        with st.expander("ğŸ’¡ ì¶”ì²œ ì„¤ì • ê°€ì´ë“œ", expanded=False):
            st.markdown("""
            ### ì¡°ì„ ì†Œ T-bar í™˜ê²½ (ì² íŒ ë…¹, ë¶ˆê· ì¼ ì¡°ëª…)
            1. âœ… ë…¸ì´ì¦ˆ ì œê±°: Bilateral Filter (d=9, sigma_color=75, sigma_space=75)
            2. âœ… ëª…ì•” ë³´ì •: CLAHE (clipLimit=2.0, tileSize=8x8)
            3. âœ… ì´ì§„í™”: Adaptive Gaussian (blockSize=11, C=2)
            4. âœ… í˜•íƒœí•™ì : Closing â†’ Opening
            
            ### ì–´ë‘ìš´ ì´ë¯¸ì§€
            1. âœ… ë…¸ì´ì¦ˆ ì œê±°: Bilateral Filter
            2. âœ… ëª…ì•” ë³´ì •: CLAHE + Gamma (0.5-0.8)
            3. âœ… ì´ì§„í™”: Adaptive Gaussian
            
            ### íë¦¿í•œ ì´ë¯¸ì§€
            1. âœ… Super Resolution (2.0-3.0ë°°)
            2. âœ… Deblurring (iterations=30-50)
            
            ### ì‘ì€ QR ì½”ë“œ
            1. âœ… Super Resolution (3.0-4.0ë°°)
            2. âœ… ë…¸ì´ì¦ˆ ì œê±°: Bilateral Filter
            """)
        
        # ì „ì²˜ë¦¬ ì˜µì…˜ ì •ë¦¬
        preprocessing_options = {
            'convert_grayscale': convert_grayscale,
            'conf_threshold': conf_threshold,
            'denoise_enabled': denoise_enabled,
            'denoise_method': denoise_method if denoise_enabled else None,
            'gaussian_kernel': gaussian_kernel if denoise_enabled and denoise_method == "gaussian" else 5,
            'median_kernel': median_kernel if denoise_enabled and denoise_method == "median" else 5,
            'bilateral_d': bilateral_d if denoise_enabled and denoise_method == "bilateral" else 9,
            'bilateral_sigma_color': bilateral_sigma_color if denoise_enabled and denoise_method == "bilateral" else 75,
            'bilateral_sigma_space': bilateral_sigma_space if denoise_enabled and denoise_method == "bilateral" else 75,
            'enhancement_enabled': enhancement_enabled,
            'enhancement_methods': enhancement_methods if enhancement_enabled else [],
            'clahe_clip_limit': clahe_clip_limit if enhancement_enabled and "clahe" in enhancement_methods else 2.0,
            'clahe_tile_size': clahe_tile_size if enhancement_enabled and "clahe" in enhancement_methods else [8, 8],
            'gamma_value': gamma_value if enhancement_enabled and "gamma" in enhancement_methods else 1.0,
            'retinex_sigma': [float(s) for s in retinex_sigma.split(',')] if enhancement_enabled and "retinex" in enhancement_methods else [15.0, 80.0, 250.0],
            'invert': invert,
            'binarization_enabled': binarization_enabled,
            'binarization_method': binarization_method if binarization_enabled else None,
            'adaptive_block_size': adaptive_block_size if binarization_enabled and "adaptive" in binarization_method else 11,
            'adaptive_c': adaptive_c if binarization_enabled and "adaptive" in binarization_method else 2,
            'morphology_enabled': morphology_enabled,
            'morphology_operations': morphology_operations if morphology_enabled else [],
            'morphology_kernel_size': morphology_kernel_size if morphology_enabled else 5,
            'dilation_iterations': dilation_iterations if morphology_enabled and "dilation" in morphology_operations else 1,
            'super_resolution_enabled': super_resolution_enabled,
            'sr_scale': sr_scale if super_resolution_enabled else 2.0,
            'deblur_enabled': deblur_enabled,
            'deblur_iterations': deblur_iterations if deblur_enabled else 30,
            'deblur_sigma': deblur_sigma if deblur_enabled else 1.5,
            'geometric_enabled': geometric_enabled,
            'rotation_angle': rotation_angle if geometric_enabled else 0,
            'perspective_correction': perspective_correction if geometric_enabled else False,
        }
    
    # ë©”ì¸ ì˜ì—­ - ì´ë¯¸ì§€ ì—…ë¡œë“œ ë° ì²˜ë¦¬
    uploaded_file = st.file_uploader("ì´ë¯¸ì§€ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”", type=['jpg', 'jpeg', 'png', 'bmp'])
    
    if uploaded_file is not None:
        # ì´ë¯¸ì§€ ì½ê¸°
        image = np.array(Image.open(uploaded_file))
        if len(image.shape) == 3:
            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
        
        # ì²˜ë¦¬ ë²„íŠ¼
        col1, col2 = st.columns([1, 1])
        with col1:
            if st.button("ğŸ”„ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘", width='stretch', type="primary"):
                if st.session_state.yolo_model is None:
                    st.error("âš ï¸ ë¨¼ì € YOLO ëª¨ë¸ì„ ë¡œë“œí•˜ì„¸ìš”!")
                else:
                    with st.spinner("ì²˜ë¦¬ ì¤‘..."):
                        results = process_image(
                            image,
                            preprocessing_options,
                            st.session_state.yolo_model,
                            st.session_state.dbr_reader,
                            st.session_state.transformer_model,
                            use_deep_learning
                        )
                        st.session_state.results = results
                    st.success("âœ… ì²˜ë¦¬ ì™„ë£Œ!")
        
        # ê²°ê³¼ í‘œì‹œ
        if st.session_state.results:
            results = st.session_state.results
            
            # ì›ë³¸ ì´ë¯¸ì§€ì™€ ì „ì²˜ë¦¬ ì´ë¯¸ì§€ ë‚˜ë€íˆ í‘œì‹œ
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("ğŸ“· ì›ë³¸ ì´ë¯¸ì§€")
                
                # ì›ë³¸ ì´ë¯¸ì§€ì— íƒì§€ ê²°ê³¼ í‘œì‹œ (ì‹œê°í™” í•¨ìˆ˜ ì‚¬ìš©)
                if results['original_image_visualized'] is not None:
                    original_rgb = cv2.cvtColor(results['original_image_visualized'], cv2.COLOR_BGR2RGB)
                    st.image(original_rgb, width='stretch')
                else:
                    original_rgb = cv2.cvtColor(results['original_image'], cv2.COLOR_BGR2RGB)
                    st.image(original_rgb, width='stretch')
                
                # ì›ë³¸ í•´ë… ê²°ê³¼
                st.markdown("**í•´ë… ê²°ê³¼:**")
                if results['original_decodings']:
                    for i, dec in enumerate(results['original_decodings']):
                        status = "âœ…" if dec['success'] else "âŒ"
                        st.text(f"{status} QR #{i+1}: {dec['text'] if dec['text'] else 'í•´ë… ì‹¤íŒ¨'} (ì‹ ë¢°ë„: {dec['confidence']:.2f})")
                else:
                    st.info("íƒì§€ëœ QR ì½”ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            with col2:
                st.subheader("âœ¨ ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€")
                
                if results['preprocessed_image_visualized'] is not None:
                    # ì „ì²˜ë¦¬ ì´ë¯¸ì§€ì— íƒì§€ ê²°ê³¼ í‘œì‹œ (ì‹œê°í™” í•¨ìˆ˜ ì‚¬ìš©)
                    preprocessed_vis = results['preprocessed_image_visualized']
                    # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ì¸ ê²½ìš° BGRë¡œ ë³€í™˜
                    if len(preprocessed_vis.shape) == 2:
                        preprocessed_vis = cv2.cvtColor(preprocessed_vis, cv2.COLOR_GRAY2BGR)
                    preprocessed_rgb = cv2.cvtColor(preprocessed_vis, cv2.COLOR_BGR2RGB)
                    st.image(preprocessed_rgb, width='stretch')
                elif results['preprocessed_image'] is not None:
                    # ì „ì²˜ë¦¬ë§Œ ìˆê³  ì‹œê°í™”ê°€ ì—†ëŠ” ê²½ìš°
                    preprocessed_clean = results['preprocessed_image']
                    if len(preprocessed_clean.shape) == 2:
                        preprocessed_clean = cv2.cvtColor(preprocessed_clean, cv2.COLOR_GRAY2BGR)
                    preprocessed_rgb = cv2.cvtColor(preprocessed_clean, cv2.COLOR_BGR2RGB)
                    st.image(preprocessed_rgb, width='stretch')
                else:
                    st.info("ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
                # ì „ì²˜ë¦¬ í•´ë… ê²°ê³¼ (í•­ìƒ í‘œì‹œ)
                if results['preprocessed_image'] is not None or results['preprocessed_image_visualized'] is not None:
                    st.markdown("**í•´ë… ê²°ê³¼:**")
                    if results['preprocessed_decodings']:
                        for i, dec in enumerate(results['preprocessed_decodings']):
                            status = "âœ…" if dec['success'] else "âŒ"
                            st.text(f"{status} QR #{i+1}: {dec['text'] if dec['text'] else 'í•´ë… ì‹¤íŒ¨'} (ì‹ ë¢°ë„: {dec['confidence']:.2f})")
                    else:
                        st.info("íƒì§€ëœ QR ì½”ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # ë¹„êµ í†µê³„
            st.markdown("---")
            st.subheader("ğŸ“Š ê²°ê³¼ ë¹„êµ")
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ì›ë³¸ íƒì§€ ìˆ˜", len(results['original_detections']))
            with col2:
                st.metric("ì›ë³¸ í•´ë… ì„±ê³µ", sum(1 for d in results['original_decodings'] if d['success']))
            with col3:
                st.metric("ì „ì²˜ë¦¬ íƒì§€ ìˆ˜", len(results['preprocessed_detections']))
            with col4:
                st.metric("ì „ì²˜ë¦¬ í•´ë… ì„±ê³µ", sum(1 for d in results['preprocessed_decodings'] if d['success']))
            
            # ë‹¤ìš´ë¡œë“œ ì„¹ì…˜
            st.markdown("---")
            st.subheader("ğŸ’¾ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
            
            download_col1, download_col2, download_col3 = st.columns(3)
            
            with download_col1:
                st.markdown("**ğŸ“· ì›ë³¸ ì´ë¯¸ì§€**")
                if results['original_image_visualized'] is not None:
                    # ì‹œê°í™”ëœ ì›ë³¸ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
                    original_vis_rgb = cv2.cvtColor(results['original_image_visualized'], cv2.COLOR_BGR2RGB)
                    pil_image = Image.fromarray(original_vis_rgb)
                    buf = io.BytesIO()
                    pil_image.save(buf, format='JPEG', quality=95)
                    buf.seek(0)
                    
                    st.download_button(
                        label="â¬‡ï¸ ì›ë³¸ (ì‹œê°í™”)",
                        data=buf.getvalue(),
                        file_name=f"original_visualized_{uploaded_file.name}",
                        mime="image/jpeg",
                        width='stretch',
                        help="íƒì§€ ê²°ê³¼ê°€ í‘œì‹œëœ ì›ë³¸ ì´ë¯¸ì§€"
                    )
            
            with download_col2:
                st.markdown("**âœ¨ ì „ì²˜ë¦¬ ì´ë¯¸ì§€ (ì‹œê°í™”)**")
                if results['preprocessed_image_visualized'] is not None:
                    # ì‹œê°í™”ëœ ì „ì²˜ë¦¬ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
                    preprocessed_vis = results['preprocessed_image_visualized']
                    # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ì¸ ê²½ìš° BGRë¡œ ë³€í™˜
                    if len(preprocessed_vis.shape) == 2:
                        preprocessed_vis = cv2.cvtColor(preprocessed_vis, cv2.COLOR_GRAY2BGR)
                    preprocessed_vis_rgb = cv2.cvtColor(preprocessed_vis, cv2.COLOR_BGR2RGB)
                    pil_image = Image.fromarray(preprocessed_vis_rgb)
                    buf = io.BytesIO()
                    pil_image.save(buf, format='JPEG', quality=95)
                    buf.seek(0)
                    
                    st.download_button(
                        label="â¬‡ï¸ ì „ì²˜ë¦¬ (ì‹œê°í™”)",
                        data=buf.getvalue(),
                        file_name=f"preprocessed_visualized_{uploaded_file.name}",
                        mime="image/jpeg",
                        width='stretch',
                        help="íƒì§€ ê²°ê³¼ê°€ í‘œì‹œëœ ì „ì²˜ë¦¬ ì´ë¯¸ì§€"
                    )
            
            with download_col3:
                st.markdown("**âœ¨ ì „ì²˜ë¦¬ ì´ë¯¸ì§€ (ìˆœìˆ˜)**")
                if results['preprocessed_image'] is not None:
                    # ì‹œê°í™” ì•ˆëœ ìˆœìˆ˜ ì „ì²˜ë¦¬ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
                    preprocessed_clean = results['preprocessed_image']
                    # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ì¸ ê²½ìš° BGRë¡œ ë³€í™˜
                    if len(preprocessed_clean.shape) == 2:
                        preprocessed_clean = cv2.cvtColor(preprocessed_clean, cv2.COLOR_GRAY2BGR)
                    preprocessed_clean_rgb = cv2.cvtColor(preprocessed_clean, cv2.COLOR_BGR2RGB)
                    pil_image = Image.fromarray(preprocessed_clean_rgb)
                    buf = io.BytesIO()
                    pil_image.save(buf, format='JPEG', quality=95)
                    buf.seek(0)
                    
                    st.download_button(
                        label="â¬‡ï¸ ì „ì²˜ë¦¬ (ìˆœìˆ˜)",
                        data=buf.getvalue(),
                        file_name=f"preprocessed_clean_{uploaded_file.name}",
                        mime="image/jpeg",
                        width='stretch',
                        help="íƒì§€ ê²°ê³¼ í‘œì‹œ ì—†ì´ ì „ì²˜ë¦¬ë§Œ ì ìš©ëœ ìˆœìˆ˜ ì´ë¯¸ì§€"
                    )
            
            # ì „ì²´ ë‹¤ìš´ë¡œë“œ (ZIP)
            if (results['original_image_visualized'] is not None or 
                results['preprocessed_image_visualized'] is not None or 
                results['preprocessed_image'] is not None):
                st.markdown("---")
                
                # ZIP íŒŒì¼ ìƒì„±
                zip_buffer = io.BytesIO()
                with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
                    # ì›ë³¸ ì‹œê°í™”
                    if results['original_image_visualized'] is not None:
                        original_vis_rgb = cv2.cvtColor(results['original_image_visualized'], cv2.COLOR_BGR2RGB)
                        pil_image = Image.fromarray(original_vis_rgb)
                        buf = io.BytesIO()
                        pil_image.save(buf, format='JPEG', quality=95)
                        buf.seek(0)
                        zip_file.writestr(f"original_visualized_{uploaded_file.name}", buf.getvalue())
                    
                    # ì „ì²˜ë¦¬ ì‹œê°í™”
                    if results['preprocessed_image_visualized'] is not None:
                        preprocessed_vis = results['preprocessed_image_visualized']
                        if len(preprocessed_vis.shape) == 2:
                            preprocessed_vis = cv2.cvtColor(preprocessed_vis, cv2.COLOR_GRAY2BGR)
                        preprocessed_vis_rgb = cv2.cvtColor(preprocessed_vis, cv2.COLOR_BGR2RGB)
                        pil_image = Image.fromarray(preprocessed_vis_rgb)
                        buf = io.BytesIO()
                        pil_image.save(buf, format='JPEG', quality=95)
                        buf.seek(0)
                        zip_file.writestr(f"preprocessed_visualized_{uploaded_file.name}", buf.getvalue())
                    
                    # ì „ì²˜ë¦¬ ìˆœìˆ˜
                    if results['preprocessed_image'] is not None:
                        preprocessed_clean = results['preprocessed_image']
                        if len(preprocessed_clean.shape) == 2:
                            preprocessed_clean = cv2.cvtColor(preprocessed_clean, cv2.COLOR_GRAY2BGR)
                        preprocessed_clean_rgb = cv2.cvtColor(preprocessed_clean, cv2.COLOR_BGR2RGB)
                        pil_image = Image.fromarray(preprocessed_clean_rgb)
                        buf = io.BytesIO()
                        pil_image.save(buf, format='JPEG', quality=95)
                        buf.seek(0)
                        zip_file.writestr(f"preprocessed_clean_{uploaded_file.name}", buf.getvalue())
                
                zip_buffer.seek(0)
                zip_filename = f"qr_results_{os.path.splitext(uploaded_file.name)[0]}.zip"
                st.download_button(
                    label="ğŸ“¦ ëª¨ë“  ì´ë¯¸ì§€ ZIPìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ",
                    data=zip_buffer.getvalue(),
                    file_name=zip_filename,
                    mime="application/zip",
                    width='stretch',
                    help="ì›ë³¸(ì‹œê°í™”), ì „ì²˜ë¦¬(ì‹œê°í™”), ì „ì²˜ë¦¬(ìˆœìˆ˜) ì´ë¯¸ì§€ë¥¼ ëª¨ë‘ í¬í•¨í•œ ZIP íŒŒì¼"
                )

if __name__ == "__main__":
    main()

